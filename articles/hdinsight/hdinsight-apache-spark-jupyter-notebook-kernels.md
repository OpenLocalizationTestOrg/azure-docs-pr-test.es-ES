---
title: "clústeres de aaaKernels para Jupyter notebook en Spark en HDInsight de Azure | Documentos de Microsoft"
description: "Obtenga información sobre los kernels de hello PySpark, PySpark3 y Spark para Jupyter notebook disponible con clústeres de Spark en HDInsight de Azure."
keywords: Jupyter Notebook en Spark, Spark en Jupyter
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="a4257-104">Kernels para Jupyter Notebook en clústeres Spark en Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="a4257-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="a4257-105">Los clústeres de HDInsight Spark proporcionan kernels que puede usar con el Bloc de notas de hello Jupyter en Spark para probar las aplicaciones.</span><span class="sxs-lookup"><span data-stu-id="a4257-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="a4257-106">Un kernel es un programa que ejecuta e interpreta el código.</span><span class="sxs-lookup"><span data-stu-id="a4257-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="a4257-107">los kernels de tres Hola son:</span><span class="sxs-lookup"><span data-stu-id="a4257-107">hello three kernels are:</span></span>

- <span data-ttu-id="a4257-108">**PySpark** (para aplicaciones escritas en Python2)</span><span class="sxs-lookup"><span data-stu-id="a4257-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="a4257-109">**PySpark3** (para aplicaciones escritas en Python3)</span><span class="sxs-lookup"><span data-stu-id="a4257-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="a4257-110">**Spark** (para aplicaciones escritas en Scala)</span><span class="sxs-lookup"><span data-stu-id="a4257-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="a4257-111">En este artículo, aprenderá cómo toouse estos kernels y las ventajas de Hola de su uso.</span><span class="sxs-lookup"><span data-stu-id="a4257-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="a4257-112">Requisitos previos</span><span class="sxs-lookup"><span data-stu-id="a4257-112">Prerequisites</span></span>

* <span data-ttu-id="a4257-113">Un clúster de Apache Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="a4257-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="a4257-114">Para obtener instrucciones, vea [Creación de clústeres Apache Spark en HDInsight de Azure](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="a4257-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="a4257-115">Creación de un cuaderno de Jupyter Notebook en clústeres Spark de HDInsight</span><span class="sxs-lookup"><span data-stu-id="a4257-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="a4257-116">De hello [portal de Azure](https://portal.azure.com/), abra el clúster.</span><span class="sxs-lookup"><span data-stu-id="a4257-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="a4257-117">Vea [lista y mostrar los clústeres de](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) para obtener instrucciones de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="a4257-118">clúster de Hola se abre en una nueva hoja de portal.</span><span class="sxs-lookup"><span data-stu-id="a4257-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="a4257-119">De hello **vínculos rápidos** sección, haga clic en **paneles de clúster** tooopen hello **paneles de clúster** hoja.</span><span class="sxs-lookup"><span data-stu-id="a4257-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="a4257-120">Si no ve **vínculos rápidos**, haga clic en **Introducción** desde el menú de la izquierda hello en la hoja de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="a4257-121">![Jupyter Notebook en Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter Notebook en Spark")</span><span class="sxs-lookup"><span data-stu-id="a4257-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="a4257-122">Haga clic en **Jupyter Notebook**.</span><span class="sxs-lookup"><span data-stu-id="a4257-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="a4257-123">Si se le pide, escriba las credenciales de administrador de Hola para clúster Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="a4257-124">También puede tener acceso a Jupyter notebook de hello en clúster de Spark por abrir Hola siguiente dirección URL en el explorador.</span><span class="sxs-lookup"><span data-stu-id="a4257-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="a4257-125">Reemplace **CLUSTERNAME** con nombre hello del clúster:</span><span class="sxs-lookup"><span data-stu-id="a4257-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="a4257-126">Haga clic en **New**y, a continuación, haga clic en **Pyspark**, **PySpark3**, o **Spark** toocreate un bloc de notas.</span><span class="sxs-lookup"><span data-stu-id="a4257-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="a4257-127">Usar el kernel de Spark Hola para aplicaciones Scala, kernel PySpark para aplicaciones de Python2 y PySpark3 kernel para aplicaciones de Python3.</span><span class="sxs-lookup"><span data-stu-id="a4257-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="a4257-128">![Kernels de Jupyter Notebook en Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels de Jupyter Notebook en Spark")</span><span class="sxs-lookup"><span data-stu-id="a4257-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="a4257-129">Se abre un bloc de notas con kernel Hola que seleccionó.</span><span class="sxs-lookup"><span data-stu-id="a4257-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="a4257-130">Ventajas de utilizar los kernels de Hola</span><span class="sxs-lookup"><span data-stu-id="a4257-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="a4257-131">Estas son algunas ventajas de usar kernels nuevos Hola con Jupyter notebook en clústeres de HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="a4257-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="a4257-132">**Contextos preestablecidos**.</span><span class="sxs-lookup"><span data-stu-id="a4257-132">**Preset contexts**.</span></span> <span data-ttu-id="a4257-133">Con **PySpark**, **PySpark3**, o hello **Spark** kernels, no es necesario tooset Hola Spark o subárbol contextos explícitamente antes de empezar a trabajar con las aplicaciones.</span><span class="sxs-lookup"><span data-stu-id="a4257-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="a4257-134">ya que están disponibles de forma predeterminada.</span><span class="sxs-lookup"><span data-stu-id="a4257-134">These are available by default.</span></span> <span data-ttu-id="a4257-135">Estos contextos son:</span><span class="sxs-lookup"><span data-stu-id="a4257-135">These contexts are:</span></span>
   
   * <span data-ttu-id="a4257-136">**sc** : para el contexto Spark</span><span class="sxs-lookup"><span data-stu-id="a4257-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="a4257-137">**sqlContext** : para el contexto Hive</span><span class="sxs-lookup"><span data-stu-id="a4257-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="a4257-138">Por lo tanto, no tiene instrucciones de toorun como Hola siguientes contextos de Hola tooset:</span><span class="sxs-lookup"><span data-stu-id="a4257-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="a4257-139">sc = SparkContext('yarn-client')  sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="a4257-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="a4257-140">En su lugar, puede usar directamente Hola preestablecido contextos de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="a4257-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="a4257-141">**Instrucciones mágicas de celda**.</span><span class="sxs-lookup"><span data-stu-id="a4257-141">**Cell magics**.</span></span> <span data-ttu-id="a4257-142">Hello PySpark kernel proporciona algunos predefinidas "magics", que son comandos especiales que se pueden llamar con `%%` (por ejemplo, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="a4257-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="a4257-143">comando mágica Hola debe ser Hola primera palabra en una celda de código y permitir varias líneas de contenido.</span><span class="sxs-lookup"><span data-stu-id="a4257-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="a4257-144">word mágica Hola debe ser primera palabra en la celda de Hola de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="a4257-145">Agregar cualquier cosa antes de magia hello, incluso de los comentarios, producirá un error.</span><span class="sxs-lookup"><span data-stu-id="a4257-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="a4257-146">Para obtener más información sobre instrucciones mágicas, vaya [aquí](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="a4257-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="a4257-147">Hello tabla siguiente enumeran magics diferentes de hello disponibles a través de los kernels de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="a4257-148">Instrucción mágica</span><span class="sxs-lookup"><span data-stu-id="a4257-148">Magic</span></span> | <span data-ttu-id="a4257-149">Ejemplo</span><span class="sxs-lookup"><span data-stu-id="a4257-149">Example</span></span> | <span data-ttu-id="a4257-150">Description</span><span class="sxs-lookup"><span data-stu-id="a4257-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="a4257-151">help</span><span class="sxs-lookup"><span data-stu-id="a4257-151">help</span></span> |`%%help` |<span data-ttu-id="a4257-152">Genera una tabla de todos los magics disponibles Hola con ejemplo y la descripción</span><span class="sxs-lookup"><span data-stu-id="a4257-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="a4257-153">info</span><span class="sxs-lookup"><span data-stu-id="a4257-153">info</span></span> |`%%info` |<span data-ttu-id="a4257-154">Genera información de sesión para el punto de conexión de hello actual Livio</span><span class="sxs-lookup"><span data-stu-id="a4257-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="a4257-155">CONFIGURAR</span><span class="sxs-lookup"><span data-stu-id="a4257-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="a4257-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="a4257-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="a4257-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="a4257-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="a4257-158">Configura los parámetros de Hola para crear una sesión.</span><span class="sxs-lookup"><span data-stu-id="a4257-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="a4257-159">Hola marca force (-f) es obligatorio si ya se ha creado una sesión, lo que garantiza que esa sesión Hola se quita y vuelve a crear.</span><span class="sxs-lookup"><span data-stu-id="a4257-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="a4257-160">Consulte [Livy's POST /sessions Request Body (Cuerpo de la solicitud de sesiones o POST de Livy)](https://github.com/cloudera/livy#request-body) para obtener una lista de parámetros válidos.</span><span class="sxs-lookup"><span data-stu-id="a4257-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="a4257-161">Parámetros deben pasarse con como una cadena JSON y deben estar en línea siguiente de hello después magia hello, como se muestra en la columna de ejemplo de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="a4257-162">sql</span><span class="sxs-lookup"><span data-stu-id="a4257-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="a4257-163">Ejecuta una consulta de Hive en hello sqlContext.</span><span class="sxs-lookup"><span data-stu-id="a4257-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="a4257-164">Si hello `-o` se pasa el parámetro, resultado de hello de consulta de Hola se conserva en hello %% contexto Python local como un [Pandas](http://pandas.pydata.org/) trama de datos.</span><span class="sxs-lookup"><span data-stu-id="a4257-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="a4257-165">local</span><span class="sxs-lookup"><span data-stu-id="a4257-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="a4257-166">Todo el código de hello en las líneas siguientes se ejecuta localmente.</span><span class="sxs-lookup"><span data-stu-id="a4257-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="a4257-167">Código debe ser válido código Python2 incluso independientemente del kernel de Hola que usa.</span><span class="sxs-lookup"><span data-stu-id="a4257-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="a4257-168">Así, incluso si ha seleccionado **PySpark3** o **Spark** kernels al crear el Bloc de notas de hello, si usas hello `%%local` mágico en una celda, esa celda solo debe tener código Python2 válido...</span><span class="sxs-lookup"><span data-stu-id="a4257-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="a4257-169">logs</span><span class="sxs-lookup"><span data-stu-id="a4257-169">logs</span></span> |`%%logs` |<span data-ttu-id="a4257-170">Salidas Hola registros de sesión de Livio actual Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="a4257-171">delete</span><span class="sxs-lookup"><span data-stu-id="a4257-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="a4257-172">Elimina una sesión específica del punto de conexión de hello actual Livio.</span><span class="sxs-lookup"><span data-stu-id="a4257-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="a4257-173">Tenga en cuenta que no se puede eliminar la sesión para el propio núcleo Hola Hola que se inicia.</span><span class="sxs-lookup"><span data-stu-id="a4257-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="a4257-174">cleanup</span><span class="sxs-lookup"><span data-stu-id="a4257-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="a4257-175">Elimina todas las sesiones del Hola Hola Livio punto de conexión actual, incluida la sesión de este bloc de notas.</span><span class="sxs-lookup"><span data-stu-id="a4257-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="a4257-176">Hola force marca -f es obligatorio.</span><span class="sxs-lookup"><span data-stu-id="a4257-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="a4257-177">Además toohello magics agregado kernel PySpark de hello, también puede usar hello [integrados magics IPython](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), incluido `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="a4257-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="a4257-178">Puede usar hello `%%sh` mágico toorun scripts y bloques de código en el nodo principal del clúster de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="a4257-179">**Visualización automática**.</span><span class="sxs-lookup"><span data-stu-id="a4257-179">**Auto visualization**.</span></span> <span data-ttu-id="a4257-180">Hola **Pyspark** kernel automáticamente visualiza la salida de hello de consultas de Hive y SQL.</span><span class="sxs-lookup"><span data-stu-id="a4257-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="a4257-181">Puede elegir entre diferentes tipos de visualizaciones, como tabla, circular, línea, área o barra.</span><span class="sxs-lookup"><span data-stu-id="a4257-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="a4257-182">Parámetros compatibles con hello %% mágico de sql</span><span class="sxs-lookup"><span data-stu-id="a4257-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="a4257-183">Hola `%%sql` mágico es compatible con parámetros diferentes que puede usar el tipo de hello toocontrol de salida que recibe cuando se ejecutan consultas.</span><span class="sxs-lookup"><span data-stu-id="a4257-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="a4257-184">Hello en la tabla siguiente muestra la salida de hello.</span><span class="sxs-lookup"><span data-stu-id="a4257-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="a4257-185">Parámetro</span><span class="sxs-lookup"><span data-stu-id="a4257-185">Parameter</span></span> | <span data-ttu-id="a4257-186">Ejemplo</span><span class="sxs-lookup"><span data-stu-id="a4257-186">Example</span></span> | <span data-ttu-id="a4257-187">Description</span><span class="sxs-lookup"><span data-stu-id="a4257-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="a4257-188">-o</span><span class="sxs-lookup"><span data-stu-id="a4257-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="a4257-189">Utilice este resultado de hello toopersist de parámetro de consulta de hello, Hola %% contexto local de Python, como un [Pandas](http://pandas.pydata.org/) trama de datos.</span><span class="sxs-lookup"><span data-stu-id="a4257-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="a4257-190">Hola de variable de la trama de datos de Hola se denomina nombre de variable de Hola que especifique.</span><span class="sxs-lookup"><span data-stu-id="a4257-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="a4257-191">-q</span><span class="sxs-lookup"><span data-stu-id="a4257-191">-q</span></span> |`-q` |<span data-ttu-id="a4257-192">Utilice este tooturn desactivar visualizaciones de celda Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="a4257-193">Si no desea tooauto-visualizar contenido Hola de una celda y sólo desea toocapture como una trama de datos, a continuación, utilice `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="a4257-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="a4257-194">Si desea tooturn desactivar visualizaciones sin capturar resultados hello (por ejemplo, para ejecutar una consulta SQL, como un `CREATE TABLE` instrucción), utilice `-q` sin especificar un `-o` argumento.</span><span class="sxs-lookup"><span data-stu-id="a4257-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="a4257-195">-m</span><span class="sxs-lookup"><span data-stu-id="a4257-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="a4257-196">Donde **METHOD** puede ser **take** o **sample** (el valor predeterminado es **take**).</span><span class="sxs-lookup"><span data-stu-id="a4257-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="a4257-197">Si es el método hello **tomar**, kernel Hola toma los elementos de la parte superior de Hola Hola datos de conjunto de resultados especificado por MAXROWS (descrita más adelante en esta tabla).</span><span class="sxs-lookup"><span data-stu-id="a4257-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="a4257-198">Si es el método hello **ejemplo**, kernel Hola muestrea de forma aleatoria los elementos del conjunto de datos de hello según demasiado`-r` parámetro, se describe a continuación en esta tabla.</span><span class="sxs-lookup"><span data-stu-id="a4257-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="a4257-199">-r</span><span class="sxs-lookup"><span data-stu-id="a4257-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="a4257-200">Aquí **FRACTION** es un número de punto flotante entre 0,0 y 1,0.</span><span class="sxs-lookup"><span data-stu-id="a4257-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="a4257-201">Si es el método de ejemplo de Hola para consultas SQL de hello `sample`, a continuación, kernel Hola muestrea fracción especificada de Hola de elementos de Hola de resultado de hello establecen automáticamente de forma aleatoria.</span><span class="sxs-lookup"><span data-stu-id="a4257-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="a4257-202">Por ejemplo, si ejecuta una consulta SQL con argumentos de hello `-m sample -r 0.01`, muestreo al azar de los 1% Hola de filas de resultados.</span><span class="sxs-lookup"><span data-stu-id="a4257-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="a4257-203">**MAXROWS** es un valor entero.</span><span class="sxs-lookup"><span data-stu-id="a4257-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="a4257-204">núcleo de Hello limita el número de Hola de filas de salida de demasiado**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="a4257-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="a4257-205">Si **MAXROWS** es un número negativo como **-1**, a continuación, Hola número de filas en el conjunto de resultados de hello no está limitado.</span><span class="sxs-lookup"><span data-stu-id="a4257-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="a4257-206">**Ejemplo:**</span><span class="sxs-lookup"><span data-stu-id="a4257-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="a4257-207">instrucción de Hello anterior Hola siguientes:</span><span class="sxs-lookup"><span data-stu-id="a4257-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="a4257-208">Selecciona todos los registros de **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="a4257-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="a4257-209">Dado que se usa -q, desactiva la visualización automática.</span><span class="sxs-lookup"><span data-stu-id="a4257-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="a4257-210">Dado que usamos `-m sample -r 0.1 -n 500` aleatoriamente muestrea el 10% de filas de hello en hello hivesampletable y límites de tamaño de filas de too500 de conjuntos de resultados de Hola de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="a4257-211">Por último, dado que hemos usado `-o query2` también guarda la salida de hello en una trama de datos denominado **consulta2**.</span><span class="sxs-lookup"><span data-stu-id="a4257-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="a4257-212">Consideraciones al usar Hola kernels nuevos</span><span class="sxs-lookup"><span data-stu-id="a4257-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="a4257-213">El kernel usa, dejando portátiles que Hola ejecutan consume recursos de clúster de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="a4257-214">Con estos núcleos, porque están predefinidos contextos de hello, simplemente salir blocs de notas de hello no kill contexto hello y, por tanto, los recursos de clúster de hello continuar toobe en uso.</span><span class="sxs-lookup"><span data-stu-id="a4257-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="a4257-215">Una buena práctica es hello de toouse **cerrar y detener la** opción de Bloc de notas hello **archivo** menú cuando haya terminado de usar el Bloc de notas de hello, que elimina el contexto de hello y, a continuación, cierra Hola Bloc de notas.</span><span class="sxs-lookup"><span data-stu-id="a4257-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="a4257-216">Estos son algunos ejemplos:</span><span class="sxs-lookup"><span data-stu-id="a4257-216">Show me some examples</span></span>

<span data-ttu-id="a4257-217">Cuando se abre Jupyter notebook, verá dos carpetas disponibles en el nivel de raíz de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="a4257-218">Hola **PySpark** carpeta tiene blocs de notas de ejemplo que use Hola nueva **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="a4257-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="a4257-219">Hola **Scala** carpeta tiene blocs de notas de ejemplo que use Hola nueva **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="a4257-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="a4257-220">Puede abrir hello **00 - [leer Léame primero] Spark magia Kernel características** Bloc de notas de hello **PySpark** o **Spark** carpeta toolearn sobre magics diferentes de hello disponibles.</span><span class="sxs-lookup"><span data-stu-id="a4257-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="a4257-221">También puede usar Hola otros blocs de notas de ejemplo disponibles en hello dos carpetas toolearn cómo tooachieve distintos escenarios utilizando blocs de notas de Jupyter con clústeres de HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="a4257-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="a4257-222">¿Dónde se almacenan los blocs de notas de hello?</span><span class="sxs-lookup"><span data-stu-id="a4257-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="a4257-223">Jupyter blocs de notas se guardan toohello cuenta de almacenamiento asociada a clúster de hello en hello **/HdiNotebooks** carpeta.</span><span class="sxs-lookup"><span data-stu-id="a4257-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="a4257-224">Blocs de notas, archivos de texto y las carpetas que se crean desde dentro de Jupyter son accesibles desde la cuenta de almacenamiento de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="a4257-225">Por ejemplo, si usa una carpeta del Jupyter toocreate **MiCarpeta** y un bloc de notas **myfolder/mynotebook.ipynb**, puede tener acceso a ese portátil a `/HdiNotebooks/myfolder/mynotebook.ipynb` dentro de la cuenta de almacenamiento de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="a4257-226">Hola inversa también es true, es decir, si carga un bloc de notas directamente la cuenta de almacenamiento de tooyour `/HdiNotebooks/mynotebook1.ipynb`, también es visible desde Jupyter notebook Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="a4257-227">Blocs de notas permanecen en la cuenta de almacenamiento de hello incluso después de que se elimina el clúster de Hola.</span><span class="sxs-lookup"><span data-stu-id="a4257-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="a4257-228">forma de Hello blocs de notas se guardan toohello cuenta de almacenamiento es compatible con HDFS.</span><span class="sxs-lookup"><span data-stu-id="a4257-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="a4257-229">Por lo tanto, si se SSH en clúster de hello que puede usar comandos de administración del archivo tal y como se muestra en el siguiente fragmento de código de hello:</span><span class="sxs-lookup"><span data-stu-id="a4257-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="a4257-230">En caso de que hay problemas de acceso a la cuenta de almacenamiento de hello para el clúster de hello, blocs de notas de hello también se guardan en el nodo principal de hello `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="a4257-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="a4257-231">Explorador compatible</span><span class="sxs-lookup"><span data-stu-id="a4257-231">Supported browser</span></span>

<span data-ttu-id="a4257-232">Los cuadernos de Jupyter Notebook que se ejecutan en clústeres Spark de HDInsight solo son compatibles con Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="a4257-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="a4257-233">Comentarios</span><span class="sxs-lookup"><span data-stu-id="a4257-233">Feedback</span></span>
<span data-ttu-id="a4257-234">Hola y kernels nuevos están en constante evolución fase se maduran con el tiempo.</span><span class="sxs-lookup"><span data-stu-id="a4257-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="a4257-235">También podría significar que las API podrían cambiar a medida que estos kernels maduran.</span><span class="sxs-lookup"><span data-stu-id="a4257-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="a4257-236">Agradecemos cualquier comentario que tenga al utilizar estos nuevos kernels.</span><span class="sxs-lookup"><span data-stu-id="a4257-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="a4257-237">Esto es útil para dar forma al lanzamiento final de Hola de estos núcleos.</span><span class="sxs-lookup"><span data-stu-id="a4257-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="a4257-238">Puede dejar los comentarios en hello **comentarios** sección Hola final de este artículo.</span><span class="sxs-lookup"><span data-stu-id="a4257-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="a4257-239"><a name="seealso"></a>Otras referencias</span><span class="sxs-lookup"><span data-stu-id="a4257-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="a4257-240">Introducción a Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="a4257-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="a4257-241">Escenarios</span><span class="sxs-lookup"><span data-stu-id="a4257-241">Scenarios</span></span>
* [<span data-ttu-id="a4257-242">Spark with BI: Realizar el análisis de datos interactivos con Spark en HDInsight con las herramientas de BI</span><span class="sxs-lookup"><span data-stu-id="a4257-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="a4257-243">Creación de aplicaciones de Aprendizaje automático con Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="a4257-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="a4257-244">Spark con aprendizaje automático: Use Spark en HDInsight toopredict de resultados de la inspección de alimentos</span><span class="sxs-lookup"><span data-stu-id="a4257-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="a4257-245">Streaming con Spark: uso de Spark en HDInsight para compilar aplicaciones de streaming en tiempo real</span><span class="sxs-lookup"><span data-stu-id="a4257-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="a4257-246">Análisis del registro del sitio web con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="a4257-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="a4257-247">Creación y ejecución de aplicaciones</span><span class="sxs-lookup"><span data-stu-id="a4257-247">Create and run applications</span></span>
* [<span data-ttu-id="a4257-248">Crear una aplicación independiente con Scala</span><span class="sxs-lookup"><span data-stu-id="a4257-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="a4257-249">Ejecutar trabajos de forma remota en un clúster de Spark mediante Livy</span><span class="sxs-lookup"><span data-stu-id="a4257-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="a4257-250">Herramientas y extensiones</span><span class="sxs-lookup"><span data-stu-id="a4257-250">Tools and extensions</span></span>
* [<span data-ttu-id="a4257-251">Usar el complemento de herramientas de HDInsight para toocreate IntelliJ IDEA y enviar solicitudes de Spark Scala</span><span class="sxs-lookup"><span data-stu-id="a4257-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="a4257-252">Usar complemento Herramientas de HDInsight para aplicaciones de IDEA IntelliJ toodebug Spark de forma remota</span><span class="sxs-lookup"><span data-stu-id="a4257-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="a4257-253">Uso de cuadernos de Zeppelin con un clúster Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="a4257-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="a4257-254">Uso de paquetes externos con cuadernos de Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="a4257-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="a4257-255">Instale Jupyter en el equipo y conecte tooan clúster de HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="a4257-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="a4257-256">Administración de recursos</span><span class="sxs-lookup"><span data-stu-id="a4257-256">Manage resources</span></span>
* [<span data-ttu-id="a4257-257">Administrar los recursos de clúster de hello Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="a4257-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="a4257-258">Track and debug jobs running on an Apache Spark cluster in HDInsight (Seguimiento y depuración de trabajos que se ejecutan en un clúster de Apache Spark en HDInsight)</span><span class="sxs-lookup"><span data-stu-id="a4257-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
