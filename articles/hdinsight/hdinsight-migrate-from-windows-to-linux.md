---
title: "Migración desde HDInsight basado en Windows a HDInsight basado en Linux: Azure | Microsoft Docs"
description: "Más información sobre cómo migrar desde un clúster de HDInsight basado en Windows a un clúster de HDInsight basado en Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 35e80efe27081cd43243f488fa60447b76a20c32
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/03/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a><span data-ttu-id="3cffe-103">Migración desde un clúster de HDInsight basado en Windows a un clúster basado en Linux</span><span class="sxs-lookup"><span data-stu-id="3cffe-103">Migrate from a Windows-based HDInsight cluster to a Linux-based cluster</span></span>

<span data-ttu-id="3cffe-104">En este documento se ofrece información sobre las diferencias entre HDInsight en Windows y en Linux, e instrucciones sobre cómo migrar cargas de trabajo existentes a un clúster basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-104">This document provides details on the differences between HDInsight on Windows and Linux, and guidance on how to migrate existing workloads to a Linux-based cluster.</span></span>

<span data-ttu-id="3cffe-105">Si bien HDInsight basado en Windows permite usar fácilmente Hadoop en la nube, tal vez necesite migrar a un clúster basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-105">While Windows-based HDInsight provides an easy way to use Hadoop in the cloud, you may need to migrate to a Linux-based cluster.</span></span> <span data-ttu-id="3cffe-106">Por ejemplo, para aprovechar las ventajas de las herramientas basadas en Linux y las tecnologías que son necesarias para su solución.</span><span class="sxs-lookup"><span data-stu-id="3cffe-106">For example, to take advantage of Linux-based tools and technologies that are required for your solution.</span></span> <span data-ttu-id="3cffe-107">Muchos de los elementos del ecosistema de Hadoop se desarrollan en sistemas basados en Linux, y puede que no estén disponibles para su uso con HDInsight basado en Windows.</span><span class="sxs-lookup"><span data-stu-id="3cffe-107">Many things in the Hadoop ecosystem are developed on Linux-based systems, and may not be available for use with Windows-based HDInsight.</span></span> <span data-ttu-id="3cffe-108">Además, en muchos libros, vídeos y otros materiales de aprendizaje se da por sentado que cuando se trabaja con Hadoop se usa un sistema Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-108">Additionally, many books, videos, and other training material assume that you are using a Linux system when working with Hadoop.</span></span>

> [!NOTE]
> <span data-ttu-id="3cffe-109">Los clústeres de HDInsight usan Ubuntu Long Term Support (LTS) como el sistema operativo de los nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-109">HDInsight clusters use Ubuntu long-term support (LTS) as the operating system for the nodes in the cluster.</span></span> <span data-ttu-id="3cffe-110">Para obtener información sobre la versión de Ubuntu disponible con HDInsight, junto con otra información de control de versiones del componente, consulte el artículo sobre [versiones de componentes de HDInsight](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-110">For information on the version of Ubuntu available with HDInsight, along with other component versioning information, see [HDInsight component versions](hdinsight-component-versioning.md).</span></span>

## <a name="migration-tasks"></a><span data-ttu-id="3cffe-111">Tareas de migración</span><span class="sxs-lookup"><span data-stu-id="3cffe-111">Migration tasks</span></span>

<span data-ttu-id="3cffe-112">El flujo de trabajo general de migración es el siguiente.</span><span class="sxs-lookup"><span data-stu-id="3cffe-112">The general workflow for migration is as follows.</span></span>

![Diagrama de flujo de trabajo de migración](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. <span data-ttu-id="3cffe-114">Leer cada sección de este documento para entender los cambios que pueden ser necesarios al migrar el flujo de trabajo existente, trabajos, etc. a un clúster basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-114">Read each section of this document to understand changes that may be required when migrating your existing workflow, jobs, etc. to a Linux-based cluster.</span></span>

2. <span data-ttu-id="3cffe-115">Cree un clúster basado en Linux como entorno de control de calidad o de pruebas.</span><span class="sxs-lookup"><span data-stu-id="3cffe-115">Create a Linux-based cluster as a test/quality assurance environment.</span></span> <span data-ttu-id="3cffe-116">Para obtener más información sobre cómo crear un clúster basado en Linux, consulte [Creación de clústeres de Hadoop basados en Linux en HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-116">For more information on creating a Linux-based cluster, see [Create Linux-based clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span></span>

3. <span data-ttu-id="3cffe-117">Copie los trabajos, los orígenes de datos y los receptores existentes en el nuevo entorno.</span><span class="sxs-lookup"><span data-stu-id="3cffe-117">Copy existing jobs, data sources, and sinks to the new environment.</span></span>

4. <span data-ttu-id="3cffe-118">Realice pruebas de validación para asegurarse de que los trabajos funcionan como se esperaba en el nuevo clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-118">Perform validation testing to make sure that your jobs work as expected on the new cluster.</span></span>

<span data-ttu-id="3cffe-119">Cuando haya comprobado que todo funciona según lo esperado, programe el tiempo de inactividad para la migración.</span><span class="sxs-lookup"><span data-stu-id="3cffe-119">Once you have verified that everything works as expected, schedule downtime for the migration.</span></span> <span data-ttu-id="3cffe-120">Durante este tiempo de inactividad, realice las acciones siguientes:</span><span class="sxs-lookup"><span data-stu-id="3cffe-120">During this downtime, perform the following actions:</span></span>

1. <span data-ttu-id="3cffe-121">Haga copia de seguridad de todos los datos transitorios almacenados localmente en los nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-121">Back up any transient data stored locally on the cluster nodes.</span></span> <span data-ttu-id="3cffe-122">Por ejemplo, si tiene datos que se almacenan directamente en un nodo principal.</span><span class="sxs-lookup"><span data-stu-id="3cffe-122">For example, if you have data stored directly on a head node.</span></span>

2. <span data-ttu-id="3cffe-123">Elimine el clúster basado en Windows.</span><span class="sxs-lookup"><span data-stu-id="3cffe-123">Delete the Windows-based cluster.</span></span>

3. <span data-ttu-id="3cffe-124">Cree un clúster basado en Linux con el mismo almacén de datos predeterminado que se utilizaba en el clúster basado en Windows.</span><span class="sxs-lookup"><span data-stu-id="3cffe-124">Create a Linux-based cluster using the same default data store that the Windows-based cluster used.</span></span> <span data-ttu-id="3cffe-125">El clúster basado en Linux puede seguir trabajando con sus datos de producción existentes.</span><span class="sxs-lookup"><span data-stu-id="3cffe-125">The Linux-based cluster can continue working against your existing production data.</span></span>

4. <span data-ttu-id="3cffe-126">Importe los datos transitorios cuya copia de seguridad realizó.</span><span class="sxs-lookup"><span data-stu-id="3cffe-126">Import any transient data you backed up.</span></span>

5. <span data-ttu-id="3cffe-127">Inicie trabajos o continúe el procesamiento con el nuevo clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-127">Start jobs/continue processing using the new cluster.</span></span>

### <a name="copy-data-to-the-test-environment"></a><span data-ttu-id="3cffe-128">Copia de datos en el entorno de prueba</span><span class="sxs-lookup"><span data-stu-id="3cffe-128">Copy data to the test environment</span></span>

<span data-ttu-id="3cffe-129">Existen muchos métodos para copiar los datos y los trabajos, pero los dos que se describen en esta sección son los métodos más sencillos para mover archivos directamente a un clúster de prueba.</span><span class="sxs-lookup"><span data-stu-id="3cffe-129">There are many methods to copy the data and jobs, however the two discussed in this section are the simplest methods to directly move files to a test cluster.</span></span>

#### <a name="hdfs-copy"></a><span data-ttu-id="3cffe-130">Copia de HDFS</span><span class="sxs-lookup"><span data-stu-id="3cffe-130">HDFS copy</span></span>

<span data-ttu-id="3cffe-131">Siga estos pasos para copiar datos desde el clúster de producción al clúster de prueba.</span><span class="sxs-lookup"><span data-stu-id="3cffe-131">Use the following steps to copy data from the production cluster to the test cluster.</span></span> <span data-ttu-id="3cffe-132">Estos pasos utilizan la utilidad `hdfs dfs` que se incluye con HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3cffe-132">These steps use the `hdfs dfs` utility that is included with HDInsight.</span></span>

1. <span data-ttu-id="3cffe-133">Busque la información de contenedor predeterminado y de cuenta de almacenamiento del clúster existente.</span><span class="sxs-lookup"><span data-stu-id="3cffe-133">Find the storage account and default container information for your existing cluster.</span></span> <span data-ttu-id="3cffe-134">En el ejemplo siguiente, se usa PowerShell para recuperar esta información:</span><span class="sxs-lookup"><span data-stu-id="3cffe-134">The following example uses PowerShell to retrieve this information:</span></span>

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. <span data-ttu-id="3cffe-135">Para crear un entorno de prueba, siga los pasos indicados en el documento Creación de clústeres basados en Linux en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3cffe-135">To create a test environment, follow the steps in the Create Linux-based clusters in HDInsight document.</span></span> <span data-ttu-id="3cffe-136">Deténgase antes de crear el clúster y, en su lugar, seleccione **Configuración opcional**.</span><span class="sxs-lookup"><span data-stu-id="3cffe-136">Stop before creating the cluster, and instead select **Optional Configuration**.</span></span>

3. <span data-ttu-id="3cffe-137">En la hoja Configuración opcional, seleccione **Cuentas de almacenamiento vinculadas**.</span><span class="sxs-lookup"><span data-stu-id="3cffe-137">From the Optional Configuration blade, select **Linked Storage Accounts**.</span></span>

4. <span data-ttu-id="3cffe-138">Seleccione **Agregar una clave de almacenamiento**y, cuando se le pida, la cuenta de almacenamiento que devolvió el script de PowerShell en el paso 1.</span><span class="sxs-lookup"><span data-stu-id="3cffe-138">Select **Add a storage key**, and when prompted, select the storage account that was returned by the PowerShell script in step 1.</span></span> <span data-ttu-id="3cffe-139">Haga clic en la opción **Seleccionar** de cada hoja.</span><span class="sxs-lookup"><span data-stu-id="3cffe-139">Click **Select** on each blade.</span></span> <span data-ttu-id="3cffe-140">Por último, cree el clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-140">Finally, create the cluster.</span></span>

5. <span data-ttu-id="3cffe-141">Una vez creado el clúster, conéctese a él utilizando **SSH**.</span><span class="sxs-lookup"><span data-stu-id="3cffe-141">Once the cluster has been created, connect to it using **SSH.**</span></span> <span data-ttu-id="3cffe-142">Para más información, consulte [Uso SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-142">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

6. <span data-ttu-id="3cffe-143">En la sesión de SSH, use el siguiente comando para copiar los archivos de la cuenta de almacenamiento vinculada a la nueva cuenta de almacenamiento predeterminada.</span><span class="sxs-lookup"><span data-stu-id="3cffe-143">From the SSH session, use the following command to copy files from the linked storage account to the new default storage account.</span></span> <span data-ttu-id="3cffe-144">Reemplace el CONTENEDOR con la información del contenedor devuelta por PowerShell.</span><span class="sxs-lookup"><span data-stu-id="3cffe-144">Replace CONTAINER with the container information returned by PowerShell.</span></span> <span data-ttu-id="3cffe-145">Reemplace __CUENTA__ con el nombre de cuenta.</span><span class="sxs-lookup"><span data-stu-id="3cffe-145">Replace __ACCOUNT__ with the account name.</span></span> <span data-ttu-id="3cffe-146">Reemplace la ruta de acceso a datos por la ruta de acceso a un archivo de datos.</span><span class="sxs-lookup"><span data-stu-id="3cffe-146">Replace the path to data with the path to a data file.</span></span>

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > <span data-ttu-id="3cffe-147">Si la estructura de directorios que contiene los datos no existe en el entorno de prueba, puede crearla con el comando siguiente:</span><span class="sxs-lookup"><span data-stu-id="3cffe-147">If the directory structure that contains the data does not exist on the test environment, you can create it using the following command:</span></span>

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    <span data-ttu-id="3cffe-148">El conmutador `-p` permite crear todos los directorios de la ruta de acceso.</span><span class="sxs-lookup"><span data-stu-id="3cffe-148">The `-p` switch enables the creation of all directories in  the path.</span></span>

#### <a name="direct-copy-between-blobs-in-azure-storage"></a><span data-ttu-id="3cffe-149">Copia directa entre blobs de Azure Storage</span><span class="sxs-lookup"><span data-stu-id="3cffe-149">Direct copy between blobs in Azure Storage</span></span>

<span data-ttu-id="3cffe-150">También puede utilizar el cmdlet de Azure PowerShell `Start-AzureStorageBlobCopy` para copiar blobs entre cuentas de almacenamiento fuera de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3cffe-150">Alternatively, you may want to use the `Start-AzureStorageBlobCopy` Azure PowerShell cmdlet to copy blobs between storage accounts outside of HDInsight.</span></span> <span data-ttu-id="3cffe-151">Para más información, consulte la sección Administración de blobs de Azure de Uso de Azure PowerShell con Almacenamiento de Azure.</span><span class="sxs-lookup"><span data-stu-id="3cffe-151">For more information, see the How to manage Azure Blobs section of Using Azure PowerShell with Azure Storage.</span></span>

## <a name="client-side-technologies"></a><span data-ttu-id="3cffe-152">Tecnologías de cliente</span><span class="sxs-lookup"><span data-stu-id="3cffe-152">Client-side technologies</span></span>

<span data-ttu-id="3cffe-153">Las tecnologías en el lado del cliente como [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [CLI de Azure](../cli-install-nodejs.md) o [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) siguen funcionando con clústeres basados en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-153">Client-side technologies such as [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), or the [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) continue to work Linux-based clusters.</span></span> <span data-ttu-id="3cffe-154">Estas tecnologías se basan en API de REST que son iguales en los dos tipos del SO del clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-154">These technologies rely on REST APIs that are the same across both cluster OS types.</span></span>

## <a name="server-side-technologies"></a><span data-ttu-id="3cffe-155">Tecnologías de servidor</span><span class="sxs-lookup"><span data-stu-id="3cffe-155">Server-side technologies</span></span>

<span data-ttu-id="3cffe-156">En la tabla siguiente se ofrece orientación sobre cómo migrar componentes de servidor que son específicos de Windows.</span><span class="sxs-lookup"><span data-stu-id="3cffe-156">The following table provides guidance on migrating server-side components that are Windows-specific.</span></span>

| <span data-ttu-id="3cffe-157">Si utiliza esta tecnología...</span><span class="sxs-lookup"><span data-stu-id="3cffe-157">If you are using this technology...</span></span> | <span data-ttu-id="3cffe-158">Realice esta acción...</span><span class="sxs-lookup"><span data-stu-id="3cffe-158">Take this action...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-159">**PowerShell** (scripts de servidor, incluidas las acciones de script que se usan durante la creación del clúster)</span><span class="sxs-lookup"><span data-stu-id="3cffe-159">**PowerShell** (server-side scripts, including Script Actions used during cluster creation)</span></span> |<span data-ttu-id="3cffe-160">Vuelva a escribirlos como scripts de Bash.</span><span class="sxs-lookup"><span data-stu-id="3cffe-160">Rewrite as Bash scripts.</span></span> <span data-ttu-id="3cffe-161">Para acciones de script, consulte [Personalización de clústeres de HDInsight mediante la acción de scripts (Linux)](hdinsight-hadoop-customize-cluster-linux.md) y [Desarrollo de la acción de script con HDInsight](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-161">For Script Actions, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span> |
| <span data-ttu-id="3cffe-162">**CLI de Azure** (scripts de servidor)</span><span class="sxs-lookup"><span data-stu-id="3cffe-162">**Azure CLI** (server-side scripts)</span></span> |<span data-ttu-id="3cffe-163">Mientras que la CLI de Azure está disponible en Linux, no viene preinstalada en los nodos principales del clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3cffe-163">While the Azure CLI is available on Linux, it does not come pre-installed on the HDInsight cluster head nodes.</span></span> <span data-ttu-id="3cffe-164">Para obtener más información sobre la instalación de la CLI de Azure, consulte [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli) (Introducción a la CLI de Azure 2.0).</span><span class="sxs-lookup"><span data-stu-id="3cffe-164">For more information on installing the Azure CLI, see [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span></span> |
| <span data-ttu-id="3cffe-165">**Componentes de .NET**</span><span class="sxs-lookup"><span data-stu-id="3cffe-165">**.NET components**</span></span> |<span data-ttu-id="3cffe-166">.NET no es compatible con HDInsight basado en Linux a través de [Mono](https://mono-project.com).</span><span class="sxs-lookup"><span data-stu-id="3cffe-166">.NET is supported on Linux-based HDInsight through [Mono](https://mono-project.com).</span></span> <span data-ttu-id="3cffe-167">Para obtener más información, consulte [Migración de soluciones .​NE​T para HDInsight basado en ​Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-167">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span> |
| <span data-ttu-id="3cffe-168">**Componentes de Win32 o de otras tecnologías de Windows**</span><span class="sxs-lookup"><span data-stu-id="3cffe-168">**Win32 components or other Windows-only technology**</span></span> |<span data-ttu-id="3cffe-169">Las indicaciones dependen del componente o tecnología.</span><span class="sxs-lookup"><span data-stu-id="3cffe-169">Guidance depends on the component or technology.</span></span> <span data-ttu-id="3cffe-170">Es posible que encuentre una versión compatible con Linux, o tal vez tenga que encontrar una solución alternativa o volver escribir este componente.</span><span class="sxs-lookup"><span data-stu-id="3cffe-170">You may be able to find a version that is compatible with Linux, or you may need to find an alternate solution or rewrite this component.</span></span> |

> [!IMPORTANT]
> <span data-ttu-id="3cffe-171">El SDK de administración de HDInsight no es totalmente compatible con Mono.</span><span class="sxs-lookup"><span data-stu-id="3cffe-171">The HDInsight management SDK is not fully compatible with Mono.</span></span> <span data-ttu-id="3cffe-172">En este caso, no debería usarse como parte de soluciones implementadas en el clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3cffe-172">It should not be used as part of solutions deployed to the HDInsight cluster at this time.</span></span>

## <a name="cluster-creation"></a><span data-ttu-id="3cffe-173">Creación de clústeres</span><span class="sxs-lookup"><span data-stu-id="3cffe-173">Cluster creation</span></span>

<span data-ttu-id="3cffe-174">Esta sección ofrece información sobre las diferencias en la creación de clústeres.</span><span class="sxs-lookup"><span data-stu-id="3cffe-174">This section provides information on differences in cluster creation.</span></span>

### <a name="ssh-user"></a><span data-ttu-id="3cffe-175">Usuario de SSH</span><span class="sxs-lookup"><span data-stu-id="3cffe-175">SSH User</span></span>

<span data-ttu-id="3cffe-176">Los clústeres de HDInsight basados en Linux usan el protocolo **Secure Shell (SSH)** para proporcionar acceso remoto a los nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-176">Linux-based HDInsight clusters use the **Secure Shell (SSH)** protocol to provide remote access to the cluster nodes.</span></span> <span data-ttu-id="3cffe-177">A diferencia de Escritorio remoto para clústeres basados en Windows, la mayoría de clientes de SSH no ofrece experiencia de usuario gráfica.</span><span class="sxs-lookup"><span data-stu-id="3cffe-177">Unlike Remote Desktop for Windows-based clusters, most SSH clients do not provide a graphical user experience.</span></span> <span data-ttu-id="3cffe-178">En su lugar, los clientes de SSH ofrecen una línea de comandos que le permite ejecutar comandos en el clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-178">Instead, SSH clients provide a command line that allows you to run commands on the cluster.</span></span> <span data-ttu-id="3cffe-179">Algunos clientes (como [MobaXterm](http://mobaxterm.mobatek.net/)) ofrecen un explorador gráfico del sistema de archivos, además de una línea de comandos remota.</span><span class="sxs-lookup"><span data-stu-id="3cffe-179">Some clients (such as [MobaXterm](http://mobaxterm.mobatek.net/)) provide a graphical file system browser in addition to a remote command line.</span></span>

<span data-ttu-id="3cffe-180">Durante la creación del clúster, debe especificar un usuario SSH y una **contraseña**, o bien un **certificado de clave pública** para la autenticación.</span><span class="sxs-lookup"><span data-stu-id="3cffe-180">During cluster creation, you must provide an SSH user and either a **password** or **public key certificate** for authentication.</span></span>

<span data-ttu-id="3cffe-181">Se recomienda usar el certificado de clave pública, ya que es más seguro que usar una contraseña.</span><span class="sxs-lookup"><span data-stu-id="3cffe-181">We recommend using Public key certificate, as it is more secure than using a password.</span></span> <span data-ttu-id="3cffe-182">La autenticación de certificado funciona generando un par de claves pública y privada con signo y especificando la clave pública al crear el clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-182">Certificate authentication works by generating a signed public/private key pair, then providing the public key when creating the cluster.</span></span> <span data-ttu-id="3cffe-183">Al conectarse al servidor mediante SSH, la clave privada en el cliente proporciona autenticación para la conexión.</span><span class="sxs-lookup"><span data-stu-id="3cffe-183">When connecting to the server using SSH, the private key on the client provides authentication for the connection.</span></span>

<span data-ttu-id="3cffe-184">Para más información, consulte [Uso SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-184">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

### <a name="cluster-customization"></a><span data-ttu-id="3cffe-185">Personalización del clúster</span><span class="sxs-lookup"><span data-stu-id="3cffe-185">Cluster customization</span></span>

<span data-ttu-id="3cffe-186">**acciones de script** se utilizan con clústeres basados en Linux y deben escribirse en script de Bash.</span><span class="sxs-lookup"><span data-stu-id="3cffe-186">**Script Actions** used with Linux-based clusters must be written in Bash script.</span></span> <span data-ttu-id="3cffe-187">Aunque las acciones de script se pueden utilizar durante la creación del clúster, en el caso de clústeres basados en Linux también pueden usarse para realizar la personalización cuando un clúster está activo y en ejecución.</span><span class="sxs-lookup"><span data-stu-id="3cffe-187">While Script Actions can be used during cluster creation, for Linux-based clusters they can also be used to perform customization after a cluster is up and running.</span></span> <span data-ttu-id="3cffe-188">Para más información, consulte [Personalización de clústeres de HDInsight mediante la acción de scripts (Linux)](hdinsight-hadoop-customize-cluster-linux.md) y [Desarrollo de la acción de script con HDInsight](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-188">For more information, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

<span data-ttu-id="3cffe-189">Otra característica de personalización es **arranque**.</span><span class="sxs-lookup"><span data-stu-id="3cffe-189">Another customization feature is **bootstrap**.</span></span> <span data-ttu-id="3cffe-190">En el caso de clústeres de Windows, esta función permite especificar la ubicación de bibliotecas adicionales para su uso con Hive.</span><span class="sxs-lookup"><span data-stu-id="3cffe-190">For Windows clusters, this feature allows you to specify the location of additional libraries for use with Hive.</span></span> <span data-ttu-id="3cffe-191">Después de crear el clúster, estas bibliotecas están automáticamente disponibles para usarse con consultas de Hive sin necesidad de utilizar `ADD JAR`.</span><span class="sxs-lookup"><span data-stu-id="3cffe-191">After cluster creation, these libraries are automatically available for use with Hive queries without the need to use `ADD JAR`.</span></span>

<span data-ttu-id="3cffe-192">La función de arranque para clústeres basados en Linux no proporciona esta funcionalidad.</span><span class="sxs-lookup"><span data-stu-id="3cffe-192">The Bootstrap feature for Linux-based clusters does not provide this functionality.</span></span> <span data-ttu-id="3cffe-193">En su lugar, use la acción de script que se documenta en [Incorporación de bibliotecas de Hive durante la creación del clúster](hdinsight-hadoop-add-hive-libraries.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-193">Instead, use script action documented in [Add Hive libraries during cluster creation](hdinsight-hadoop-add-hive-libraries.md).</span></span>

### <a name="virtual-networks"></a><span data-ttu-id="3cffe-194">Redes virtuales</span><span class="sxs-lookup"><span data-stu-id="3cffe-194">Virtual Networks</span></span>

<span data-ttu-id="3cffe-195">Los clústeres de HDInsight basados en Windows solo funcionan con redes virtuales clásicas, mientras que los clústeres HDInsight basados en Linux requieren redes virtuales del Administrador de recursos.</span><span class="sxs-lookup"><span data-stu-id="3cffe-195">Windows-based HDInsight clusters only work with Classic Virtual Networks, while Linux-based HDInsight clusters require Resource Manager Virtual Networks.</span></span> <span data-ttu-id="3cffe-196">Si tiene recursos en una red virtual clásica a la que debe conectarse el clúster de HDInsight en Linux, consulte [Conexión de una red virtual clásica a una red virtual del Administrador de recursos](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-196">If you have resources in a Classic Virtual Network that the Linux-HDInsight cluster must connect to, see [Connecting a Classic Virtual Network to a Resource Manager Virtual Network](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span></span>

<span data-ttu-id="3cffe-197">Para obtener más información sobre los requisitos de configuración para usar redes virtuales de Azure con HDInsight, consulte [Extensión de las funcionalidades de HDInsight con una red virtual](hdinsight-extend-hadoop-virtual-network.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-197">For more information on configuration requirements for using Azure Virtual Networks with HDInsight, see [Extend HDInsight capabilities by using a Virtual Network](hdinsight-extend-hadoop-virtual-network.md).</span></span>

## <a name="management-and-monitoring"></a><span data-ttu-id="3cffe-198">Administración y supervisión</span><span class="sxs-lookup"><span data-stu-id="3cffe-198">Management and monitoring</span></span>

<span data-ttu-id="3cffe-199">Es posible que muchas de las interfaces de usuario web que haya utilizado con HDInsight basado en Windows, como el historial de trabajos o la interfaz de usuario de Yarn, estén disponibles a través de Ambari.</span><span class="sxs-lookup"><span data-stu-id="3cffe-199">Many of the web UIs you may have used with Windows-based HDInsight, such as Job History or Yarn UI, are available through Ambari.</span></span> <span data-ttu-id="3cffe-200">Además, la vista Ambari Hive ofrece una forma de ejecutar consultas de Hive mediante el explorador web.</span><span class="sxs-lookup"><span data-stu-id="3cffe-200">In addition, the Ambari Hive View provides a way to run Hive queries using your web browser.</span></span> <span data-ttu-id="3cffe-201">La interfaz de usuario web de Ambari está disponible en los clústeres basados en Linux que crea en https://CLUSTERNAME.azurehdinsight.net.</span><span class="sxs-lookup"><span data-stu-id="3cffe-201">The Ambari Web UI is available on Linux-based clusters at https://CLUSTERNAME.azurehdinsight.net.</span></span>

<span data-ttu-id="3cffe-202">Para más información sobre cómo trabajar con Ambari, consulte los documentos siguientes:</span><span class="sxs-lookup"><span data-stu-id="3cffe-202">For more information on working with Ambari, see the following documents:</span></span>

* [<span data-ttu-id="3cffe-203">Web de Ambari</span><span class="sxs-lookup"><span data-stu-id="3cffe-203">Ambari Web</span></span>](hdinsight-hadoop-manage-ambari.md)
* [<span data-ttu-id="3cffe-204">API de REST de Ambari</span><span class="sxs-lookup"><span data-stu-id="3cffe-204">Ambari REST API</span></span>](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a><span data-ttu-id="3cffe-205">Alertas de Ambari</span><span class="sxs-lookup"><span data-stu-id="3cffe-205">Ambari Alerts</span></span>

<span data-ttu-id="3cffe-206">Ambari tiene un sistema de alertas que puede indicarle posibles problemas con el clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-206">Ambari has an alert system that can tell you of potential problems with the cluster.</span></span> <span data-ttu-id="3cffe-207">Las alertas aparecen como entradas en rojo o amarillo en la interfaz de usuario de Web de Ambari, pero también se pueden recuperar a través de la API de REST.</span><span class="sxs-lookup"><span data-stu-id="3cffe-207">Alerts appear as red or yellow entries in the Ambari Web UI, however you can also retrieve them through the REST API.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="3cffe-208">Las alertas de Ambari indican que *puede* que haya un problema, no que *exista* realmente.</span><span class="sxs-lookup"><span data-stu-id="3cffe-208">Ambari alerts indicate that there *may* be a problem, not that there *is* a problem.</span></span> <span data-ttu-id="3cffe-209">Por ejemplo, puede recibir una alerta que indica que no se puede tener acceso a HiveServer2, aunque pueda tener acceso a él normalmente.</span><span class="sxs-lookup"><span data-stu-id="3cffe-209">For example, you may receive an alert that HiveServer2 cannot be accessed, even though you can access it normally.</span></span>
>
> <span data-ttu-id="3cffe-210">Las alertas se implementan como consultas basadas en intervalos en un servicio y esperan una respuesta en un plazo de tiempo específico.</span><span class="sxs-lookup"><span data-stu-id="3cffe-210">Many alerts are implemented as interval-based queries against a service, and expect a response within a specific time frame.</span></span> <span data-ttu-id="3cffe-211">Por lo que la alerta no necesariamente significa que el servicio no funcione, sino que no devuelve resultados en el plazo previsto.</span><span class="sxs-lookup"><span data-stu-id="3cffe-211">So the alert doesn't necessarily mean that the service is down, just that it didn't return results within the expected time frame.</span></span>

<span data-ttu-id="3cffe-212">Debería evaluar si una alerta se ha venido produciendo durante un período prolongado o si refleja problemas de los usuarios que se han registrado antes de realizar ninguna acción en el servicio.</span><span class="sxs-lookup"><span data-stu-id="3cffe-212">You should evaluate whether an alert has been occurring for an extended period, or mirrors user problems that have been reported before taking action on it.</span></span>

## <a name="file-system-locations"></a><span data-ttu-id="3cffe-213">Ubicaciones del sistema de archivos</span><span class="sxs-lookup"><span data-stu-id="3cffe-213">File system locations</span></span>

<span data-ttu-id="3cffe-214">El sistema de archivos de clústeres de Linux se distribuye de manera diferente que en los clústeres de HDInsight basado en Windows.</span><span class="sxs-lookup"><span data-stu-id="3cffe-214">The Linux cluster file system is laid out differently than Windows-based HDInsight clusters.</span></span> <span data-ttu-id="3cffe-215">Utilice la siguiente tabla para encontrar archivos de uso habitual.</span><span class="sxs-lookup"><span data-stu-id="3cffe-215">Use the following table to find commonly used files.</span></span>

| <span data-ttu-id="3cffe-216">Hay que encontrar...</span><span class="sxs-lookup"><span data-stu-id="3cffe-216">I need to find...</span></span> | <span data-ttu-id="3cffe-217">Se encuentra...</span><span class="sxs-lookup"><span data-stu-id="3cffe-217">It is located...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-218">Configuración</span><span class="sxs-lookup"><span data-stu-id="3cffe-218">Configuration</span></span> |<span data-ttu-id="3cffe-219">`/etc`.</span><span class="sxs-lookup"><span data-stu-id="3cffe-219">`/etc`.</span></span> <span data-ttu-id="3cffe-220">Por ejemplo, `/etc/hadoop/conf/core-site.xml`</span><span class="sxs-lookup"><span data-stu-id="3cffe-220">For example, `/etc/hadoop/conf/core-site.xml`</span></span> |
| <span data-ttu-id="3cffe-221">Archivos de registro</span><span class="sxs-lookup"><span data-stu-id="3cffe-221">Log files</span></span> |`/var/logs` |
| <span data-ttu-id="3cffe-222">HortonWorks Data Platform (HDP)</span><span class="sxs-lookup"><span data-stu-id="3cffe-222">Hortonworks Data Platform (HDP)</span></span> |<span data-ttu-id="3cffe-223">`/usr/hdp`Aquí hay dos directorios ubicados, uno que corresponde a la versión HDP actual y `current`.</span><span class="sxs-lookup"><span data-stu-id="3cffe-223">`/usr/hdp`.There are two directories located here, one that is the current HDP version and `current`.</span></span> <span data-ttu-id="3cffe-224">El directorio `current` contiene los vínculos simbólicos a archivos y directorios que se encuentran en el directorio del número de versión.</span><span class="sxs-lookup"><span data-stu-id="3cffe-224">The `current` directory contains symbolic links to files and directories located in the version number directory.</span></span> <span data-ttu-id="3cffe-225">El directorio `current` sirve para acceder cómodamente a archivos HDP, ya que el número de versión cambia conforme se actualiza la versión de HDP.</span><span class="sxs-lookup"><span data-stu-id="3cffe-225">The `current` directory is provided as a convenient way of accessing HDP files since the version number changes as the HDP version is updated.</span></span> |
| <span data-ttu-id="3cffe-226">hadoop-streaming.jar</span><span class="sxs-lookup"><span data-stu-id="3cffe-226">hadoop-streaming.jar</span></span> |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

<span data-ttu-id="3cffe-227">Por lo general, si conoce el nombre del archivo, puede utilizar el siguiente comando desde una sesión de SSH para encontrar la ruta de archivo:</span><span class="sxs-lookup"><span data-stu-id="3cffe-227">In general, if you know the name of the file, you can use the following command from an SSH session to find the file path:</span></span>

    find / -name FILENAME 2>/dev/null

<span data-ttu-id="3cffe-228">También puede utilizar caracteres comodín con el nombre de archivo.</span><span class="sxs-lookup"><span data-stu-id="3cffe-228">You can also use wildcards with the file name.</span></span> <span data-ttu-id="3cffe-229">Por ejemplo, `find / -name *streaming*.jar 2>/dev/null` devuelve la ruta de acceso a los archivos JAR que contienen la palabra "streaming" en el nombre de archivo.</span><span class="sxs-lookup"><span data-stu-id="3cffe-229">For example, `find / -name *streaming*.jar 2>/dev/null` returns the path to any jar files that contain the word 'streaming' as part of the file name.</span></span>

## <a name="hive-pig-and-mapreduce"></a><span data-ttu-id="3cffe-230">Hive, Pig y MapReduce</span><span class="sxs-lookup"><span data-stu-id="3cffe-230">Hive, Pig, and MapReduce</span></span>

<span data-ttu-id="3cffe-231">Las cargas de trabajo de Pig y MapReduce son similares en clústeres basados en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-231">Pig and MapReduce workloads are similar on Linux-based clusters.</span></span> <span data-ttu-id="3cffe-232">Sin embargo, los clústeres de HDInsight basados en Linux se pueden crear usando versiones más recientes de Hadoop, Hive y Pig.</span><span class="sxs-lookup"><span data-stu-id="3cffe-232">However, Linux-based HDInsight clusters can be created using newer versions of Hadoop, Hive, and Pig.</span></span> <span data-ttu-id="3cffe-233">Estas diferencias de versión pueden provocar cambios en el funcionamiento de las soluciones existentes.</span><span class="sxs-lookup"><span data-stu-id="3cffe-233">These version differences may introduce changes in how your existing solutions function.</span></span> <span data-ttu-id="3cffe-234">Para obtener más información sobre las versiones de los componentes incluidos en HDInsight, consulte el artículo relativo a las [versiones de componentes de HDInsight](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-234">For more information on the versions of components included with HDInsight, see [HDInsight component versioning](hdinsight-component-versioning.md).</span></span>

<span data-ttu-id="3cffe-235">HDInsight basado en Linux no proporciona funcionalidad de escritorio remoto.</span><span class="sxs-lookup"><span data-stu-id="3cffe-235">Linux-based HDInsight does not provide remote desktop functionality.</span></span> <span data-ttu-id="3cffe-236">En su lugar, puede usar SSH para conectar remotamente con los nodos principales del clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-236">Instead, you can use SSH to remotely connect to the cluster head nodes.</span></span> <span data-ttu-id="3cffe-237">Para obtener más información, vea los documentos siguientes:</span><span class="sxs-lookup"><span data-stu-id="3cffe-237">For more information, see the following documents:</span></span>

* [<span data-ttu-id="3cffe-238">Uso de Hive con SSH</span><span class="sxs-lookup"><span data-stu-id="3cffe-238">Use Hive with SSH</span></span>](hdinsight-hadoop-use-hive-ssh.md)
* [<span data-ttu-id="3cffe-239">Uso de Pig con SSH</span><span class="sxs-lookup"><span data-stu-id="3cffe-239">Use Pig with SSH</span></span>](hdinsight-hadoop-use-pig-ssh.md)
* [<span data-ttu-id="3cffe-240">Uso de MapReduce con SSH</span><span class="sxs-lookup"><span data-stu-id="3cffe-240">Use MapReduce with SSH</span></span>](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a><span data-ttu-id="3cffe-241">Hive</span><span class="sxs-lookup"><span data-stu-id="3cffe-241">Hive</span></span>

> [!IMPORTANT]
> <span data-ttu-id="3cffe-242">Si utiliza una tienda de metadatos de Hive externa, debe hacer una copia de seguridad de la tienda de metadatos antes de usarla con HDInsight basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-242">If you use an external Hive metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="3cffe-243">HDInsight basado en Linux está disponible con las versiones más recientes de Hive, lo que puede provocar incompatibilidades con las tiendas de metadatos creadas con versiones anteriores.</span><span class="sxs-lookup"><span data-stu-id="3cffe-243">Linux-based HDInsight is available with newer versions of Hive, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="3cffe-244">El gráfico siguiente ofrece orientación sobre cómo migrar las cargas de trabajo de Hive.</span><span class="sxs-lookup"><span data-stu-id="3cffe-244">The following chart provides guidance on migrating your Hive workloads.</span></span>

| <span data-ttu-id="3cffe-245">En basado en Windows, se usa...</span><span class="sxs-lookup"><span data-stu-id="3cffe-245">On Windows-based, I use...</span></span> | <span data-ttu-id="3cffe-246">En basado en Linux...</span><span class="sxs-lookup"><span data-stu-id="3cffe-246">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-247">**Editor de Hive**</span><span class="sxs-lookup"><span data-stu-id="3cffe-247">**Hive Editor**</span></span> |[<span data-ttu-id="3cffe-248">Vista de Hive en Ambari</span><span class="sxs-lookup"><span data-stu-id="3cffe-248">Hive View in Ambari</span></span>](hdinsight-hadoop-use-hive-ambari-view.md) |
| <span data-ttu-id="3cffe-249">`set hive.execution.engine=tez;` para habilitar Tez</span><span class="sxs-lookup"><span data-stu-id="3cffe-249">`set hive.execution.engine=tez;` to enable Tez</span></span> |<span data-ttu-id="3cffe-250">Tez es el motor de ejecución predeterminado para clústeres basados en Linux, por lo que ya no se necesita la instrucción set.</span><span class="sxs-lookup"><span data-stu-id="3cffe-250">Tez is the default execution engine for Linux-based clusters, so the set statement is no longer needed.</span></span> |
| <span data-ttu-id="3cffe-251">Funciones definidas por el usuario de C#</span><span class="sxs-lookup"><span data-stu-id="3cffe-251">C# user-defined functions</span></span> | <span data-ttu-id="3cffe-252">Para obtener información sobre cómo validar los componentes de C# con HDInsight basado en Linux, consulte [Migración de soluciones .​NE​T para HDInsight basado en ​Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="3cffe-252">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="3cffe-253">Scripts o archivos CMD en el servidor que se invoca como parte de un trabajo de Hive</span><span class="sxs-lookup"><span data-stu-id="3cffe-253">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="3cffe-254">se usan scripts de Bash</span><span class="sxs-lookup"><span data-stu-id="3cffe-254">use Bash scripts</span></span> |
| <span data-ttu-id="3cffe-255">`hive` desde Escritorio remoto</span><span class="sxs-lookup"><span data-stu-id="3cffe-255">`hive` command from remote desktop</span></span> |<span data-ttu-id="3cffe-256">Uso de [Beeline](hdinsight-hadoop-use-hive-beeline.md) o [Hive en una sesión de SSH](hdinsight-hadoop-use-hive-ssh.md)</span><span class="sxs-lookup"><span data-stu-id="3cffe-256">Use [Beeline](hdinsight-hadoop-use-hive-beeline.md) or [Hive from an SSH session](hdinsight-hadoop-use-hive-ssh.md)</span></span> |

### <a name="pig"></a><span data-ttu-id="3cffe-257">Pig</span><span class="sxs-lookup"><span data-stu-id="3cffe-257">Pig</span></span>

| <span data-ttu-id="3cffe-258">En basado en Windows, se usa...</span><span class="sxs-lookup"><span data-stu-id="3cffe-258">On Windows-based, I use...</span></span> | <span data-ttu-id="3cffe-259">En basado en Linux...</span><span class="sxs-lookup"><span data-stu-id="3cffe-259">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-260">Funciones definidas por el usuario de C#</span><span class="sxs-lookup"><span data-stu-id="3cffe-260">C# user-defined functions</span></span> | <span data-ttu-id="3cffe-261">Para obtener información sobre cómo validar los componentes de C# con HDInsight basado en Linux, consulte [Migración de soluciones .​NE​T para HDInsight basado en ​Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="3cffe-261">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="3cffe-262">Scripts o archivos CMD en el servidor que se invocan como parte de un trabajo de Pig</span><span class="sxs-lookup"><span data-stu-id="3cffe-262">CMD files or scripts on the server invoked as part of a Pig job</span></span> |<span data-ttu-id="3cffe-263">se usan scripts de Bash</span><span class="sxs-lookup"><span data-stu-id="3cffe-263">use Bash scripts</span></span> |

### <a name="mapreduce"></a><span data-ttu-id="3cffe-264">MapReduce</span><span class="sxs-lookup"><span data-stu-id="3cffe-264">MapReduce</span></span>

| <span data-ttu-id="3cffe-265">En basado en Windows, se usa...</span><span class="sxs-lookup"><span data-stu-id="3cffe-265">On Windows-based, I use...</span></span> | <span data-ttu-id="3cffe-266">En basado en Linux...</span><span class="sxs-lookup"><span data-stu-id="3cffe-266">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-267">Componentes asignadores y reductores de C#</span><span class="sxs-lookup"><span data-stu-id="3cffe-267">C# mapper and reducer components</span></span> | <span data-ttu-id="3cffe-268">Para obtener información sobre cómo validar los componentes de C# con HDInsight basado en Linux, consulte [Migración de soluciones .​NE​T para HDInsight basado en ​Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="3cffe-268">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="3cffe-269">Scripts o archivos CMD en el servidor que se invoca como parte de un trabajo de Hive</span><span class="sxs-lookup"><span data-stu-id="3cffe-269">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="3cffe-270">se usan scripts de Bash</span><span class="sxs-lookup"><span data-stu-id="3cffe-270">use Bash scripts</span></span> |

## <a name="oozie"></a><span data-ttu-id="3cffe-271">Oozie</span><span class="sxs-lookup"><span data-stu-id="3cffe-271">Oozie</span></span>

> [!IMPORTANT]
> <span data-ttu-id="3cffe-272">Si utiliza una tienda de metadatos de Oozie externa, debe hacer una copia de seguridad de la tienda de metadatos antes de usarla con HDInsight basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-272">If you use an external Oozie metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="3cffe-273">HDInsight basado en Linux está disponible con las versiones más recientes de Oozie, lo que puede provocar incompatibilidades con las tiendas de metadatos creadas con versiones anteriores.</span><span class="sxs-lookup"><span data-stu-id="3cffe-273">Linux-based HDInsight is available with newer versions of Oozie, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="3cffe-274">Los flujos de trabajo de Oozie permiten acciones de shell.</span><span class="sxs-lookup"><span data-stu-id="3cffe-274">Oozie workflows allow shell actions.</span></span> <span data-ttu-id="3cffe-275">Las acciones de shell usan el shell predeterminado del sistema operativo para ejecutar comandos de línea de comandos.</span><span class="sxs-lookup"><span data-stu-id="3cffe-275">Shell actions use the default shell for the operating system to run command-line commands.</span></span> <span data-ttu-id="3cffe-276">Si tiene flujos de trabajo de Oozie que se basan en el shell de Windows, debe volver a escribir los flujos de trabajo para que se basen en el entorno de shell de Linux (Bash).</span><span class="sxs-lookup"><span data-stu-id="3cffe-276">If you have Oozie workflows that rely on the Windows shell, you must rewrite the workflows to rely on the Linux shell environment (Bash).</span></span> <span data-ttu-id="3cffe-277">Para obtener más información sobre el uso de acciones de shell con Oozie, consulte [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html) (Extensión de la acción del shell de Oozie).</span><span class="sxs-lookup"><span data-stu-id="3cffe-277">For more information on using shell actions with Oozie, see [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span></span>

<span data-ttu-id="3cffe-278">Si tiene flujos de trabajo de Oozie que se basan en las aplicaciones de C# invocadas a través de acciones de shell, debe validar estas aplicaciones en un entorno de Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-278">If you have Oozie workflows that rely on C# applications invoked through shell actions, you must validate these applications in a Linux environment.</span></span> <span data-ttu-id="3cffe-279">Para obtener más información, consulte [Migración de soluciones .​NE​T para HDInsight basado en ​Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-279">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span>

## <a name="storm"></a><span data-ttu-id="3cffe-280">Storm</span><span class="sxs-lookup"><span data-stu-id="3cffe-280">Storm</span></span>

| <span data-ttu-id="3cffe-281">En basado en Windows, se usa...</span><span class="sxs-lookup"><span data-stu-id="3cffe-281">On Windows-based, I use...</span></span> | <span data-ttu-id="3cffe-282">En basado en Linux...</span><span class="sxs-lookup"><span data-stu-id="3cffe-282">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="3cffe-283">Panel de Storm</span><span class="sxs-lookup"><span data-stu-id="3cffe-283">Storm Dashboard</span></span> |<span data-ttu-id="3cffe-284">El panel de Storm no está disponible.</span><span class="sxs-lookup"><span data-stu-id="3cffe-284">The Storm Dashboard is not available.</span></span> <span data-ttu-id="3cffe-285">Consulte [Implementación y administración de topologías de Storm en HDInsight basado en Linux](hdinsight-storm-deploy-monitor-topology-linux.md) para ver formas de enviar topologías.</span><span class="sxs-lookup"><span data-stu-id="3cffe-285">See [Deploy and Manage Storm topologies on Linux-based HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) for ways to submit topologies</span></span> |
| <span data-ttu-id="3cffe-286">UI de Storm</span><span class="sxs-lookup"><span data-stu-id="3cffe-286">Storm UI</span></span> |<span data-ttu-id="3cffe-287">La interfaz de usuario de Storm está disponible en https://NOMBREDELCLÚSTER.azurehdinsight.net/stormui</span><span class="sxs-lookup"><span data-stu-id="3cffe-287">The Storm UI is available at https://CLUSTERNAME.azurehdinsight.net/stormui</span></span> |
| <span data-ttu-id="3cffe-288">Visual Studio para crear, implementar y administrar topologías de C# o híbridas</span><span class="sxs-lookup"><span data-stu-id="3cffe-288">Visual Studio to create, deploy, and manage C# or hybrid topologies</span></span> |<span data-ttu-id="3cffe-289">Visual Studio puede utilizarse para crear, implementar y administrar topologías de C# (SCP.NET) o topologías híbridas en clústeres Storm en HDInsight basados en Linux creados después del 28/10/2016.</span><span class="sxs-lookup"><span data-stu-id="3cffe-289">Visual Studio can be used to create, deploy, and manage C# (SCP.NET) or hybrid topologies on Linux-based Storm on HDInsight clusters created after 10/28/2016.</span></span> |

## <a name="hbase"></a><span data-ttu-id="3cffe-290">HBase</span><span class="sxs-lookup"><span data-stu-id="3cffe-290">HBase</span></span>

<span data-ttu-id="3cffe-291">En los clústeres basados en Linux, el elemento primario del ZNode para HBase es `/hbase-unsecure`.</span><span class="sxs-lookup"><span data-stu-id="3cffe-291">On Linux-based clusters, the znode parent for HBase is `/hbase-unsecure`.</span></span> <span data-ttu-id="3cffe-292">Debe establecer este valor en la configuración de las aplicaciones cliente de Java que usan la API nativa de Java de HBase.</span><span class="sxs-lookup"><span data-stu-id="3cffe-292">Set this value in the configuration for any Java client applications that use native HBase Java API.</span></span>

<span data-ttu-id="3cffe-293">Consulte [Compilación de una aplicación HBase basada en Java](hdinsight-hbase-build-java-maven.md) para ver un cliente de ejemplo que establece este valor.</span><span class="sxs-lookup"><span data-stu-id="3cffe-293">See [Build a Java-based HBase application](hdinsight-hbase-build-java-maven.md) for an example client that sets this value.</span></span>

## <a name="spark"></a><span data-ttu-id="3cffe-294">Spark</span><span class="sxs-lookup"><span data-stu-id="3cffe-294">Spark</span></span>

<span data-ttu-id="3cffe-295">Los clústeres de Spark estaban disponibles en los clústeres de Windows durante la vista previa.</span><span class="sxs-lookup"><span data-stu-id="3cffe-295">Spark clusters were available on Windows-clusters during preview.</span></span> <span data-ttu-id="3cffe-296">Spark GA solo está disponible con clústeres basados en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-296">Spark GA is only available with Linux-based clusters.</span></span> <span data-ttu-id="3cffe-297">No hay ninguna ruta de migración de un clúster de versión preliminar de Spark basado en Windows a un clúster de versión de Spark basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-297">There is no migration path from a Windows-based Spark preview cluster to a release Linux-based Spark cluster.</span></span>

## <a name="known-issues"></a><span data-ttu-id="3cffe-298">Problemas conocidos</span><span class="sxs-lookup"><span data-stu-id="3cffe-298">Known issues</span></span>

### <a name="azure-data-factory-custom-net-activities"></a><span data-ttu-id="3cffe-299">Actividades de .NET personalizadas de Data Factory de Azure</span><span class="sxs-lookup"><span data-stu-id="3cffe-299">Azure Data Factory custom .NET activities</span></span>

<span data-ttu-id="3cffe-300">Las actividades de .NET personalizadas de Data Factory de Azure no son compatibles actualmente con clústeres de HDInsight basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-300">Azure Data Factory custom .NET activities are not currently supported on Linux-based HDInsight clusters.</span></span> <span data-ttu-id="3cffe-301">En su lugar, se debe usar uno de los métodos siguientes para implementar actividades personalizadas como parte de la canalización de ADF.</span><span class="sxs-lookup"><span data-stu-id="3cffe-301">Instead, you should use one of the following methods to implement custom activities as part of your ADF pipeline.</span></span>

* <span data-ttu-id="3cffe-302">Ejecute actividades de .NET en grupo de Lote de Azure.</span><span class="sxs-lookup"><span data-stu-id="3cffe-302">Execute .NET activities on Azure Batch pool.</span></span> <span data-ttu-id="3cffe-303">Consulte la sección Servicio vinculado de Lote de Azure de [Uso de actividades personalizadas en una canalización de Azure Data Factory](../data-factory/data-factory-use-custom-activities.md)</span><span class="sxs-lookup"><span data-stu-id="3cffe-303">See the Use Azure Batch linked service section of [Use custom activities in an Azure Data Factory pipeline](../data-factory/data-factory-use-custom-activities.md)</span></span>
* <span data-ttu-id="3cffe-304">Implemente la actividad como una actividad MapReduce.</span><span class="sxs-lookup"><span data-stu-id="3cffe-304">Implement the activity as a MapReduce activity.</span></span> <span data-ttu-id="3cffe-305">Para obtener más información, consulte [Invocación de programas MapReduce desde Data Factory](../data-factory/data-factory-map-reduce.md).</span><span class="sxs-lookup"><span data-stu-id="3cffe-305">For more information, see [Invoke MapReduce Programs from Data Factory](../data-factory/data-factory-map-reduce.md).</span></span>

### <a name="line-endings"></a><span data-ttu-id="3cffe-306">Fin de línea</span><span class="sxs-lookup"><span data-stu-id="3cffe-306">Line endings</span></span>

<span data-ttu-id="3cffe-307">Por lo general, los fines de línea en sistemas basados en Windows usan CRLF, mientras que los sistemas basados en Linux usan LF.</span><span class="sxs-lookup"><span data-stu-id="3cffe-307">In general, line endings on Windows-based systems use CRLF, while Linux-based systems use LF.</span></span> <span data-ttu-id="3cffe-308">Si produce o espera datos con fines de línea CRLF, puede que tenga que modificar los productores o los consumidores para trabajar con el fin de línea LF.</span><span class="sxs-lookup"><span data-stu-id="3cffe-308">If you produce, or expect, data with CRLF line endings, you may need to modify the producers or consumers to work with the LF line ending.</span></span>

<span data-ttu-id="3cffe-309">Por ejemplo, el uso de Azure PowerShell para consultar HDInsight en un clúster basado en Windows devuelve datos con CRLF.</span><span class="sxs-lookup"><span data-stu-id="3cffe-309">For example, using Azure PowerShell to query HDInsight on a Windows-based cluster returns data with CRLF.</span></span> <span data-ttu-id="3cffe-310">La misma consulta con un clúster basado en Linux devuelve LF.</span><span class="sxs-lookup"><span data-stu-id="3cffe-310">The same query with a Linux-based cluster returns LF.</span></span> <span data-ttu-id="3cffe-311">Debería hacer una prueba para comprobar si el fin de línea causa algún problema con su solución antes de migrar a un clúster basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-311">You should test to see if the line ending causes a problem with your solutuion before migrating to a Linux-based cluster.</span></span>

<span data-ttu-id="3cffe-312">Si tiene scripts que se ejecutan directamente en los nodos del clúster de Linux, debe utilizar siempre LF como el final de línea.</span><span class="sxs-lookup"><span data-stu-id="3cffe-312">If you have scripts that are executed directly on the Linux-cluster nodes, you should always use LF as the line ending.</span></span> <span data-ttu-id="3cffe-313">Si utiliza CRLF, puede que vea errores al ejecutar los scripts en un clúster basado en Linux.</span><span class="sxs-lookup"><span data-stu-id="3cffe-313">If you use CRLF, you may see errors when running the scripts on a Linux-based cluster.</span></span>

<span data-ttu-id="3cffe-314">Si sabe que los scripts no contienen cadenas de caracteres CR incrustados, puede cambiar los fines de línea mediante uno de los métodos siguientes:</span><span class="sxs-lookup"><span data-stu-id="3cffe-314">If you know that the scripts do not contain strings with embedded CR characters, you can bulk change the line endings using one of the following methods:</span></span>

* <span data-ttu-id="3cffe-315">**Antes de cargar en el clúster**: use las siguientes instrucciones de PowerShell para cambiar los fines de línea de CRLF a LF antes de cargar el script en el clúster.</span><span class="sxs-lookup"><span data-stu-id="3cffe-315">**Before uploading to the cluster**: Use the following PowerShell statements to change the line endings from CRLF to LF before uploading the script to the cluster.</span></span>

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* <span data-ttu-id="3cffe-316">**Después de cargar en el clúster**: use el siguiente comando desde una sesión de SSH para el clúster basado en Linux para modificar el script.</span><span class="sxs-lookup"><span data-stu-id="3cffe-316">**After uploading to the cluster**: Use the following command from an SSH session to the Linux-based cluster to modify the script.</span></span>

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a><span data-ttu-id="3cffe-317">Pasos siguientes</span><span class="sxs-lookup"><span data-stu-id="3cffe-317">Next Steps</span></span>

* [<span data-ttu-id="3cffe-318">Más información sobre cómo crear clústeres de HDInsight basado en Linux</span><span class="sxs-lookup"><span data-stu-id="3cffe-318">Learn how to create Linux-based HDInsight clusters</span></span>](hdinsight-hadoop-provision-linux-clusters.md)
* [<span data-ttu-id="3cffe-319">Uso de SSH para conectarse a HDInsight</span><span class="sxs-lookup"><span data-stu-id="3cffe-319">Use SSH to connect to HDInsight</span></span>](hdinsight-hadoop-linux-use-ssh-unix.md)
* [<span data-ttu-id="3cffe-320">Administración de un clúster basado en Linux mediante Ambari</span><span class="sxs-lookup"><span data-stu-id="3cffe-320">Manage a Linux-based cluster using Ambari</span></span>](hdinsight-hadoop-manage-ambari.md)
