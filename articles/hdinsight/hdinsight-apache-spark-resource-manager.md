---
title: "Administración de recursos de un clúster Apache Spark en Azure HDInsight | Microsoft Docs"
description: "Aprenda a usar recursos de administración para clústeres Spark en Azure HDInsight para mejorar el rendimiento."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: 952fa15162a40bccb3f8c7a88508556757ca6675
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/03/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="c7939-103">Administración de recursos de un clúster Apache Spark en Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="c7939-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="c7939-104">En este artículo aprenderá a acceder a interfaces como la interfaz de usuario de Ambari, la de YARN y al servidor de historial de Spark asociado con el clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-104">In this article you will learn how to access the interfaces like Ambari UI, YARN UI, and the Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="c7939-105">También aprenderá a ajustar la configuración del clúster para conseguir un rendimiento óptimo.</span><span class="sxs-lookup"><span data-stu-id="c7939-105">You will also learn about how to tune the cluster configuration for optimal performance.</span></span>

<span data-ttu-id="c7939-106">**Requisitos previos:**</span><span class="sxs-lookup"><span data-stu-id="c7939-106">**Prerequisites:**</span></span>

<span data-ttu-id="c7939-107">Debe tener lo siguiente:</span><span class="sxs-lookup"><span data-stu-id="c7939-107">You must have the following:</span></span>

* <span data-ttu-id="c7939-108">Una suscripción de Azure.</span><span class="sxs-lookup"><span data-stu-id="c7939-108">An Azure subscription.</span></span> <span data-ttu-id="c7939-109">Vea [Obtener evaluación gratuita de Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="c7939-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="c7939-110">Un clúster de Apache Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c7939-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="c7939-111">Para obtener instrucciones, vea [Creación de clústeres Apache Spark en HDInsight de Azure](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="c7939-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-the-ambari-web-ui"></a><span data-ttu-id="c7939-112">¿Cómo se puede iniciar la interfaz de usuario web de Ambari?</span><span class="sxs-lookup"><span data-stu-id="c7939-112">How do I launch the Ambari Web UI?</span></span>
1. <span data-ttu-id="c7939-113">Desde el [Portal de Azure](https://portal.azure.com/), en el panel de inicio, haga clic en el icono del clúster Spark (si lo ancló al panel de inicio).</span><span class="sxs-lookup"><span data-stu-id="c7939-113">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span> <span data-ttu-id="c7939-114">También puede navegar hasta el clúster en **Examinar todo** > **Clústeres de HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="c7939-114">You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="c7939-115">En la hoja del clúster Spark, haga clic en **Panel**.</span><span class="sxs-lookup"><span data-stu-id="c7939-115">From the Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="c7939-116">Cuando se le pida, escriba las credenciales de administrador del clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-116">When prompted, enter the admin credentials for the Spark cluster.</span></span>

    <span data-ttu-id="c7939-117">![Inicio de Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Inicio de Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="c7939-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="c7939-118">Esto debería iniciar la interfaz de usuario web de Ambari, como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="c7939-118">This should launch the Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="c7939-119">![Interfaz de usuario web de Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Interfaz de usuario web de Ambari")</span><span class="sxs-lookup"><span data-stu-id="c7939-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-the-spark-history-server"></a><span data-ttu-id="c7939-120">¿Cómo se puede iniciar el servidor de historial de Spark?</span><span class="sxs-lookup"><span data-stu-id="c7939-120">How do I launch the Spark History Server?</span></span>
1. <span data-ttu-id="c7939-121">Desde el [Portal de Azure](https://portal.azure.com/), en el panel de inicio, haga clic en el icono del clúster Spark (si lo ancló al panel de inicio).</span><span class="sxs-lookup"><span data-stu-id="c7939-121">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span>
2. <span data-ttu-id="c7939-122">En la hoja del clúster, en **Vínculos rápidos**, haga clic en **Panel de clúster**.</span><span class="sxs-lookup"><span data-stu-id="c7939-122">From the cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="c7939-123">En la hoja **Panel de clúster**, haga clic en **Servidor de historial de Spark**.</span><span class="sxs-lookup"><span data-stu-id="c7939-123">In the **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="c7939-124">![Servidor de historial de Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Servidor de historial de Spark")</span><span class="sxs-lookup"><span data-stu-id="c7939-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="c7939-125">Cuando se le pida, escriba las credenciales de administrador del clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-125">When prompted, enter the admin credentials for the Spark cluster.</span></span>

## <a name="how-do-i-launch-the-yarn-ui"></a><span data-ttu-id="c7939-126">¿Cómo se puede iniciar la interfaz de usuario de Yarn?</span><span class="sxs-lookup"><span data-stu-id="c7939-126">How do I launch the Yarn UI?</span></span>
<span data-ttu-id="c7939-127">Puede utilizar la interfaz de usuario de YARN para supervisar las aplicaciones que se encuentran en ejecución en el clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-127">You can use the YARN UI to monitor applications that are currently running on the Spark cluster.</span></span>

1. <span data-ttu-id="c7939-128">En la hoja del clúster, haga clic en **Panel de clúster** y en **YARN**.</span><span class="sxs-lookup"><span data-stu-id="c7939-128">From the cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Iniciar interfaz de usuario de YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="c7939-130">También puede iniciar la interfaz de usuario de YARN desde la de Ambari.</span><span class="sxs-lookup"><span data-stu-id="c7939-130">Alternatively, you can also launch the YARN UI from the Ambari UI.</span></span> <span data-ttu-id="c7939-131">Para iniciar la interfaz de usuario de Ambari, en la hoja del clúster, haga clic en **Panel de clúster** y luego en **Panel de clúster de HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="c7939-131">To launch the Ambari UI, from the cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="c7939-132">En la interfaz de usuario de Ambari, haga clic en **YARN**, en **Vínculos rápidos**, en la instancia activa de Resource Manager y, finalmente, en la **interfaz de usuario de Resource Manager**.</span><span class="sxs-lookup"><span data-stu-id="c7939-132">From the Ambari UI, click **YARN**, click **Quick Links**, click the active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-the-optimum-cluster-configuration-to-run-spark-applications"></a><span data-ttu-id="c7939-133">¿Cuál es la configuración de clúster óptima para ejecutar aplicaciones de Spark?</span><span class="sxs-lookup"><span data-stu-id="c7939-133">What is the optimum cluster configuration to run Spark applications?</span></span>
<span data-ttu-id="c7939-134">Los tres parámetros clave que se pueden utilizar para la configuración de Spark según los requisitos de la aplicación son `spark.executor.instances`, `spark.executor.cores` y `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="c7939-134">The three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="c7939-135">Un ejecutor es un proceso que se inicia para una aplicación Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="c7939-136">Se ejecuta en el nodo de trabajo y es responsable de realizar las tareas de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="c7939-136">It runs on the worker node and is responsible to carry out the tasks for the application.</span></span> <span data-ttu-id="c7939-137">El número predeterminado de ejecutores y el tamaño de estos para cada clúster se calcula en función del número de nodos de trabajo y el tamaño de estos.</span><span class="sxs-lookup"><span data-stu-id="c7939-137">The default number of executors and the executor sizes for each cluster is calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="c7939-138">Estos se almacenan en `spark-defaults.conf` en los nodos principales del clúster.</span><span class="sxs-lookup"><span data-stu-id="c7939-138">These are stored in `spark-defaults.conf` on the cluster head nodes.</span></span>

<span data-ttu-id="c7939-139">Los tres parámetros de configuración se pueden configurar en el nivel de clúster (para todas las aplicaciones que se ejecutan en el clúster) o se pueden especificar también para cada aplicación individual.</span><span class="sxs-lookup"><span data-stu-id="c7939-139">The three configuration parameters can be configured at the cluster level (for all applications that run on the cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-the-parameters-using-ambari-ui"></a><span data-ttu-id="c7939-140">Cambio de los parámetros mediante la interfaz de usuario de Ambari</span><span class="sxs-lookup"><span data-stu-id="c7939-140">Change the parameters using Ambari UI</span></span>
1. <span data-ttu-id="c7939-141">En la interfaz de usuario de Ambari, haga clic en **Spark** y en **Configs** (Configuraciones). A continuación, expanda **Custom spark-defaults** (spark-defaults personalizado).</span><span class="sxs-lookup"><span data-stu-id="c7939-141">From the Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Establecer los parámetros mediante Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="c7939-143">Los valores predeterminados son necesarios para hacer que se ejecuten 4 aplicaciones Spark simultáneamente en el clúster.</span><span class="sxs-lookup"><span data-stu-id="c7939-143">The default values are good to have 4 Spark applications run concurrently on the cluster.</span></span> <span data-ttu-id="c7939-144">Puede cambiar estos valores desde la interfaz de usuario, como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="c7939-144">You can changes these values from the user interface, as shown below.</span></span>

    ![Establecer los parámetros mediante Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="c7939-146">Para guardar los cambios de configuración, haga clic en **Save** (Guardar).</span><span class="sxs-lookup"><span data-stu-id="c7939-146">Click **Save** to save the configuration changes.</span></span> <span data-ttu-id="c7939-147">En la parte superior de la página, se le pedirá que reinicie todos los servicios afectados.</span><span class="sxs-lookup"><span data-stu-id="c7939-147">At the top of the page, you will be prompted to restart all the affected services.</span></span> <span data-ttu-id="c7939-148">Haga clic en **Restart**(Reiniciar).</span><span class="sxs-lookup"><span data-stu-id="c7939-148">Click **Restart**.</span></span>

    ![Reiniciar los servicios](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-the-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="c7939-150">Cambio de los parámetros de una aplicación que se ejecuta en Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="c7939-150">Change the parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="c7939-151">Para aplicaciones que se ejecutan en Jupyter Notebook, puede utilizar la instrucción mágica `%%configure` para realizar los cambios de configuración.</span><span class="sxs-lookup"><span data-stu-id="c7939-151">For applications running in the Jupyter notebook, you can use the `%%configure` magic to make the configuration changes.</span></span> <span data-ttu-id="c7939-152">Idealmente, debe realizar estos cambios al comienzo de la aplicación, antes de ejecutar la primera celda de código.</span><span class="sxs-lookup"><span data-stu-id="c7939-152">Ideally, you must make such changes at the beginning of the application, before you run your first code cell.</span></span> <span data-ttu-id="c7939-153">Esto garantiza que la configuración se aplicará a la sesión de Livy, cuando esta se cree.</span><span class="sxs-lookup"><span data-stu-id="c7939-153">This ensures that the configuration is applied to the Livy session, when it gets created.</span></span> <span data-ttu-id="c7939-154">Si desea cambiar la configuración en una fase posterior de la aplicación, debe utilizar el parámetro `-f` .</span><span class="sxs-lookup"><span data-stu-id="c7939-154">If you want to change the configuration at a later stage in the application, you must use the `-f` parameter.</span></span> <span data-ttu-id="c7939-155">Sin embargo, al hacerlo, se perderán todos los progresos en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="c7939-155">However, by doing so all progress in the application will be lost.</span></span>

<span data-ttu-id="c7939-156">El siguiente fragmento de código muestra cómo cambiar la configuración de una aplicación que se ejecuta en Jupyter.</span><span class="sxs-lookup"><span data-stu-id="c7939-156">The snippet below shows how to change the configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="c7939-157">Los parámetros de configuración deben pasarse como una cadena JSON y deben estar en la siguiente línea después de la instrucción mágica, como se muestra en la columna de ejemplo.</span><span class="sxs-lookup"><span data-stu-id="c7939-157">Configuration parameters must be passed in as a JSON string and must be on the next line after the magic, as shown in the example column.</span></span>

### <a name="change-the-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="c7939-158">Cambio de los parámetros de una aplicación enviada mediante spark-submit</span><span class="sxs-lookup"><span data-stu-id="c7939-158">Change the parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="c7939-159">El siguiente comando es un ejemplo de cómo cambiar los parámetros de configuración de una aplicación de lote que se envía mediante `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="c7939-159">Following command is an example of how to change the configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <the application class to execute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-the-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="c7939-160">Cambio de los parámetros de una aplicación enviada mediante cURL</span><span class="sxs-lookup"><span data-stu-id="c7939-160">Change the parameters for an application submitted using cURL</span></span>
<span data-ttu-id="c7939-161">El siguiente comando es un ejemplo de cómo cambiar los parámetros de configuración de una aplicación de lote que se envía mediante cURL.</span><span class="sxs-lookup"><span data-stu-id="c7939-161">Following command is an example of how to change the configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<the application class to execute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="c7939-162">¿Cómo se pueden cambiar estos parámetros en un servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="c7939-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="c7939-163">El servidor Thrift de Spark proporciona acceso JDBC/ODBC a un clúster de Spark y se utiliza para enviar consultas de Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="c7939-163">Spark Thrift Server provides JDBC/ODBC access to a Spark cluster and is used to service Spark SQL queries.</span></span> <span data-ttu-id="c7939-164">Herramientas como Power BI, Tableau, etc.</span><span class="sxs-lookup"><span data-stu-id="c7939-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="c7939-165">usan el protocolo ODBC para comunicarse con el servidor Thrift de Spark para ejecutar consultas de Spark SQL como una aplicación Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-165">use ODBC protocol to communicate with Spark Thrift Server to execute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="c7939-166">Cuando se crea un clúster de Spark, se inician dos instancias del servidor Thrift de Spark, una en cada nodo principal.</span><span class="sxs-lookup"><span data-stu-id="c7939-166">When a Spark cluster is created, two instances of the Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="c7939-167">Cada servidor Thrift de Spark está visible como una aplicación Spark en la interfaz de usuario de YARN.</span><span class="sxs-lookup"><span data-stu-id="c7939-167">Each Spark Thrift Server is visible as a Spark application in the YARN UI.</span></span>

<span data-ttu-id="c7939-168">El servidor Thrift de Spark utiliza la asignación dinámica de ejecutores de Spark y, por tanto, las `spark.executor.instances` no se utilizan.</span><span class="sxs-lookup"><span data-stu-id="c7939-168">Spark Thrift Server uses Spark dynamic executor allocation and hence the `spark.executor.instances` is not used.</span></span> <span data-ttu-id="c7939-169">En su lugar, el servidor Thrift de Spark usa `spark.dynamicAllocation.minExecutors` y `spark.dynamicAllocation.maxExecutors` para especificar el recuento de ejecutores.</span><span class="sxs-lookup"><span data-stu-id="c7939-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` to specify the executor count.</span></span> <span data-ttu-id="c7939-170">Los parámetros de configuración `spark.executor.cores` y `spark.executor.memory` se usan para modificar el tamaño del ejecutor.</span><span class="sxs-lookup"><span data-stu-id="c7939-170">The configuration parameters `spark.executor.cores` and `spark.executor.memory` is used to modify the executor size.</span></span> <span data-ttu-id="c7939-171">Puede cambiar estos parámetros como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="c7939-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="c7939-172">Expanda la categoría **Advanced spark-thrift-sparkconf** (spark-thrift-sparkconf avanzado) para actualizar los parámetros `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors` y `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="c7939-172">Expand the **Advanced spark-thrift-sparkconf** category to update the parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurar el servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="c7939-174">Expanda la categoría **Custom spark-thrift-sparkconf** (spark-thrift-sparkconf personalizado) para actualizar el parámetro `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="c7939-174">Expand the **Custom spark-thrift-sparkconf** category to update the parameter `spark.executor.cores`.</span></span>

    ![Configurar el servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-the-driver-memory-of-the-spark-thrift-server"></a><span data-ttu-id="c7939-176">¿Cómo se puede cambiar la memoria del controlador del servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="c7939-176">How do I change the driver memory of the Spark Thrift Server?</span></span>
<span data-ttu-id="c7939-177">La memoria del controlador del servidor Thrift de Spark se ha configurado al 25 % del tamaño de la RAM del nodo principal, suponiendo que el tamaño total de la RAM del nodo principal sea superior a 14 GB.</span><span class="sxs-lookup"><span data-stu-id="c7939-177">Spark Thrift Server driver memory is configured to 25% of the head node RAM size, provided the total RAM size of the head node is greater than 14GB.</span></span> <span data-ttu-id="c7939-178">Puede utilizar la interfaz de usuario de Ambari para cambiar la configuración de memoria del controlador, tal como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="c7939-178">You can use the Ambari UI to change the driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="c7939-179">En la interfaz de usuario de Ambari, haga clic en **Spark** y en **Configs** (Configuraciones). A continuación, expanda **Advanced spark-env** (spark-env avanzado) y especifique un valor para **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="c7939-179">From the Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide the value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurar la RAM del servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-the-resources-back"></a><span data-ttu-id="c7939-181">No uso BI con el clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="c7939-182">¿Cómo elimino los recursos de nuevo?</span><span class="sxs-lookup"><span data-stu-id="c7939-182">How do I take the resources back?</span></span>
<span data-ttu-id="c7939-183">Dado que se utiliza la asignación dinámica de Spark, los únicos recursos consumidos por el servidor Thrift son los recursos de los dos maestros de aplicación.</span><span class="sxs-lookup"><span data-stu-id="c7939-183">Since we use Spark dynamic allocation, the only resources that are consumed by thrift server are the resources for the two application masters.</span></span> <span data-ttu-id="c7939-184">Para recuperar estos recursos debe detener los servicios del servidor Thrift que se estén ejecutando en el clúster.</span><span class="sxs-lookup"><span data-stu-id="c7939-184">To reclaim these resources you must stop the Thrift Server services running on the cluster.</span></span>

1. <span data-ttu-id="c7939-185">En la interfaz de usuario de Ambari, en el panel izquierdo, haga clic en **Spark**.</span><span class="sxs-lookup"><span data-stu-id="c7939-185">From the Ambari UI, from the left pane, click **Spark**.</span></span>
2. <span data-ttu-id="c7939-186">En la siguiente página, haga clic en **Spark Thrift Servers**(Servidores Thrift de Spark).</span><span class="sxs-lookup"><span data-stu-id="c7939-186">In the next page, click **Spark Thrift Servers**.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="c7939-188">Aparecerán los dos nodos principales en el que se ejecuta el servidor Thrift de Spark.</span><span class="sxs-lookup"><span data-stu-id="c7939-188">You should see the two headnodes on which the Spark Thrift Server is running.</span></span> <span data-ttu-id="c7939-189">Haga clic en uno de los nodos principales.</span><span class="sxs-lookup"><span data-stu-id="c7939-189">Click one of the headnodes.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="c7939-191">La siguiente página muestra todos los servicios que se ejecutan en ese nodo principal.</span><span class="sxs-lookup"><span data-stu-id="c7939-191">The next page lists all the services running on that headnode.</span></span> <span data-ttu-id="c7939-192">En la lista, haga clic en el botón desplegable situado junto al servidor Thrift de Spark y, a continuación, haga clic en **Stop**(Detener).</span><span class="sxs-lookup"><span data-stu-id="c7939-192">From the list click the drop-down button next to Spark Thrift Server, and then click **Stop**.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="c7939-194">Repita también estos pasos en el otro nodo principal.</span><span class="sxs-lookup"><span data-stu-id="c7939-194">Repeat these steps on the other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-the-service"></a><span data-ttu-id="c7939-195">Mis cuadernos de Jupyter no se ejecutan según lo previsto.</span><span class="sxs-lookup"><span data-stu-id="c7939-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="c7939-196">¿Cómo se puede reiniciar el servicio?</span><span class="sxs-lookup"><span data-stu-id="c7939-196">How can I restart the service?</span></span>
<span data-ttu-id="c7939-197">Inicie la interfaz de usuario web de Ambari como se ha indicado anteriormente.</span><span class="sxs-lookup"><span data-stu-id="c7939-197">Launch the Ambari Web UI as shown above.</span></span> <span data-ttu-id="c7939-198">En el panel de navegación izquierdo, haga clic en **Jupyter**, en **Service Actions** (Acciones de servicio) y en **Restart All** (Reiniciar todo).</span><span class="sxs-lookup"><span data-stu-id="c7939-198">From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="c7939-199">Esto iniciará el servicio de Jupyter en todos los nodos principales.</span><span class="sxs-lookup"><span data-stu-id="c7939-199">This will start the Jupyter service on all the headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="c7939-200">¿Cómo sé si me estoy quedando sin recursos?</span><span class="sxs-lookup"><span data-stu-id="c7939-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="c7939-201">Inicie la interfaz de usuario de Yarn como se indicó anteriormente.</span><span class="sxs-lookup"><span data-stu-id="c7939-201">Launch the Yarn UI as shown above.</span></span> <span data-ttu-id="c7939-202">En la tabla de métricas del clúster, compruebe los valores de **Memory Used** (Memoria usada) y **Memory Total** (Memoria total).</span><span class="sxs-lookup"><span data-stu-id="c7939-202">In Cluster Metrics table on top of the screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="c7939-203">Si los 2 valores son muy similares, puede que no haya recursos suficientes para iniciar la siguiente aplicación.</span><span class="sxs-lookup"><span data-stu-id="c7939-203">If the 2 values are very close, there might not be enough resources to start the next application.</span></span> <span data-ttu-id="c7939-204">Lo mismo se aplica a las columnas **VCores Used** (Núcleos virtuales usados) y **VCores Total** (Núcleos virtuales totales).</span><span class="sxs-lookup"><span data-stu-id="c7939-204">The same applies to the **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="c7939-205">Además, si en la vista principal hay una aplicación con el estado **ACCEPTED** (ACEPTADO) y no pasa al estado **RUNNING** (EN EJECUCIÓN) o **FAILED** (ERROR), podría ser una señal de que no hay suficientes recursos para comenzar.</span><span class="sxs-lookup"><span data-stu-id="c7939-205">Also, in the main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources to start.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-to-free-up-resource"></a><span data-ttu-id="c7939-206">¿Cómo se elimina una aplicación en ejecución para liberar recursos?</span><span class="sxs-lookup"><span data-stu-id="c7939-206">How do I kill a running application to free up resource?</span></span>
1. <span data-ttu-id="c7939-207">En la interfaz de usuario de Yarn, en el panel izquierdo, haga clic en **Running** (En ejecución).</span><span class="sxs-lookup"><span data-stu-id="c7939-207">In the Yarn UI, from the left panel, click **Running**.</span></span> <span data-ttu-id="c7939-208">En la lista de aplicaciones en ejecución, determine la aplicación que se eliminará y haga clic en el **ID** (Identificador).</span><span class="sxs-lookup"><span data-stu-id="c7939-208">From the list of running applications, determine the application to be killed and click on the **ID**.</span></span>

    <span data-ttu-id="c7939-209">![Eliminación de App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Eliminación de App1")</span><span class="sxs-lookup"><span data-stu-id="c7939-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="c7939-210">Haga clic en **Kill Application** (Eliminar aplicación) en la esquina superior derecha y luego en **OK** (Aceptar).</span><span class="sxs-lookup"><span data-stu-id="c7939-210">Click **Kill Application** on the top right corner, then click **OK**.</span></span>

    <span data-ttu-id="c7939-211">![Eliminación de App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Eliminación de App2")</span><span class="sxs-lookup"><span data-stu-id="c7939-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="c7939-212">Otras referencias</span><span class="sxs-lookup"><span data-stu-id="c7939-212">See also</span></span>
* [<span data-ttu-id="c7939-213">Track and debug jobs running on an Apache Spark cluster in HDInsight (Seguimiento y depuración de trabajos que se ejecutan en un clúster de Apache Spark en HDInsight)</span><span class="sxs-lookup"><span data-stu-id="c7939-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="c7939-214">Para analistas de datos</span><span class="sxs-lookup"><span data-stu-id="c7939-214">For data analysts</span></span>

* [<span data-ttu-id="c7939-215">Creación de aplicaciones de Aprendizaje automático con Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="c7939-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="c7939-216">Spark con Aprendizaje automático: uso de Spark en HDInsight para predecir los resultados de la inspección de alimentos</span><span class="sxs-lookup"><span data-stu-id="c7939-216">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="c7939-217">Análisis del registro del sitio web con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="c7939-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="c7939-218">Análisis de datos de telemetría de Application Insights con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="c7939-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="c7939-219">Uso de Caffe en Azure HDInsight Spark para el aprendizaje profundo distribuido</span><span class="sxs-lookup"><span data-stu-id="c7939-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="c7939-220">Para desarrolladores de Spark</span><span class="sxs-lookup"><span data-stu-id="c7939-220">For Spark developers</span></span>

* [<span data-ttu-id="c7939-221">Crear una aplicación independiente con Scala</span><span class="sxs-lookup"><span data-stu-id="c7939-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="c7939-222">Ejecutar trabajos de forma remota en un clúster de Spark mediante Livy</span><span class="sxs-lookup"><span data-stu-id="c7939-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="c7939-223">Uso del complemento de herramientas de HDInsight para IntelliJ IDEA para crear y enviar aplicaciones de Spark Scala</span><span class="sxs-lookup"><span data-stu-id="c7939-223">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="c7939-224">Streaming con Spark: uso de Spark en HDInsight para compilar aplicaciones de streaming en tiempo real</span><span class="sxs-lookup"><span data-stu-id="c7939-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="c7939-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely (Uso del complemento de herramientas de HDInsight para IntelliJ IDEA para depurar aplicaciones de Spark de forma remota)</span><span class="sxs-lookup"><span data-stu-id="c7939-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="c7939-226">Uso de cuadernos de Zeppelin con un clúster Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="c7939-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="c7939-227">Kernels disponibles para el cuaderno de Jupyter en el clúster Spark para HDInsight</span><span class="sxs-lookup"><span data-stu-id="c7939-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="c7939-228">Uso de paquetes externos con cuadernos de Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="c7939-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="c7939-229">Instalación de un cuaderno de Jupyter Notebook en el equipo y conexión al clúster de Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="c7939-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
