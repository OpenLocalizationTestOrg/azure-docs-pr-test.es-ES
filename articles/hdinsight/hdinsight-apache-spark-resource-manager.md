---
title: "clúster de recursos de aaaManage de Apache Spark en HDInsight de Azure | Documentos de Microsoft"
description: "Obtenga información acerca de cómo toouse administrar recursos para clústeres de Spark en HDInsight de Azure para mejorar el rendimiento."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="9c32d-103">Administración de recursos de un clúster Apache Spark en Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="9c32d-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="9c32d-104">En este artículo, aprenderá cómo interfaces de hello tooaccess como Ambari UI, interfaz de usuario de YARN y Hola Spark historial Server asociada a su clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="9c32d-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="9c32d-105">También obtendrá información acerca de cómo tootune Hola configuración de clúster para un rendimiento óptimo.</span><span class="sxs-lookup"><span data-stu-id="9c32d-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="9c32d-106">**Requisitos previos:**</span><span class="sxs-lookup"><span data-stu-id="9c32d-106">**Prerequisites:**</span></span>

<span data-ttu-id="9c32d-107">Debe disponer de hello siguiente:</span><span class="sxs-lookup"><span data-stu-id="9c32d-107">You must have hello following:</span></span>

* <span data-ttu-id="9c32d-108">Una suscripción de Azure.</span><span class="sxs-lookup"><span data-stu-id="9c32d-108">An Azure subscription.</span></span> <span data-ttu-id="9c32d-109">Vea [Obtener evaluación gratuita de Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="9c32d-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="9c32d-110">Un clúster de Apache Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9c32d-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="9c32d-111">Para obtener instrucciones, vea [Creación de clústeres Apache Spark en HDInsight de Azure](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="9c32d-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="9c32d-112">¿Cómo se puede iniciar hello Ambari Web UI?</span><span class="sxs-lookup"><span data-stu-id="9c32d-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="9c32d-113">De hello [Portal de Azure](https://portal.azure.com/), desde el panel de inicio de hello, haga clic en icono de hello para el clúster de Spark (si anclarlo toohello panel de inicio).</span><span class="sxs-lookup"><span data-stu-id="9c32d-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="9c32d-114">También puede navegar clúster tooyour en **examinar todos los** > **clústeres de HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="9c32d-115">En la hoja de clúster de Spark hello, haga clic en **panel**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="9c32d-116">Cuando se le solicite, escriba las credenciales de administrador de Hola para clúster de Spark Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="9c32d-117">![Inicio de Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Inicio de Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="9c32d-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="9c32d-118">Esto debería iniciar hello Ambari la interfaz de usuario Web, tal y como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="9c32d-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="9c32d-119">![Interfaz de usuario web de Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Interfaz de usuario web de Ambari")</span><span class="sxs-lookup"><span data-stu-id="9c32d-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="9c32d-120">¿Cómo se puede iniciar Hola Spark historial Server?</span><span class="sxs-lookup"><span data-stu-id="9c32d-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="9c32d-121">De hello [Portal de Azure](https://portal.azure.com/), desde el panel de inicio de hello, haga clic en icono de hello para el clúster de Spark (si anclarlo toohello panel de inicio).</span><span class="sxs-lookup"><span data-stu-id="9c32d-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="9c32d-122">De hello clúster hoja, en **vínculos rápidos**, haga clic en **panel clúster**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="9c32d-123">Hola **panel clúster** hoja, haga clic en **Spark historial Server**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="9c32d-124">![Servidor de historial de Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Servidor de historial de Spark")</span><span class="sxs-lookup"><span data-stu-id="9c32d-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="9c32d-125">Cuando se le solicite, escriba las credenciales de administrador de Hola para clúster de Spark Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="9c32d-126">¿Cómo se puede iniciar hello Yarn UI?</span><span class="sxs-lookup"><span data-stu-id="9c32d-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="9c32d-127">Puede usar las aplicaciones de toomonitor de interfaz de usuario de YARN Hola que se están ejecutando en el clúster de Spark Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="9c32d-128">En la hoja de clúster de hello, haga clic en **panel clúster**y, a continuación, haga clic en **YARN**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Iniciar interfaz de usuario de YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="9c32d-130">Como alternativa, también puede iniciar hello YARN UI de hello Ambari UI.</span><span class="sxs-lookup"><span data-stu-id="9c32d-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="9c32d-131">Hola toolaunch Ambari UI, desde la hoja de clúster de hello, haga clic en **panel clúster**y, a continuación, haga clic en **panel de clúster de HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="9c32d-132">En hello Ambari UI, haga clic en **YARN**, haga clic en **vínculos rápidos**, haga clic en Administrador de recursos activos de hello y, a continuación, haga clic en **ResourceManager UI**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="9c32d-133">¿Qué es aplicaciones de Spark de toorun de configuración de clúster óptima de hello?</span><span class="sxs-lookup"><span data-stu-id="9c32d-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="9c32d-134">Hola tres parámetros clave que pueden usar para la configuración de Spark según los requisitos de la aplicación son `spark.executor.instances`, `spark.executor.cores`, y `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="9c32d-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="9c32d-135">Un ejecutor es un proceso que se inicia para una aplicación Spark.</span><span class="sxs-lookup"><span data-stu-id="9c32d-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="9c32d-136">Se ejecuta en el nodo de trabajo hello y es responsable toocarry tareas de hello para la aplicación hello.</span><span class="sxs-lookup"><span data-stu-id="9c32d-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="9c32d-137">número predeterminado de Hola de ejecutor y tamaños de ejecutor de Hola para cada clúster se calcula según en número de Hola de nodos de trabajador y el tamaño de nodo de trabajo de Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="9c32d-138">Estos se almacenan en `spark-defaults.conf` en nodos principales del clúster Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="9c32d-139">tres parámetros de configuración de Hello pueden configurarse en el nivel de clúster de hello (para todas las aplicaciones que se ejecutan en el clúster de hello) o se pueden especificar para cada aplicación así.</span><span class="sxs-lookup"><span data-stu-id="9c32d-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="9c32d-140">Cambiar los parámetros de hello usando Ambari UI</span><span class="sxs-lookup"><span data-stu-id="9c32d-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="9c32d-141">En hello Ambari UI haga clic en **Spark**, haga clic en **configuraciones**y, a continuación, expanda **valores predeterminados personalizados spark**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Establecer los parámetros mediante Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="9c32d-143">valores predeterminados de Hello son aplicaciones de Spark de buena toohave 4 ejecutarse simultáneamente en el clúster de Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="9c32d-144">Puede cambios estos valores de la interfaz de usuario de hello, tal y como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="9c32d-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Establecer los parámetros mediante Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="9c32d-146">Haga clic en **guardar** cambios de configuración de toosave Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="9c32d-147">Hola parte superior de la página de hello, se le pedirá toorestart Hola a todos los servicios afectados.</span><span class="sxs-lookup"><span data-stu-id="9c32d-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="9c32d-148">Haga clic en **Restart**(Reiniciar).</span><span class="sxs-lookup"><span data-stu-id="9c32d-148">Click **Restart**.</span></span>

    ![Reiniciar los servicios](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="9c32d-150">Cambiar los parámetros de Hola de una aplicación que se ejecuta en el Bloc de notas de Jupyter</span><span class="sxs-lookup"><span data-stu-id="9c32d-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="9c32d-151">Para aplicaciones que se ejecutan en el Bloc de notas de hello Jupyter, puede usar hello `%%configure` mágico cambios de configuración de toomake Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="9c32d-152">Idealmente, debe realizar dichos cambios al principio de hello de la aplicación hello, antes de ejecutar la primera celda de código.</span><span class="sxs-lookup"><span data-stu-id="9c32d-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="9c32d-153">Esto garantiza que la configuración de hello esté aplicado toohello Livio sesión, cuando se crea.</span><span class="sxs-lookup"><span data-stu-id="9c32d-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="9c32d-154">Si desea que la configuración de Hola de toochange en una fase posterior en la aplicación hello, debe usar hello `-f` parámetro.</span><span class="sxs-lookup"><span data-stu-id="9c32d-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="9c32d-155">Sin embargo, por lo que todos transcurrir en hello aplicación se perderá.</span><span class="sxs-lookup"><span data-stu-id="9c32d-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="9c32d-156">fragmento de Hola a continuación muestra cómo toochange Hola configuración para una aplicación que se ejecuta en Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9c32d-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="9c32d-157">Parámetros de configuración deben pasar como una cadena JSON y deben estar en línea siguiente de hello después magia hello, como se muestra en la columna de ejemplo de Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="9c32d-158">Cambiar los parámetros de Hola para una aplicación que se envía mediante spark-submit</span><span class="sxs-lookup"><span data-stu-id="9c32d-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="9c32d-159">Siguiente comando es un ejemplo de cómo toochange Hola parámetros de configuración para una aplicación de lote que se envía mediante `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="9c32d-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="9c32d-160">Cambiar los parámetros de Hola de una aplicación que se envía mediante cURL</span><span class="sxs-lookup"><span data-stu-id="9c32d-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="9c32d-161">Siguiente comando es un ejemplo de cómo toochange Hola parámetros de configuración para una aplicación de lote que se envía utilizando cURL.</span><span class="sxs-lookup"><span data-stu-id="9c32d-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="9c32d-162">¿Cómo se pueden cambiar estos parámetros en un servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="9c32d-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="9c32d-163">Servidor Thrift de Spark proporciona clúster de Spark JDBC/ODBC acceso tooa y es utilizado tooservice consultas Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="9c32d-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="9c32d-164">Herramientas como Power BI, Tableau, etc.</span><span class="sxs-lookup"><span data-stu-id="9c32d-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="9c32d-165">utilizar ODBC protocolo toocommunicate con consultas de servidor Thrift de Spark tooexecute Spark SQL como una aplicación de Spark.</span><span class="sxs-lookup"><span data-stu-id="9c32d-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="9c32d-166">Cuando se crea un clúster de Spark, dos instancias de hello servidor Thrift de Spark se inician, uno en cada nodo principal.</span><span class="sxs-lookup"><span data-stu-id="9c32d-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="9c32d-167">Cada servidor Thrift de Spark está visible como una aplicación de Spark en hello YARN interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="9c32d-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="9c32d-168">Servidor Thrift de Spark usa inspirará asignación dinámica ejecutor y Hola, por tanto, `spark.executor.instances` no se utiliza.</span><span class="sxs-lookup"><span data-stu-id="9c32d-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="9c32d-169">En su lugar, utiliza el servidor Thrift de Spark `spark.dynamicAllocation.minExecutors` y `spark.dynamicAllocation.maxExecutors` recuento de ejecutor de toospecify Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="9c32d-170">parámetros de configuración de Hola `spark.executor.cores` y `spark.executor.memory` es toomodify Hola ejecutor tamaño usado.</span><span class="sxs-lookup"><span data-stu-id="9c32d-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="9c32d-171">Puede cambiar estos parámetros como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="9c32d-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="9c32d-172">Expanda hello **avanzada spark-thrift-sparkconf** parámetros de categoría tooupdate hello `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, y `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="9c32d-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurar el servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="9c32d-174">Expanda hello **personalizado spark-thrift-sparkconf** parámetro de categoría tooupdate hello `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="9c32d-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Configurar el servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="9c32d-176">¿Cómo se cambia la memoria del controlador de Hola de hello servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="9c32d-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="9c32d-177">Memoria de servidor Thrift de Spark controlador es too25 configurado % del tamaño de RAM del nodo principal de hello, proporcionado por el tamaño de RAM total de Hola de nodo principal de hello es mayor que 14GB.</span><span class="sxs-lookup"><span data-stu-id="9c32d-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="9c32d-178">Puede usar hello Ambari UI toochange Hola controlador configuración de la memoria, tal y como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="9c32d-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="9c32d-179">En hello Ambari UI haga clic en **Spark**, haga clic en **configuraciones**, expanda **avanzada spark env**y, a continuación, proporcionar valor de Hola para **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurar la RAM del servidor Thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="9c32d-181">No uso BI con el clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="9c32d-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="9c32d-182">¿Cómo realizo recursos Hola nuevo?</span><span class="sxs-lookup"><span data-stu-id="9c32d-182">How do I take hello resources back?</span></span>
<span data-ttu-id="9c32d-183">Dado que se usa la asignación dinámica de Spark, hello únicamente los recursos consumidos por servidor thrift son Hola recursos para dos patrones de aplicación Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="9c32d-184">tooreclaim servicios de servidor Thrift que se ejecutan en el clúster de Hola Hola a estos recursos que debe detener.</span><span class="sxs-lookup"><span data-stu-id="9c32d-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="9c32d-185">De Hola Ambari UI, desde el panel izquierdo de hello, haga clic en **Spark**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="9c32d-186">En la página siguiente de hello, haga clic en **servidores Thrift de Spark**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="9c32d-188">Debería ver Hola dos headnodes en qué Hola se está ejecutando servidor Thrift de Spark.</span><span class="sxs-lookup"><span data-stu-id="9c32d-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="9c32d-189">Haga clic en uno de hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="9c32d-189">Click one of hello headnodes.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="9c32d-191">página siguiente de Hello enumera todos los servicios de hello ejecutando en ese nodo principal.</span><span class="sxs-lookup"><span data-stu-id="9c32d-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="9c32d-192">En lista de hello haga clic en hello botón desplegable siguiente tooSpark servidor Thrift y, a continuación, haga clic en **detener**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Reiniciar el servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="9c32d-194">Repita estos pasos en hello también otro nodo principal.</span><span class="sxs-lookup"><span data-stu-id="9c32d-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="9c32d-195">Mis cuadernos de Jupyter no se ejecutan según lo previsto.</span><span class="sxs-lookup"><span data-stu-id="9c32d-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="9c32d-196">¿Cómo puedo reiniciar servicio Hola?</span><span class="sxs-lookup"><span data-stu-id="9c32d-196">How can I restart hello service?</span></span>
<span data-ttu-id="9c32d-197">Inicie hello Ambari Web UI como se indicó anteriormente.</span><span class="sxs-lookup"><span data-stu-id="9c32d-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="9c32d-198">En el panel de navegación izquierdo de hello, haga clic en **Jupyter**, haga clic en **acciones de servicio**y, a continuación, haga clic en **reiniciar todos los**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="9c32d-199">Esto iniciará el servicio de Jupyter de hello en todos los headnodes Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="9c32d-200">¿Cómo sé si me estoy quedando sin recursos?</span><span class="sxs-lookup"><span data-stu-id="9c32d-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="9c32d-201">Inicie hello Yarn interfaz de usuario como se indicó anteriormente.</span><span class="sxs-lookup"><span data-stu-id="9c32d-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="9c32d-202">En la tabla de métricas de clúster sobre la pantalla de bienvenida, compruebe los valores de **usa memoria** y **Total de memoria** columnas.</span><span class="sxs-lookup"><span data-stu-id="9c32d-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="9c32d-203">Si los valores de hello 2 son muy similares, podría no ser suficiente siguiente aplicación de recursos toostart Hola.</span><span class="sxs-lookup"><span data-stu-id="9c32d-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="9c32d-204">Hello Esto mismo aplica toohello **VCores utiliza** y **VCores Total** columnas.</span><span class="sxs-lookup"><span data-stu-id="9c32d-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="9c32d-205">Además, en la vista principal de hello, si hay una aplicación permanecido en **aceptado** estado y no pasar al **EJECUTANDO** ni **error** estado, esto también podría ser una indicación que no está obteniendo suficiente toostart de recursos.</span><span class="sxs-lookup"><span data-stu-id="9c32d-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="9c32d-206">¿Cómo se puede terminar un ejecución toofree aplicación recurso?</span><span class="sxs-lookup"><span data-stu-id="9c32d-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="9c32d-207">Hola Yarn de interfaz de usuario, desde el panel izquierdo de hello, haga clic en **ejecutando**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="9c32d-208">En la lista hello las aplicaciones en ejecución, determinar Hola aplicación toobe eliminar y haga clic en hello **identificador**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="9c32d-209">![Eliminación de App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Eliminación de App1")</span><span class="sxs-lookup"><span data-stu-id="9c32d-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="9c32d-210">Haga clic en **aplicación Kill** en hello esquina superior derecha, a continuación, haga clic en **Aceptar**.</span><span class="sxs-lookup"><span data-stu-id="9c32d-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="9c32d-211">![Eliminación de App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Eliminación de App2")</span><span class="sxs-lookup"><span data-stu-id="9c32d-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="9c32d-212">Otras referencias</span><span class="sxs-lookup"><span data-stu-id="9c32d-212">See also</span></span>
* [<span data-ttu-id="9c32d-213">Track and debug jobs running on an Apache Spark cluster in HDInsight (Seguimiento y depuración de trabajos que se ejecutan en un clúster de Apache Spark en HDInsight)</span><span class="sxs-lookup"><span data-stu-id="9c32d-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="9c32d-214">Para analistas de datos</span><span class="sxs-lookup"><span data-stu-id="9c32d-214">For data analysts</span></span>

* [<span data-ttu-id="9c32d-215">Creación de aplicaciones de Aprendizaje automático con Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="9c32d-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="9c32d-216">Spark con aprendizaje automático: Use Spark en HDInsight toopredict de resultados de la inspección de alimentos</span><span class="sxs-lookup"><span data-stu-id="9c32d-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="9c32d-217">Análisis del registro del sitio web con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="9c32d-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="9c32d-218">Análisis de datos de telemetría de Application Insights con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="9c32d-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="9c32d-219">Uso de Caffe en Azure HDInsight Spark para el aprendizaje profundo distribuido</span><span class="sxs-lookup"><span data-stu-id="9c32d-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="9c32d-220">Para desarrolladores de Spark</span><span class="sxs-lookup"><span data-stu-id="9c32d-220">For Spark developers</span></span>

* [<span data-ttu-id="9c32d-221">Crear una aplicación independiente con Scala</span><span class="sxs-lookup"><span data-stu-id="9c32d-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="9c32d-222">Ejecutar trabajos de forma remota en un clúster de Spark mediante Livy</span><span class="sxs-lookup"><span data-stu-id="9c32d-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="9c32d-223">Usar el complemento de herramientas de HDInsight para toocreate IntelliJ IDEA y enviar solicitudes de Spark Scala</span><span class="sxs-lookup"><span data-stu-id="9c32d-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="9c32d-224">Streaming con Spark: uso de Spark en HDInsight para compilar aplicaciones de streaming en tiempo real</span><span class="sxs-lookup"><span data-stu-id="9c32d-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="9c32d-225">Usar complemento Herramientas de HDInsight para aplicaciones de IDEA IntelliJ toodebug Spark de forma remota</span><span class="sxs-lookup"><span data-stu-id="9c32d-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="9c32d-226">Uso de cuadernos de Zeppelin con un clúster Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="9c32d-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="9c32d-227">Kernels disponibles para el cuaderno de Jupyter en el clúster Spark para HDInsight</span><span class="sxs-lookup"><span data-stu-id="9c32d-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="9c32d-228">Uso de paquetes externos con cuadernos de Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="9c32d-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="9c32d-229">Instale Jupyter en el equipo y conecte tooan clúster de HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="9c32d-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
