---
title: 'Sugerencias para usar Hadoop en HDInsight basado en Linux: Azure | Microsoft Docs'
description: "Obtenga sugerencias de implementación para usar clústeres de HDInsight basado en Linux (Hadoop) en un entorno de Linux conocido que se ejecuta en la nube de Azure."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: c41c611c-5798-4c14-81cc-bed1e26b5609
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 8c6ff4a6b8617cda9b12be060c7c7bed62cb3f44
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/03/2017
---
# <a name="information-about-using-hdinsight-on-linux"></a><span data-ttu-id="95c6b-103">Información sobre el uso de HDInsight en Linux</span><span class="sxs-lookup"><span data-stu-id="95c6b-103">Information about using HDInsight on Linux</span></span>

<span data-ttu-id="95c6b-104">Los clústeres de Azure HDInsight proporcionan Hadoop en un entorno conocido de Linux, que se ejecuta en la nube de Azure.</span><span class="sxs-lookup"><span data-stu-id="95c6b-104">Azure HDInsight clusters provide Hadoop on a familiar Linux environment, running in the Azure cloud.</span></span> <span data-ttu-id="95c6b-105">En la mayoría de los casos, debiera funcionar exactamente como cualquier otra instalación de Hadoop en Linux.</span><span class="sxs-lookup"><span data-stu-id="95c6b-105">For most things, it should work exactly as any other Hadoop-on-Linux installation.</span></span> <span data-ttu-id="95c6b-106">Este documento detalla las diferencias específicas que debe tener en cuenta.</span><span class="sxs-lookup"><span data-stu-id="95c6b-106">This document calls out specific differences that you should be aware of.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="95c6b-107">Linux es el único sistema operativo que se usa en la versión 3.4 de HDInsight, o en las superiores.</span><span class="sxs-lookup"><span data-stu-id="95c6b-107">Linux is the only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="95c6b-108">Consulte la información sobre la [retirada de HDInsight en Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span><span class="sxs-lookup"><span data-stu-id="95c6b-108">For more information, see [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="95c6b-109">Requisitos previos</span><span class="sxs-lookup"><span data-stu-id="95c6b-109">Prerequisites</span></span>

<span data-ttu-id="95c6b-110">Muchos de los pasos de este documento utilizan las siguientes utilidades, que pueden tener que instalarse en el sistema.</span><span class="sxs-lookup"><span data-stu-id="95c6b-110">Many of the steps in this document use the following utilities, which may need to be installed on your system.</span></span>

* <span data-ttu-id="95c6b-111">[cURL](https://curl.haxx.se/) : se usa para comunicarse con servicios basados en web</span><span class="sxs-lookup"><span data-stu-id="95c6b-111">[cURL](https://curl.haxx.se/) - used to communicate with web-based services</span></span>
* <span data-ttu-id="95c6b-112">[jq](https://stedolan.github.io/jq/) : se usa para analizar documentos JSON</span><span class="sxs-lookup"><span data-stu-id="95c6b-112">[jq](https://stedolan.github.io/jq/) - used to parse JSON documents</span></span>
* <span data-ttu-id="95c6b-113">[CLI de Azure 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (versión preliminar): se usa para administrar servicios de Azure remotamente</span><span class="sxs-lookup"><span data-stu-id="95c6b-113">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (preview) - used to remotely manage Azure services</span></span>

## <a name="users"></a><span data-ttu-id="95c6b-114">Usuarios</span><span class="sxs-lookup"><span data-stu-id="95c6b-114">Users</span></span>

<span data-ttu-id="95c6b-115">A menos que esté [unido a un dominio](hdinsight-domain-joined-introduction.md), HDInsight debe considerarse un sistema de **un solo usuario**.</span><span class="sxs-lookup"><span data-stu-id="95c6b-115">Unless [domain-joined](hdinsight-domain-joined-introduction.md), HDInsight should be considered a **single-user** system.</span></span> <span data-ttu-id="95c6b-116">Se crea una sola cuenta de usuario SSH con el clúster, con permisos de nivel de administrador.</span><span class="sxs-lookup"><span data-stu-id="95c6b-116">A single SSH user account is created with the cluster, with administrator level permissions.</span></span> <span data-ttu-id="95c6b-117">Se pueden crear cuentas adicionales de SSH, pero también tienen acceso de administrador al clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-117">Additional SSH accounts can be created, but they also have administrator access to the cluster.</span></span>

<span data-ttu-id="95c6b-118">HDInsight unido a un dominio admite varios usuarios y una configuración más granular de los permisos y roles.</span><span class="sxs-lookup"><span data-stu-id="95c6b-118">Domain-joined HDInsight supports multiple users and more granular permission and role settings.</span></span> <span data-ttu-id="95c6b-119">Para más información, consulte [Manage domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md) (Administración de clústeres de HDInsight unidos a dominio).</span><span class="sxs-lookup"><span data-stu-id="95c6b-119">For more information, see [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md).</span></span>

## <a name="domain-names"></a><span data-ttu-id="95c6b-120">Nombres de dominio</span><span class="sxs-lookup"><span data-stu-id="95c6b-120">Domain names</span></span>

<span data-ttu-id="95c6b-121">El nombre de dominio completo (FQDN) que se usa al conectarse al clúster desde Internet es **&lt;nombreDeClúster>.azurehdinsight.net** o **&lt;nombreDeClúster-ssh>.azurehdinsight.net** (solo para SSH).</span><span class="sxs-lookup"><span data-stu-id="95c6b-121">The fully qualified domain name (FQDN) to use when connecting to the cluster from the internet is **&lt;clustername>.azurehdinsight.net** or (for SSH only) **&lt;clustername-ssh>.azurehdinsight.net**.</span></span>

<span data-ttu-id="95c6b-122">De forma interna, cada nodo del clúster tiene un nombre que se asigna durante la configuración del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-122">Internally, each node in the cluster has a name that is assigned during cluster configuration.</span></span> <span data-ttu-id="95c6b-123">Para buscar los nombres de clúster, consulte la página **Hosts** en la interfaz de usuario web de Ambari.</span><span class="sxs-lookup"><span data-stu-id="95c6b-123">To find the cluster names, see the **Hosts** page on the Ambari Web UI.</span></span> <span data-ttu-id="95c6b-124">También puede usar lo siguiente para devolver una lista de hosts desde la API de REST de Ambari:</span><span class="sxs-lookup"><span data-stu-id="95c6b-124">You can also use the following to return a list of hosts from the Ambari REST API:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

<span data-ttu-id="95c6b-125">Reemplace **PASSWORD** por la contraseña de la cuenta de administrador y **CLUSTERNAME** por el nombre del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-125">Replace **PASSWORD** with the password of the admin account, and **CLUSTERNAME** with the name of your cluster.</span></span> <span data-ttu-id="95c6b-126">Este comando devuelve un documento JSON que contiene una lista de los hosts del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-126">This command returns a JSON document that contains a list of the hosts in the cluster.</span></span> <span data-ttu-id="95c6b-127">Jq se usa para extraer el valor del elemento `host_name` de cada host.</span><span class="sxs-lookup"><span data-stu-id="95c6b-127">Jq is used to extract the `host_name` element value for each host.</span></span>

<span data-ttu-id="95c6b-128">Si necesita encontrar el nombre del nodo de un servicio específico, puede consultar a Ambari por ese componente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-128">If you need to find the name of the node for a specific service, you can query Ambari for that component.</span></span> <span data-ttu-id="95c6b-129">Por ejemplo, para encontrar los hosts del nodo de nombres HDFS, use el siguiente comando:</span><span class="sxs-lookup"><span data-stu-id="95c6b-129">For example, to find the hosts for the HDFS name node, use the following command:</span></span>

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

<span data-ttu-id="95c6b-130">Este comando devuelve un documento JSON que describe el servicio y, luego, jq extrae solo el valor `host_name` para los hosts.</span><span class="sxs-lookup"><span data-stu-id="95c6b-130">This command returns a JSON document describing the service, and then jq pulls out only the `host_name` value for the hosts.</span></span>

## <a name="remote-access-to-services"></a><span data-ttu-id="95c6b-131">Acceso remoto a los servicios</span><span class="sxs-lookup"><span data-stu-id="95c6b-131">Remote access to services</span></span>

* <span data-ttu-id="95c6b-132">**Ambari (web)** - https://&lt;clustername>.azurehdinsight.net</span><span class="sxs-lookup"><span data-stu-id="95c6b-132">**Ambari (web)** - https://&lt;clustername>.azurehdinsight.net</span></span>

    <span data-ttu-id="95c6b-133">Realice la autenticación con el usuario y la contraseña del administrador de clúster y, a continuación, inicie sesión en Ambari.</span><span class="sxs-lookup"><span data-stu-id="95c6b-133">Authenticate by using the cluster administrator user and password, and then log in to Ambari.</span></span>

    <span data-ttu-id="95c6b-134">La autenticación es texto no cifrado: use siempre HTTPS para asegurarse de que la conexión sea segura.</span><span class="sxs-lookup"><span data-stu-id="95c6b-134">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="95c6b-135">Algunas de la interfaces de usuario web disponibles a través de Ambari acceden a los nodos con un nombre de dominio interno.</span><span class="sxs-lookup"><span data-stu-id="95c6b-135">Some of the web UIs available through Ambari access nodes using an internal domain name.</span></span> <span data-ttu-id="95c6b-136">Los nombres de dominio internos no son accesibles públicamente a través de Internet.</span><span class="sxs-lookup"><span data-stu-id="95c6b-136">Internal domain names are not publicly accessible over the internet.</span></span> <span data-ttu-id="95c6b-137">Puede recibir errores de "servidor no encontrado" al intentar acceder a algunas características a través de Internet.</span><span class="sxs-lookup"><span data-stu-id="95c6b-137">You may receive "server not found" errors when trying to access some features over the Internet.</span></span>
    >
    > <span data-ttu-id="95c6b-138">Para usar la funcionalidad completa de la interfaz de usuario de la web Ambari, usa un túnel SSH para delegar el tráfico web al nodo principal del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-138">To use the full functionality of the Ambari web UI, use an SSH tunnel to proxy web traffic to the cluster head node.</span></span> <span data-ttu-id="95c6b-139">Consulte [Uso de la tunelación SSH para tener acceso a la interfaz de usuario web de Ambari, ResourceManager, JobHistory, NameNode, Oozie y otras interfaces de usuario web](hdinsight-linux-ambari-ssh-tunnel.md)</span><span class="sxs-lookup"><span data-stu-id="95c6b-139">See [Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UIs](hdinsight-linux-ambari-ssh-tunnel.md)</span></span>

* <span data-ttu-id="95c6b-140">**Ambari (REST)** - https://&lt;nombreDeClúster>.azurehdinsight.net/ambari</span><span class="sxs-lookup"><span data-stu-id="95c6b-140">**Ambari (REST)** - https://&lt;clustername>.azurehdinsight.net/ambari</span></span>

    > [!NOTE]
    > <span data-ttu-id="95c6b-141">Realice la autenticación con el usuario y la contraseña del administrador de clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-141">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="95c6b-142">La autenticación es texto no cifrado: use siempre HTTPS para asegurarse de que la conexión sea segura.</span><span class="sxs-lookup"><span data-stu-id="95c6b-142">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="95c6b-143">**WebHCat (Templeton)** - https://&lt;nombreDeClúster>.azurehdinsight.net/templeton</span><span class="sxs-lookup"><span data-stu-id="95c6b-143">**WebHCat (Templeton)** - https://&lt;clustername>.azurehdinsight.net/templeton</span></span>

    > [!NOTE]
    > <span data-ttu-id="95c6b-144">Realice la autenticación con el usuario y la contraseña del administrador de clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-144">Authenticate by using the cluster administrator user and password.</span></span>
    >
    > <span data-ttu-id="95c6b-145">La autenticación es texto no cifrado: use siempre HTTPS para asegurarse de que la conexión sea segura.</span><span class="sxs-lookup"><span data-stu-id="95c6b-145">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</span></span>

* <span data-ttu-id="95c6b-146">**SSH** - &lt;nombreDeClúster>-ssh.azurehdinsight.net en los puertos 22 o 23.</span><span class="sxs-lookup"><span data-stu-id="95c6b-146">**SSH** - &lt;clustername>-ssh.azurehdinsight.net on port 22 or 23.</span></span> <span data-ttu-id="95c6b-147">El puerto 22 se usa para conectarse al nodo principal primario, mientras que el 23 se usa para conectarse al secundario.</span><span class="sxs-lookup"><span data-stu-id="95c6b-147">Port 22 is used to connect to the primary headnode, while 23 is used to connect to the secondary.</span></span> <span data-ttu-id="95c6b-148">Para obtener más información sobre los nodos principales, consulte [Disponibilidad y confiabilidad de clústeres de Hadoop en HDInsight](hdinsight-high-availability-linux.md).</span><span class="sxs-lookup"><span data-stu-id="95c6b-148">For more information on the head nodes, see [Availability and reliability of Hadoop clusters in HDInsight](hdinsight-high-availability-linux.md).</span></span>

    > [!NOTE]
    > <span data-ttu-id="95c6b-149">Solo puede tener acceso a los nodos principales del clúster a través de SSH desde un equipo cliente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-149">You can only access the cluster head nodes through SSH from a client machine.</span></span> <span data-ttu-id="95c6b-150">Una vez conectado, puede acceder a los nodos de trabajo usando SSH desde un nodo principal.</span><span class="sxs-lookup"><span data-stu-id="95c6b-150">Once connected, you can then access the worker nodes by using SSH from a headnode.</span></span>

## <a name="file-locations"></a><span data-ttu-id="95c6b-151">Ubicaciones de archivo</span><span class="sxs-lookup"><span data-stu-id="95c6b-151">File locations</span></span>

<span data-ttu-id="95c6b-152">Puede encontrar los archivos relacionados con Hadoop en los nodos de clúster en `/usr/hdp`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-152">Hadoop-related files can be found on the cluster nodes at `/usr/hdp`.</span></span> <span data-ttu-id="95c6b-153">Este directorio raíz contiene los siguientes subdirectorios:</span><span class="sxs-lookup"><span data-stu-id="95c6b-153">This directory contains the following subdirectories:</span></span>

* <span data-ttu-id="95c6b-154">**2.2.4.9-1**: el nombre de directorio es la versión de Hortonworks Data Platform usada por HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-154">**2.2.4.9-1**: The directory name is the version of the Hortonworks Data Platform used by HDInsight.</span></span> <span data-ttu-id="95c6b-155">El número del clúster puede ser diferente al que aparece aquí.</span><span class="sxs-lookup"><span data-stu-id="95c6b-155">The number on your cluster may be different than the one listed here.</span></span>
* <span data-ttu-id="95c6b-156">**current**: este directorio contiene vínculos a subdirectorios del directorio **2.2.4.9-1**.</span><span class="sxs-lookup"><span data-stu-id="95c6b-156">**current**: This directory contains links to subdirectories under the **2.2.4.9-1** directory.</span></span> <span data-ttu-id="95c6b-157">Este directorio existe para que no tenga que recordar el número de versión.</span><span class="sxs-lookup"><span data-stu-id="95c6b-157">This directory exists so that you don't have to remember the version number.</span></span>

<span data-ttu-id="95c6b-158">Se pueden encontrar datos de ejemplo y archivos JAR en el sistema de archivos distribuido de Hadoop en `/example` y `/HdiSamples`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-158">Example data and JAR files can be found on Hadoop Distributed File System at `/example` and `/HdiSamples`</span></span>

## <a name="hdfs-azure-storage-and-data-lake-store"></a><span data-ttu-id="95c6b-159">HDFS, Azure Storage y Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="95c6b-159">HDFS, Azure Storage, and Data Lake Store</span></span>

<span data-ttu-id="95c6b-160">En la mayoría de las distribuciones de Hadoop, se crean copias de seguridad de HDFS en el almacenamiento local de las máquinas del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-160">In most Hadoop distributions, HDFS is backed by local storage on the machines in the cluster.</span></span> <span data-ttu-id="95c6b-161">El uso de almacenamiento local puede ser costoso para una solución basada en la nube en la que se le cobra por hora o por minuto por los recursos de proceso.</span><span class="sxs-lookup"><span data-stu-id="95c6b-161">Using local storage can be costly for a cloud-based solution where you are charged hourly or by minute for compute resources.</span></span>

<span data-ttu-id="95c6b-162">HDInsight usa blobs de Azure Storage o Azure Data Lake Store como almacén predeterminado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-162">HDInsight uses either blobs in Azure Storage or Azure Data Lake Store as the default store.</span></span> <span data-ttu-id="95c6b-163">Estos servicios ofrecen las siguientes ventajas:</span><span class="sxs-lookup"><span data-stu-id="95c6b-163">These services provide the following benefits:</span></span>

* <span data-ttu-id="95c6b-164">Almacenamiento económico a largo plazo</span><span class="sxs-lookup"><span data-stu-id="95c6b-164">Cheap long-term storage</span></span>
* <span data-ttu-id="95c6b-165">Accesible desde servicios externos, como sitios web, utilidades para carga/descarga de archivos, SDK en varios idiomas y exploradores web.</span><span class="sxs-lookup"><span data-stu-id="95c6b-165">Accessibility from external services such as websites, file upload/download utilities, various language SDKs, and web browsers</span></span>

> [!WARNING]
> <span data-ttu-id="95c6b-166">HDInsight solo admite cuentas de Azure Storage de __uso general__.</span><span class="sxs-lookup"><span data-stu-id="95c6b-166">HDInsight only supports __General-purpose__ Azure Storage accounts.</span></span> <span data-ttu-id="95c6b-167">No admite actualmente el tipo de cuenta de __Blob Storage__.</span><span class="sxs-lookup"><span data-stu-id="95c6b-167">It does not currently support the __Blob storage__ account type.</span></span>

<span data-ttu-id="95c6b-168">Una cuenta de Azure Storage puede almacenar hasta 4,75 TB, si bien los blobs individuales (o archivos desde una perspectiva de HDInsight) solo pueden contener hasta 195 GB.</span><span class="sxs-lookup"><span data-stu-id="95c6b-168">An Azure Storage account can hold up to 4.75 TB, though individual blobs (or files from an HDInsight perspective) can only go up to 195 GB.</span></span> <span data-ttu-id="95c6b-169">Azure Data Lake Store puede crecer de manera dinámica para almacenar billones de archivos, con archivos individuales de más de un petabyte.</span><span class="sxs-lookup"><span data-stu-id="95c6b-169">Azure Data Lake Store can grow dynamically to hold trillions of files, with individual files greater than a petabyte.</span></span> <span data-ttu-id="95c6b-170">Para más información, consulte [Introducción a los blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) y [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span><span class="sxs-lookup"><span data-stu-id="95c6b-170">For more information, see [Understanding blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) and [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).</span></span>

<span data-ttu-id="95c6b-171">Cuando se usa Azure Storage o Data Lake Store, no tiene que hacer nada especial desde HDInsight para acceder a los datos.</span><span class="sxs-lookup"><span data-stu-id="95c6b-171">When using either Azure Storage or Data Lake Store, you don't have to do anything special from HDInsight to access the data.</span></span> <span data-ttu-id="95c6b-172">Por ejemplo, el comando siguiente enumera los archivos existentes en la carpeta `/example/data` sin importar si está almacenada en Azure Storage o en Data Lake Store:</span><span class="sxs-lookup"><span data-stu-id="95c6b-172">For example, the following command lists files in the `/example/data` folder regardless of whether it is stored on Azure Storage or Data Lake Store:</span></span>

    hdfs dfs -ls /example/data

### <a name="uri-and-scheme"></a><span data-ttu-id="95c6b-173">Identificador URI y esquema</span><span class="sxs-lookup"><span data-stu-id="95c6b-173">URI and scheme</span></span>

<span data-ttu-id="95c6b-174">Algunos comandos pueden pedirle que especifique el esquema como parte del identificador URI al acceder a un archivo.</span><span class="sxs-lookup"><span data-stu-id="95c6b-174">Some commands may require you to specify the scheme as part of the URI when accessing a file.</span></span> <span data-ttu-id="95c6b-175">Por ejemplo, el componente Storm-HDFS le pide que especifique el esquema.</span><span class="sxs-lookup"><span data-stu-id="95c6b-175">For example, the Storm-HDFS component requires you to specify the scheme.</span></span> <span data-ttu-id="95c6b-176">Cuando se usa un almacenamiento no predeterminado (almacenamiento agregado como almacenamiento "adicional" al clúster), debe utilizar siempre el esquema como parte del identificador URI.</span><span class="sxs-lookup"><span data-stu-id="95c6b-176">When using non-default storage (storage added as "additional" storage to the cluster), you must always use the scheme as part of the URI.</span></span>

<span data-ttu-id="95c6b-177">Cuando use __Azure Storage__, utilice uno de los siguientes esquemas de URI:</span><span class="sxs-lookup"><span data-stu-id="95c6b-177">When using __Azure Storage__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="95c6b-178">`wasb:///`: accede al almacenamiento predeterminado mediante una comunicación sin cifrar.</span><span class="sxs-lookup"><span data-stu-id="95c6b-178">`wasb:///`: Access default storage using unencrypted communication.</span></span>

* <span data-ttu-id="95c6b-179">`wasbs:///`: accede al almacenamiento predeterminado mediante una comunicación cifrada.</span><span class="sxs-lookup"><span data-stu-id="95c6b-179">`wasbs:///`: Access default storage using encrypted communication.</span></span>  <span data-ttu-id="95c6b-180">El esquema wasbs solo se admite en la versión 3.6 y posteriores de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-180">The wasbs scheme is supported only from HDInsight version 3.6 onwards.</span></span>

* <span data-ttu-id="95c6b-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: se usa al comunicarse con una cuenta de almacenamiento no predeterminada.</span><span class="sxs-lookup"><span data-stu-id="95c6b-181">`wasb://<container-name>@<account-name>.blob.core.windows.net/`: Used when communicating with a non-default storage account.</span></span> <span data-ttu-id="95c6b-182">Por ejemplo, cuando tiene una cuenta de almacenamiento adicional o accede a los datos almacenados en una cuenta de almacenamiento que es accesible públicamente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-182">For example, when you have an additional storage account or when accessing data stored in a publicly accessible storage account.</span></span>

<span data-ttu-id="95c6b-183">Cuando use __Data Lake Store__, utilice uno de los siguientes esquemas de URI:</span><span class="sxs-lookup"><span data-stu-id="95c6b-183">When using __Data Lake Store__, use one of the following URI schemes:</span></span>

* <span data-ttu-id="95c6b-184">`adl:///`: accede al almacén Data Lake Store predeterminado del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-184">`adl:///`: Access the default Data Lake Store for the cluster.</span></span>

* <span data-ttu-id="95c6b-185">`adl://<storage-name>.azuredatalakestore.net/`: se usa al comunicarse con un almacén Data Lake Store no predeterminado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-185">`adl://<storage-name>.azuredatalakestore.net/`: Used when communicating with a non-default Data Lake Store.</span></span> <span data-ttu-id="95c6b-186">También se usa para acceder a datos de fuera del directorio raíz del clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-186">Also used to access data outside the root directory of your HDInsight cluster.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="95c6b-187">Cuando se usa Data Lake Store como almacén predeterminado de HDInsight, debe especificar una ruta de acceso en el almacén que se usará como la raíz de almacenamiento para HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-187">When using Data Lake Store as the default store for HDInsight, you must specify a path within the store to use as the root of HDInsight storage.</span></span> <span data-ttu-id="95c6b-188">La ruta de acceso predeterminada es `/clusters/<cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-188">The default path is `/clusters/<cluster-name>/`.</span></span>
>
> <span data-ttu-id="95c6b-189">Cuando se usa `/` o `adl:///` para acceder a los datos, solo puede acceder a los datos almacenados en la raíz (por ejemplo, `/clusters/<cluster-name>/`) del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-189">When using `/` or `adl:///` to access data, you can only access data stored in the root (for example, `/clusters/<cluster-name>/`) of the cluster.</span></span> <span data-ttu-id="95c6b-190">Para acceder a datos en cualquier lugar del almacén, use el formato `adl://<storage-name>.azuredatalakestore.net/`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-190">To access data anywhere in the store, use the `adl://<storage-name>.azuredatalakestore.net/` format.</span></span>

### <a name="what-storage-is-the-cluster-using"></a><span data-ttu-id="95c6b-191">¿Qué almacenamiento usa el clúster?</span><span class="sxs-lookup"><span data-stu-id="95c6b-191">What storage is the cluster using</span></span>

<span data-ttu-id="95c6b-192">Puede usar Ambari para recuperar la configuración de almacenamiento predeterminada del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-192">You can use Ambari to retrieve the default storage configuration for the cluster.</span></span> <span data-ttu-id="95c6b-193">Utilice el siguiente comando para recuperar información de configuración de HDFS con curl y filtrarla mediante [jq](https://stedolan.github.io/jq/):</span><span class="sxs-lookup"><span data-stu-id="95c6b-193">Use the following command to retrieve HDFS configuration information using curl, and filter it using [jq](https://stedolan.github.io/jq/):</span></span>

```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'```

> [!NOTE]
> <span data-ttu-id="95c6b-194">Esto devuelve la primera configuración aplicada al servidor (`service_config_version=1`), que contiene esta información.</span><span class="sxs-lookup"><span data-stu-id="95c6b-194">This returns the first configuration applied to the server (`service_config_version=1`), which contains this information.</span></span> <span data-ttu-id="95c6b-195">Es posible que tenga que enumerar todas las versiones de configuración para encontrar la más reciente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-195">You may need to list all configuration versions to find the latest one.</span></span>

<span data-ttu-id="95c6b-196">Este comando devuelve un valor similar a los siguientes URI:</span><span class="sxs-lookup"><span data-stu-id="95c6b-196">This command returns a value similar to the following URIs:</span></span>

* <span data-ttu-id="95c6b-197">`wasb://<container-name>@<account-name>.blob.core.windows.net` si usa una cuenta de Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="95c6b-197">`wasb://<container-name>@<account-name>.blob.core.windows.net` if using an Azure Storage account.</span></span>

    <span data-ttu-id="95c6b-198">El nombre de la cuenta es el nombre de la cuenta de Azure Storage, mientras que el nombre del contenedor es el contenedor de blobs que es la raíz del almacenamiento del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-198">The account name is the name of the Azure Storage account, while the container name is the blob container that is the root of the cluster storage.</span></span>

* <span data-ttu-id="95c6b-199">`adl://home` si usa Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="95c6b-199">`adl://home` if using Azure Data Lake Store.</span></span> <span data-ttu-id="95c6b-200">Para obtener el nombre de la instancia de Data Lake Store, use la siguiente llamada REST:</span><span class="sxs-lookup"><span data-stu-id="95c6b-200">To get the Data Lake Store name, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.hostname"] | select(. != null)'```

    <span data-ttu-id="95c6b-201">Este comando devuelve el siguiente nombre de host: `<data-lake-store-account-name>.azuredatalakestore.net`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-201">This command returns the following host name: `<data-lake-store-account-name>.azuredatalakestore.net`.</span></span>

    <span data-ttu-id="95c6b-202">Para obtener el directorio del almacén que es la raíz de HDInsight, use la siguiente llamada REST:</span><span class="sxs-lookup"><span data-stu-id="95c6b-202">To get the directory within the store that is the root for HDInsight, use the following REST call:</span></span>

    ```curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.mountpoint"] | select(. != null)'```

    <span data-ttu-id="95c6b-203">Este comando devuelve una ruta de acceso similar a la siguiente: `/clusters/<hdinsight-cluster-name>/`.</span><span class="sxs-lookup"><span data-stu-id="95c6b-203">This command returns a path similar to the following path: `/clusters/<hdinsight-cluster-name>/`.</span></span>

<span data-ttu-id="95c6b-204">También puede encontrar la información de almacenamiento mediante Azure Portal realizando los siguientes pasos:</span><span class="sxs-lookup"><span data-stu-id="95c6b-204">You can also find the storage information using the Azure portal by using the following steps:</span></span>

1. <span data-ttu-id="95c6b-205">En [Azure Portal](https://portal.azure.com/), seleccione el clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-205">In the [Azure portal](https://portal.azure.com/), select your HDInsight cluster.</span></span>

2. <span data-ttu-id="95c6b-206">En la sección **Propiedades**, seleccione **Cuentas de almacenamiento**.</span><span class="sxs-lookup"><span data-stu-id="95c6b-206">From the **Properties** section, select **Storage Accounts**.</span></span> <span data-ttu-id="95c6b-207">Se muestra la información de almacenamiento del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-207">The storage information for the cluster is displayed.</span></span>

### <a name="how-do-i-access-files-from-outside-hdinsight"></a><span data-ttu-id="95c6b-208">¿Cómo accedo a los archivos desde fuera de HDInsight?</span><span class="sxs-lookup"><span data-stu-id="95c6b-208">How do I access files from outside HDInsight</span></span>

<span data-ttu-id="95c6b-209">Hay varias maneras de acceder a los datos desde fuera del clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-209">There are a various ways to access data from outside the HDInsight cluster.</span></span> <span data-ttu-id="95c6b-210">Los siguientes son algunos vínculos a las utilidades y SDK que puede usar para trabajar con los datos:</span><span class="sxs-lookup"><span data-stu-id="95c6b-210">The following are a few links to utilities and SDKs that can be used to work with your data:</span></span>

<span data-ttu-id="95c6b-211">Si usa __Azure Storage__, consulte los siguientes vínculos para ver las formas en que puede acceder a los datos:</span><span class="sxs-lookup"><span data-stu-id="95c6b-211">If using __Azure Storage__, see the following links for ways that you can access your data:</span></span>

* <span data-ttu-id="95c6b-212">[CLI de Azure 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): comandos de la interfaz de la línea de comandos para trabajar con Azure.</span><span class="sxs-lookup"><span data-stu-id="95c6b-212">[Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2): Command-Line interface commands for working with Azure.</span></span> <span data-ttu-id="95c6b-213">Después de la instalación, use el comando `az storage` para obtener ayuda sobre el uso del almacenamiento o `az storage blob` para comandos específicos para los blobs.</span><span class="sxs-lookup"><span data-stu-id="95c6b-213">After installing, use the `az storage` command for help on using storage, or `az storage blob` for blob-specific commands.</span></span>
* <span data-ttu-id="95c6b-214">[blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): un script de Python para trabajar con blobs en Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="95c6b-214">[blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage): A python script for working with blobs in Azure Storage.</span></span>
* <span data-ttu-id="95c6b-215">Diversos SDK:</span><span class="sxs-lookup"><span data-stu-id="95c6b-215">Various SDKs:</span></span>

    * [<span data-ttu-id="95c6b-216">Java</span><span class="sxs-lookup"><span data-stu-id="95c6b-216">Java</span></span>](https://github.com/Azure/azure-sdk-for-java)
    * [<span data-ttu-id="95c6b-217">Node.js</span><span class="sxs-lookup"><span data-stu-id="95c6b-217">Node.js</span></span>](https://github.com/Azure/azure-sdk-for-node)
    * [<span data-ttu-id="95c6b-218">PHP</span><span class="sxs-lookup"><span data-stu-id="95c6b-218">PHP</span></span>](https://github.com/Azure/azure-sdk-for-php)
    * [<span data-ttu-id="95c6b-219">Python</span><span class="sxs-lookup"><span data-stu-id="95c6b-219">Python</span></span>](https://github.com/Azure/azure-sdk-for-python)
    * [<span data-ttu-id="95c6b-220">Ruby</span><span class="sxs-lookup"><span data-stu-id="95c6b-220">Ruby</span></span>](https://github.com/Azure/azure-sdk-for-ruby)
    * [<span data-ttu-id="95c6b-221">.NET</span><span class="sxs-lookup"><span data-stu-id="95c6b-221">.NET</span></span>](https://github.com/Azure/azure-sdk-for-net)
    * [<span data-ttu-id="95c6b-222">API de REST de almacenamiento</span><span class="sxs-lookup"><span data-stu-id="95c6b-222">Storage REST API</span></span>](https://msdn.microsoft.com/library/azure/dd135733.aspx)

<span data-ttu-id="95c6b-223">Si usa __Azure Data Lake Store__, consulte los siguientes vínculos para ver las formas en que puede acceder a los datos:</span><span class="sxs-lookup"><span data-stu-id="95c6b-223">If using __Azure Data Lake Store__, see the following links for ways that you can access your data:</span></span>

* [<span data-ttu-id="95c6b-224">Explorador web</span><span class="sxs-lookup"><span data-stu-id="95c6b-224">Web browser</span></span>](../data-lake-store/data-lake-store-get-started-portal.md)
* [<span data-ttu-id="95c6b-225">PowerShell</span><span class="sxs-lookup"><span data-stu-id="95c6b-225">PowerShell</span></span>](../data-lake-store/data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="95c6b-226">CLI de Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="95c6b-226">Azure CLI 2.0</span></span>](../data-lake-store/data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="95c6b-227">API de REST de WebHDFS</span><span class="sxs-lookup"><span data-stu-id="95c6b-227">WebHDFS REST API</span></span>](../data-lake-store/data-lake-store-get-started-rest-api.md)
* [<span data-ttu-id="95c6b-228">Data Lake Tools para Visual Studio</span><span class="sxs-lookup"><span data-stu-id="95c6b-228">Data Lake Tools for Visual Studio</span></span>](https://www.microsoft.com/download/details.aspx?id=49504)
* [<span data-ttu-id="95c6b-229">.NET</span><span class="sxs-lookup"><span data-stu-id="95c6b-229">.NET</span></span>](../data-lake-store/data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="95c6b-230">Java</span><span class="sxs-lookup"><span data-stu-id="95c6b-230">Java</span></span>](../data-lake-store/data-lake-store-get-started-java-sdk.md)
* [<span data-ttu-id="95c6b-231">Python</span><span class="sxs-lookup"><span data-stu-id="95c6b-231">Python</span></span>](../data-lake-store/data-lake-store-get-started-python.md)

## <span data-ttu-id="95c6b-232"><a name="scaling"></a>Escalar el clúster</span><span class="sxs-lookup"><span data-stu-id="95c6b-232"><a name="scaling"></a>Scaling your cluster</span></span>

<span data-ttu-id="95c6b-233">La característica de escalado de clúster permite cambiar de forma dinámica la cantidad de nodos de datos que usa un clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-233">The cluster scaling feature allows you to dynamically change the number of data nodes used by a cluster.</span></span> <span data-ttu-id="95c6b-234">Puedes realizar operaciones de escala mientras se están ejecutando otros trabajos o procesos en un clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-234">You can perform scaling operations while other jobs or processes are running on a cluster.</span></span>

<span data-ttu-id="95c6b-235">Los diferentes tipos de clúster se ven afectados por la escala de esta manera:</span><span class="sxs-lookup"><span data-stu-id="95c6b-235">The different cluster types are affected by scaling as follows:</span></span>

* <span data-ttu-id="95c6b-236">**Hadoop**: al reducir verticalmente el número de nodos en un clúster, se reinician algunos de los servicios del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-236">**Hadoop**: When scaling down the number of nodes in a cluster, some of the services in the cluster are restarted.</span></span> <span data-ttu-id="95c6b-237">Las operaciones de escalado pueden provocar errores en los trabajos pendientes o en ejecución al completarse la operación de escalado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-237">Scaling operations can cause jobs running or pending to fail at the completion of the scaling operation.</span></span> <span data-ttu-id="95c6b-238">Sin embargo, puedes volver a enviar los trabajos una vez finalizada la operación.</span><span class="sxs-lookup"><span data-stu-id="95c6b-238">You can resubmit the jobs once the operation is complete.</span></span>
* <span data-ttu-id="95c6b-239">**HBase**: los servidores regionales se equilibran automáticamente en unos pocos minutos tras completar la operación de escalado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-239">**HBase**: Regional servers are automatically balanced within a few minutes after completion of the scaling operation.</span></span> <span data-ttu-id="95c6b-240">Para equilibrar manualmente servidores regionales, siga estos pasos:</span><span class="sxs-lookup"><span data-stu-id="95c6b-240">To manually balance regional servers, use the following steps:</span></span>

    1. <span data-ttu-id="95c6b-241">Conéctate al clúster de HDInsight con SSH:</span><span class="sxs-lookup"><span data-stu-id="95c6b-241">Connect to the HDInsight cluster using SSH.</span></span> <span data-ttu-id="95c6b-242">Para más información, consulte [Uso SSH con HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span><span class="sxs-lookup"><span data-stu-id="95c6b-242">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

    2. <span data-ttu-id="95c6b-243">Usa lo siguiente para iniciar el shell de HBase:</span><span class="sxs-lookup"><span data-stu-id="95c6b-243">Use the following to start the HBase shell:</span></span>

            hbase shell

    3. <span data-ttu-id="95c6b-244">Una vez que se haya cargado el shell de HBase, usa lo siguiente para equilibrar manualmente los servidores regionales:</span><span class="sxs-lookup"><span data-stu-id="95c6b-244">Once the HBase shell has loaded, use the following to manually balance the regional servers:</span></span>

            balancer

* <span data-ttu-id="95c6b-245">**Storm**: debe reequilibrar todas las topologías Storm en ejecución después de realizar una operación de escalado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-245">**Storm**: You should rebalance any running Storm topologies after a scaling operation has been performed.</span></span> <span data-ttu-id="95c6b-246">El reequilibrado permite que la topología vuelva a ajustar la configuración de paralelismo en función del nuevo número de nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-246">Rebalancing allows the topology to readjust parallelism settings based on the new number of nodes in the cluster.</span></span> <span data-ttu-id="95c6b-247">Para volver a equilibrar las topologías en ejecución, usa una de las siguientes opciones:</span><span class="sxs-lookup"><span data-stu-id="95c6b-247">To rebalance running topologies, use one of the following options:</span></span>

    * <span data-ttu-id="95c6b-248">**SSH**: conéctese al servidor y use el siguiente comando para volver a equilibrar una topología:</span><span class="sxs-lookup"><span data-stu-id="95c6b-248">**SSH**: Connect to the server and use the following command to rebalance a topology:</span></span>

            storm rebalance TOPOLOGYNAME

        <span data-ttu-id="95c6b-249">También puedes especificar parámetros para reemplazar las sugerencias de paralelismo que proporcionó originalmente la topología.</span><span class="sxs-lookup"><span data-stu-id="95c6b-249">You can also specify parameters to override the parallelism hints originally provided by the topology.</span></span> <span data-ttu-id="95c6b-250">Por ejemplo, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` vuelve a configurar la topología en 5 procesos de trabajo, 3 ejecutores para el componente blue-spout y 10 ejecutores para el componente yellow-bolt.</span><span class="sxs-lookup"><span data-stu-id="95c6b-250">For example, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` reconfigures the topology to 5 worker processes, 3 executors for the blue-spout component, and 10 executors for the yellow-bolt component.</span></span>

    * <span data-ttu-id="95c6b-251">**Interfaz de usuario de Storm**: siga estos pasos para reequilibrar una topología mediante la interfaz de usuario de Storm.</span><span class="sxs-lookup"><span data-stu-id="95c6b-251">**Storm UI**: Use the following steps to rebalance a topology using the Storm UI.</span></span>

        1. <span data-ttu-id="95c6b-252">Abra **https://CLUSTERNAME.azurehdinsight.net/stormui** en su explorador web, donde CLUSTERNAME es el nombre del clúster de Storm.</span><span class="sxs-lookup"><span data-stu-id="95c6b-252">Open **https://CLUSTERNAME.azurehdinsight.net/stormui** in your web browser, where CLUSTERNAME is the name of your Storm cluster.</span></span> <span data-ttu-id="95c6b-253">Si se le solicite, escriba el nombre de administrador (admin) del clúster de HDInsight y la contraseña que especificó al crear el clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-253">If prompted, enter the HDInsight cluster administrator (admin) name and password you specified when creating the cluster.</span></span>
        2. <span data-ttu-id="95c6b-254">Seleccione la topología que quiere equilibrar y, después, seleccione el botón **Reequilibrar**.</span><span class="sxs-lookup"><span data-stu-id="95c6b-254">Select the topology you wish to rebalance, then select the **Rebalance** button.</span></span> <span data-ttu-id="95c6b-255">Especifica el retraso antes de realizar la operación de reequilibrio.</span><span class="sxs-lookup"><span data-stu-id="95c6b-255">Enter the delay before the rebalance operation is performed.</span></span>

<span data-ttu-id="95c6b-256">Para obtener información específica sobre cómo ampliar tu clúster de HDInsight, consulta:</span><span class="sxs-lookup"><span data-stu-id="95c6b-256">For specific information on scaling your HDInsight cluster, see:</span></span>

* [<span data-ttu-id="95c6b-257">Administración de clústeres de Hadoop en HDInsight mediante Azure Portal</span><span class="sxs-lookup"><span data-stu-id="95c6b-257">Manage Hadoop clusters in HDInsight by using the Azure portal</span></span>](hdinsight-administer-use-portal-linux.md#scale-clusters)
* [<span data-ttu-id="95c6b-258">Administración de clústeres de Hadoop en HDInsight con Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="95c6b-258">Manage Hadoop clusters in HDInsight by using Azure PowerShell</span></span>](hdinsight-administer-use-command-line.md#scale-clusters)

## <a name="how-do-i-install-hue-or-other-hadoop-component"></a><span data-ttu-id="95c6b-259">¿Cómo puedo instalar Hue (u otro componente de Hadoop)?</span><span class="sxs-lookup"><span data-stu-id="95c6b-259">How do I install Hue (or other Hadoop component)?</span></span>

<span data-ttu-id="95c6b-260">HDInsight es un servicio administrado.</span><span class="sxs-lookup"><span data-stu-id="95c6b-260">HDInsight is a managed service.</span></span> <span data-ttu-id="95c6b-261">Si Azure detecta un problema con el clúster, podría eliminar el nodo que ha dado error y crear un nodo para sustituirlo.</span><span class="sxs-lookup"><span data-stu-id="95c6b-261">If Azure detects a problem with the cluster, it may delete the failing node and create a node to replace it.</span></span> <span data-ttu-id="95c6b-262">Si instala manualmente elementos en el clúster, no se conservan cuando se produce esta operación.</span><span class="sxs-lookup"><span data-stu-id="95c6b-262">If you manually install things on the cluster, they are not persisted when this operation occurs.</span></span> <span data-ttu-id="95c6b-263">En su lugar, use [acciones de script de HDInsight](hdinsight-hadoop-customize-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="95c6b-263">Instead, use [HDInsight Script Actions](hdinsight-hadoop-customize-cluster.md).</span></span> <span data-ttu-id="95c6b-264">Una acción de script se puede usar para realizar los siguientes cambios:</span><span class="sxs-lookup"><span data-stu-id="95c6b-264">A script action can be used to make the following changes:</span></span>

* <span data-ttu-id="95c6b-265">Instalar y configurar un servicio o un sitio web, como Spark o Hue.</span><span class="sxs-lookup"><span data-stu-id="95c6b-265">Install and configure a service or web site such as Spark or Hue.</span></span>
* <span data-ttu-id="95c6b-266">Instalar y configurar un componente que requiera cambios de configuración en varios nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-266">Install and configure a component that requires configuration changes on multiple nodes in the cluster.</span></span> <span data-ttu-id="95c6b-267">Por ejemplo, una variable de entorno requerida o la creación de un directorio de registro o de un archivo de configuración.</span><span class="sxs-lookup"><span data-stu-id="95c6b-267">For example, a required environment variable, creating of a logging directory, or creation of a configuration file.</span></span>

<span data-ttu-id="95c6b-268">Las acciones de script son scripts de Bash.</span><span class="sxs-lookup"><span data-stu-id="95c6b-268">Script Actions are Bash scripts.</span></span> <span data-ttu-id="95c6b-269">Los scripts se ejecutan durante el aprovisionamiento del clúster y se pueden usar para instalar y configurar componentes adicionales en el clúster.</span><span class="sxs-lookup"><span data-stu-id="95c6b-269">The scripts run during cluster provisioning, and can be used to install and configure additional components on the cluster.</span></span> <span data-ttu-id="95c6b-270">Se proporcionan scripts de ejemplo para instalar los componentes siguientes:</span><span class="sxs-lookup"><span data-stu-id="95c6b-270">Example scripts are provided for installing the following components:</span></span>

* [<span data-ttu-id="95c6b-271">Hue</span><span class="sxs-lookup"><span data-stu-id="95c6b-271">Hue</span></span>](hdinsight-hadoop-hue-linux.md)
* [<span data-ttu-id="95c6b-272">Giraph.</span><span class="sxs-lookup"><span data-stu-id="95c6b-272">Giraph</span></span>](hdinsight-hadoop-giraph-install-linux.md)
* [<span data-ttu-id="95c6b-273">Solr</span><span class="sxs-lookup"><span data-stu-id="95c6b-273">Solr</span></span>](hdinsight-hadoop-solr-install-linux.md)

<span data-ttu-id="95c6b-274">Para obtener información sobre el desarrollo de sus propias acciones de script, consulte [Desarrollo de la acción de script con HDInsight](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="95c6b-274">For information on developing your own Script Actions, see [Script Action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

### <a name="jar-files"></a><span data-ttu-id="95c6b-275">Archivos JAR</span><span class="sxs-lookup"><span data-stu-id="95c6b-275">Jar files</span></span>

<span data-ttu-id="95c6b-276">Algunas tecnologías de Hadoop se proporcionan en archivos jar independientes con funciones que se usan como parte de un trabajo de MapReduce o desde dentro de Pig o Hive.</span><span class="sxs-lookup"><span data-stu-id="95c6b-276">Some Hadoop technologies are provided in self-contained jar files that contain functions used as part of a MapReduce job, or from inside Pig or Hive.</span></span> <span data-ttu-id="95c6b-277">Aunque se pueden instalar mediante acciones de script, a menudo, no requieren ninguna configuración y se pueden cargar en el clúster después de haberlos aprovisionado y usado directamente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-277">While these can be installed using Script Actions, they often don't require any setup and can be uploaded to the cluster after provisioning and used directly.</span></span> <span data-ttu-id="95c6b-278">Si desea asegurarse de que el componente sobreviva a la creación de una nueva imagen del clúster, puede almacenar el archivo jar en el almacenamiento predeterminado del clúster (WASB o ADL).</span><span class="sxs-lookup"><span data-stu-id="95c6b-278">If you want to make sure the component survives reimaging of the cluster, you can store the jar file in the default storage for your cluster (WASB or ADL).</span></span>

<span data-ttu-id="95c6b-279">Por ejemplo, si desea usar la versión más reciente de [DataFu](http://datafu.incubator.apache.org/), puede descargar un archivo jar que contiene el proyecto y cargarlo en el clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="95c6b-279">For example, if you want to use the latest version of [DataFu](http://datafu.incubator.apache.org/), you can download a jar containing the project and upload it to the HDInsight cluster.</span></span> <span data-ttu-id="95c6b-280">A continuación, siga las instrucciones que aparecen en la documentación de DataFu sobre el uso con Pig o Hive.</span><span class="sxs-lookup"><span data-stu-id="95c6b-280">Then follow the DataFu documentation on how to use it from Pig or Hive.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="95c6b-281">Algunos componentes que son archivos jar independientes se proporcionan con HDInsight, pero no están en la ruta de acceso.</span><span class="sxs-lookup"><span data-stu-id="95c6b-281">Some components that are standalone jar files are provided with HDInsight, but are not in the path.</span></span> <span data-ttu-id="95c6b-282">Si está buscando un componente específico, puede utilizar lo siguiente para buscarlo en el clúster:</span><span class="sxs-lookup"><span data-stu-id="95c6b-282">If you are looking for a specific component, you can use the follow to search for it on your cluster:</span></span>
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> <span data-ttu-id="95c6b-283">Este comando devuelve la ruta de acceso de cualquier archivo jar coincidente.</span><span class="sxs-lookup"><span data-stu-id="95c6b-283">This command returns the path of any matching jar files.</span></span>

<span data-ttu-id="95c6b-284">Para usar otra versión de un componente, cargue la versión que necesita y úsela en los trabajos.</span><span class="sxs-lookup"><span data-stu-id="95c6b-284">To use a different version of a component, upload the version you need and use it in your jobs.</span></span>

> [!WARNING]
> <span data-ttu-id="95c6b-285">Los componentes proporcionados con el clúster de HDInsight son totalmente compatibles. Además, el soporte técnico de Microsoft lo ayudará a aislar y resolver problemas relacionados con estos componentes.</span><span class="sxs-lookup"><span data-stu-id="95c6b-285">Components provided with the HDInsight cluster are fully supported and Microsoft Support helps to isolate and resolve issues related to these components.</span></span>
>
> <span data-ttu-id="95c6b-286">Los componentes personalizados reciben soporte técnico comercialmente razonable para ayudarle a solucionar el problema.</span><span class="sxs-lookup"><span data-stu-id="95c6b-286">Custom components receive commercially reasonable support to help you to further troubleshoot the issue.</span></span> <span data-ttu-id="95c6b-287">Esto podría resolver el problema o pedirle que forme parte de los canales disponibles para las tecnologías de código abierto donde se encuentra la más amplia experiencia para esa tecnología.</span><span class="sxs-lookup"><span data-stu-id="95c6b-287">This might result in resolving the issue OR asking you to engage available channels for the open source technologies where deep expertise for that technology is found.</span></span> <span data-ttu-id="95c6b-288">Por ejemplo, hay diversos sitios de la comunidad que se pueden usar, como el [foro de MSDN para HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight), [http://stackoverflow.com](http://stackoverflow.com).</span><span class="sxs-lookup"><span data-stu-id="95c6b-288">For example, there are many community sites that can be used, like: [MSDN forum for HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight), [http://stackoverflow.com](http://stackoverflow.com).</span></span> <span data-ttu-id="95c6b-289">Además, los proyectos de Apache tienen sitios del proyecto en [http://apache.org](http://apache.org), por ejemplo, [Hadoop](http://hadoop.apache.org/) y [Spark](http://spark.apache.org/).</span><span class="sxs-lookup"><span data-stu-id="95c6b-289">Also Apache projects have project sites on [http://apache.org](http://apache.org), for example: [Hadoop](http://hadoop.apache.org/), [Spark](http://spark.apache.org/).</span></span>

## <a name="next-steps"></a><span data-ttu-id="95c6b-290">Pasos siguientes</span><span class="sxs-lookup"><span data-stu-id="95c6b-290">Next steps</span></span>

* [<span data-ttu-id="95c6b-291">Migrate from Windows-based HDInsight to Linux-based (Migración desde HDInsight basado en Windows a HDInsight basado en Linux)</span><span class="sxs-lookup"><span data-stu-id="95c6b-291">Migrate from Windows-based HDInsight to Linux-based</span></span>](hdinsight-migrate-from-windows-to-linux.md)
* [<span data-ttu-id="95c6b-292">Uso de Hive con HDInsight</span><span class="sxs-lookup"><span data-stu-id="95c6b-292">Use Hive with HDInsight</span></span>](hdinsight-use-hive.md)
* [<span data-ttu-id="95c6b-293">Uso de Pig con HDInsight</span><span class="sxs-lookup"><span data-stu-id="95c6b-293">Use Pig with HDInsight</span></span>](hdinsight-use-pig.md)
* [<span data-ttu-id="95c6b-294">Uso de trabajos de MapReduce con HDInsight</span><span class="sxs-lookup"><span data-stu-id="95c6b-294">Use MapReduce jobs with HDInsight</span></span>](hdinsight-use-mapreduce.md)
