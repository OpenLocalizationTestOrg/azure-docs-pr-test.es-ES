---
title: "Introducción a Spark en Azure HDInsight | Microsoft Docs"
description: "En este artículo se proporciona una introducción a Spark en HDInsight y los diferentes escenarios en los que puede usar un clúster de Spark en HDInsight."
keywords: "qué es apache spark, clúster de spark, introducción a spark, spark en hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="d70f1-104">Introducción a Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="d70f1-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="d70f1-105">En este artículo se proporciona una introducción a Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="d70f1-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> es un marco de procesamiento paralelo de código abierto que admite el procesamiento en memoria para mejorar el rendimiento de las aplicaciones analíticas de Big Data.</span><span class="sxs-lookup"><span data-stu-id="d70f1-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="d70f1-107">Un clúster de Spark en HDInsight es compatible con Azure Storage (WASB), así como con Azure Data Lake Store, por lo que los datos existentes almacenados en Azure pueden procesarse fácilmente por medio de un clúster de Spark.</span><span class="sxs-lookup"><span data-stu-id="d70f1-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="d70f1-108">Cuando crea un clúster de Spark en HDInsight, aprovisiona recursos de proceso de Azure con Spark instalado y configurado.</span><span class="sxs-lookup"><span data-stu-id="d70f1-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="d70f1-109">Solamente se tardan unos diez minutos en crear un clúster Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="d70f1-110">Los datos que se van a procesar se almacenan en Azure Storage o Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="d70f1-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="d70f1-111">Consulte [Uso de Azure Storage con HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="d70f1-112">**Para crear un clúster de Spark en HDInsight**, consulte el [inicio rápido sobre cómo crear un clúster de Spark en HDInsight y ejecutar consultas interactivas mediante Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="d70f1-113">¿Qué es Apache Spark en Azure HDInsight?</span><span class="sxs-lookup"><span data-stu-id="d70f1-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="d70f1-114">Los clústeres de Spark en HDInsight ofrecen un servicio de Spark completamente administrado.</span><span class="sxs-lookup"><span data-stu-id="d70f1-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="d70f1-115">Aquí se enumeran las ventajas de crear un clúster de Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="d70f1-116">Característica</span><span class="sxs-lookup"><span data-stu-id="d70f1-116">Feature</span></span> | <span data-ttu-id="d70f1-117">Descripción</span><span class="sxs-lookup"><span data-stu-id="d70f1-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="d70f1-118">Facilidad de creación de clústeres de Spark</span><span class="sxs-lookup"><span data-stu-id="d70f1-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="d70f1-119">Puede crear un clúster de Spark en HDInsight en cuestión de minutos mediante Azure Portal, Azure PowerShell o el SDK de .NET de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="d70f1-120">Consulte [Introducción al clúster de Spark en HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="d70f1-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="d70f1-121">Facilidad de uso</span><span class="sxs-lookup"><span data-stu-id="d70f1-121">Ease of use</span></span> |<span data-ttu-id="d70f1-122">El clúster de Spark en HDInsight incluye notebooks de Jupyter y Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="d70f1-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="d70f1-123">Puede usarlos para el procesamiento y la visualización de datos interactivos.</span><span class="sxs-lookup"><span data-stu-id="d70f1-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="d70f1-124">API de REST</span><span class="sxs-lookup"><span data-stu-id="d70f1-124">REST APIs</span></span> |<span data-ttu-id="d70f1-125">Los clústeres de Spark en HDInsight incluyen [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), un servidor de trabajos de Spark basado en una API de REST para enviar y supervisar trabajos de forma remota.</span><span class="sxs-lookup"><span data-stu-id="d70f1-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="d70f1-126">Compatibilidad con Almacén de Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="d70f1-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="d70f1-127">Se puede configurar un clúster de Spark en HDInsight para que utilice Azure Data Lake Store como almacenamiento adicional, además de como almacenamiento principal (solo con clústeres de HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="d70f1-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="d70f1-128">Para más información acerca del Almacén de Data Lake, consulte la página con [información general del Almacén de Azure Data Lake](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="d70f1-129">Integración con servicios de Azure</span><span class="sxs-lookup"><span data-stu-id="d70f1-129">Integration with Azure services</span></span> |<span data-ttu-id="d70f1-130">Un clúster de Spark en HDInsight incluye un conector a Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="d70f1-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="d70f1-131">Los clientes pueden compilar aplicaciones de streaming con los Centros de eventos, además de con [Kafka](http://kafka.apache.org/), que ya está disponible como parte de Spark.</span><span class="sxs-lookup"><span data-stu-id="d70f1-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="d70f1-132">Compatibilidad con R Server</span><span class="sxs-lookup"><span data-stu-id="d70f1-132">Support for R Server</span></span> | <span data-ttu-id="d70f1-133">Puede configurar R Server en el clúster Spark de HDInsight para ejecutar cálculos R distribuidos con las velocidades prometidas mediante un clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="d70f1-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="d70f1-134">Para obtener más información, consulte [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md)(Introducción a R Server en HDInsight).</span><span class="sxs-lookup"><span data-stu-id="d70f1-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="d70f1-135">Integración con IDE de terceros</span><span class="sxs-lookup"><span data-stu-id="d70f1-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="d70f1-136">HDInsight proporciona complementos para IDE tales como IntelliJ IDEA y Eclipse que puede usar para crear y enviar solicitudes a un clúster de Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="d70f1-137">Para más información, consulte [Uso del kit de herramientas de Azure para IDEA IntelliJ](hdinsight-apache-spark-intellij-tool-plugin.md) y [Uso del kit de herramientas de Azure para Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="d70f1-138">Consultas simultáneas</span><span class="sxs-lookup"><span data-stu-id="d70f1-138">Concurrent Queries</span></span> |<span data-ttu-id="d70f1-139">Los clústeres de Spark en HDInsight admiten consultas simultáneas.</span><span class="sxs-lookup"><span data-stu-id="d70f1-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="d70f1-140">Esto permite que varias consultas de un usuario o varias consultas de diversos usuarios y aplicaciones compartan los mismos recursos de clúster.</span><span class="sxs-lookup"><span data-stu-id="d70f1-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="d70f1-141">Almacenamiento en caché en SSD</span><span class="sxs-lookup"><span data-stu-id="d70f1-141">Caching on SSDs</span></span> |<span data-ttu-id="d70f1-142">Puede almacenar datos en caché, ya sea en memoria o en SSD conectadas a los nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="d70f1-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="d70f1-143">El almacenamiento en memoria proporciona el mejor rendimiento para las consultas pero podría ser costoso; el almacenamiento en SSD ofrece una opción excelente para mejorar el rendimiento de las consultas sin necesidad de crear un clúster de un tamaño que admita todo el conjunto de datos en memoria.</span><span class="sxs-lookup"><span data-stu-id="d70f1-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="d70f1-144">Integración con herramientas de BI</span><span class="sxs-lookup"><span data-stu-id="d70f1-144">Integration with BI Tools</span></span> |<span data-ttu-id="d70f1-145">Los clústeres de Spark en HDInsight ofrecen conectores para herramientas de BI como [Power BI](http://www.powerbi.com/) y [Tableau](http://www.tableau.com/products/desktop) para el análisis de datos.</span><span class="sxs-lookup"><span data-stu-id="d70f1-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="d70f1-146">Bibliotecas de Anaconda precargadas</span><span class="sxs-lookup"><span data-stu-id="d70f1-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="d70f1-147">Los clústeres Spark en HDInsight incluyen bibliotecas de Anaconda preinstaladas.</span><span class="sxs-lookup"><span data-stu-id="d70f1-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="d70f1-148">[Anaconda](http://docs.continuum.io/anaconda/) ofrece prácticamente 200 bibliotecas para el aprendizaje automático, el análisis de datos, la visualización, etc.</span><span class="sxs-lookup"><span data-stu-id="d70f1-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="d70f1-149">Escalabilidad</span><span class="sxs-lookup"><span data-stu-id="d70f1-149">Scalability</span></span> |<span data-ttu-id="d70f1-150">Aunque puede especificar el número de nodos del clúster durante la creación, puede que desee aumentar o reducir el clúster para que coincida con la carga de trabajo.</span><span class="sxs-lookup"><span data-stu-id="d70f1-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="d70f1-151">Todos los clústeres de HDInsight le permiten cambiar el número de nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="d70f1-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="d70f1-152">Además, se pueden quitar clústeres de Spark sin que se pierdan datos, ya que todos están almacenados en Azure Storage o Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="d70f1-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="d70f1-153">Soporte técnico ininterrumpido</span><span class="sxs-lookup"><span data-stu-id="d70f1-153">24/7 Support</span></span> |<span data-ttu-id="d70f1-154">Los clústeres de Spark en HDInsight incluyen soporte técnico ininterrumpido de nivel empresarial y un Acuerdo de Nivel de Servicio del 99,9 % de tiempo de actividad.</span><span class="sxs-lookup"><span data-stu-id="d70f1-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="d70f1-155">¿Cuáles son los casos de uso para Spark en HDInsight?</span><span class="sxs-lookup"><span data-stu-id="d70f1-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="d70f1-156">Los clústeres de Spark en HDInsight hacen posibles los siguientes escenarios clave.</span><span class="sxs-lookup"><span data-stu-id="d70f1-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="d70f1-157">Análisis interactivo de datos y BI</span><span class="sxs-lookup"><span data-stu-id="d70f1-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="d70f1-158">Vea un tutorial</span><span class="sxs-lookup"><span data-stu-id="d70f1-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="d70f1-159">Apache Spark en HDInsight almacena datos en Azure Storage o Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="d70f1-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="d70f1-160">Los expertos de la empresa y los responsables de la toma de decisiones clave pueden analizar esos datos y generar informes con ellos, así como usar Microsoft Power BI para crear informes interactivos a partir de los datos analizados.</span><span class="sxs-lookup"><span data-stu-id="d70f1-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="d70f1-161">Los analistas pueden comenzar a partir de datos no estructurados y semiestructurados presentes en el almacenamiento de clúster, definir un esquema de los datos mediante notebooks y luego generar modelos de datos mediante Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="d70f1-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="d70f1-162">Los clústeres de Spark en HDInsight también admiten varias herramientas de BI de terceros, como Tableau, por lo que es una plataforma ideal para los analistas de datos, expertos de empresa y responsables de la toma de decisiones clave.</span><span class="sxs-lookup"><span data-stu-id="d70f1-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="d70f1-163">Aprendizaje automático con Spark</span><span class="sxs-lookup"><span data-stu-id="d70f1-163">Spark Machine Learning</span></span>
[<span data-ttu-id="d70f1-164">Mire un tutorial: predecir las temperaturas de edificios con datos HVAC</span><span class="sxs-lookup"><span data-stu-id="d70f1-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="d70f1-165">Mire un tutorial: predecir los resultados de la inspección de alimentos</span><span class="sxs-lookup"><span data-stu-id="d70f1-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="d70f1-166">Apache Spark incluye [MLlib](http://spark.apache.org/mllib/), una biblioteca de aprendizaje automático basada en Spark que puede usar desde un clúster de Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="d70f1-167">El clúster de Spark en HDInsight también incluye Anaconda, una distribución de Python con diversos paquetes para aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="d70f1-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="d70f1-168">Si agregamos a esto la compatibilidad integrada con notebooks de Jupyter y Zeppelin, dispone de un entorno de primera línea para la creación de aplicaciones de aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="d70f1-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="d70f1-169">Streaming y análisis de datos en tiempo real con Spark</span><span class="sxs-lookup"><span data-stu-id="d70f1-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="d70f1-170">Vea un tutorial</span><span class="sxs-lookup"><span data-stu-id="d70f1-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="d70f1-171">Los clústeres de Spark en HDInsight ofrecen amplia compatibilidad para crear soluciones de análisis en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="d70f1-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="d70f1-172">Mientras que Spark ya posee conectores para insertar datos de varios orígenes como los sockets TCP, Flume, Twitter, ZeroMQ o Kafka, Spark en HDInsight agrega compatibilidad de primera clase para insertar datos desde Centros de eventos de Azure.</span><span class="sxs-lookup"><span data-stu-id="d70f1-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="d70f1-173">Los Centros de eventos son el servicio de cola más usado en Azure.</span><span class="sxs-lookup"><span data-stu-id="d70f1-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="d70f1-174">La disponibilidad inmediata de la compatibilidad con Event Hubs convierte a los clústeres de Spark en HDInsight en una plataforma ideal para crear la canalización de análisis en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="d70f1-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="d70f1-175"><a name="next-steps"></a>¿Qué componentes se incluyen como parte de un clúster Spark?</span><span class="sxs-lookup"><span data-stu-id="d70f1-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="d70f1-176">Los clústeres de Spark en HDInsight incluyen los siguientes componentes que están disponibles en los clústeres de manera predeterminada.</span><span class="sxs-lookup"><span data-stu-id="d70f1-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="d70f1-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="d70f1-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="d70f1-178">Incluye Spark Core, Spark SQL, API Spark de streaming, GraphX y MLlib.</span><span class="sxs-lookup"><span data-stu-id="d70f1-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="d70f1-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="d70f1-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="d70f1-180">Livy</span><span class="sxs-lookup"><span data-stu-id="d70f1-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="d70f1-181">Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="d70f1-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="d70f1-182">Zeppelin Notebook</span><span class="sxs-lookup"><span data-stu-id="d70f1-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="d70f1-183">Los clústeres de Spark en HDInsight también ofrecen un [controlador ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) para la conectividad con clústeres de Spark en HDInsight desde herramientas de inteligencia empresarial como Microsoft Power BI y Tableau.</span><span class="sxs-lookup"><span data-stu-id="d70f1-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="d70f1-184">¿Por dónde empiezo?</span><span class="sxs-lookup"><span data-stu-id="d70f1-184">Where do I start?</span></span>
<span data-ttu-id="d70f1-185">Empiece por crear un clúster de Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d70f1-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="d70f1-186">Consulte el [inicio rápido sobre cómo crear un clúster de Spark en HDInsight Linux y ejecutar consultas interactivas mediante Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="d70f1-187">Pasos siguientes</span><span class="sxs-lookup"><span data-stu-id="d70f1-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="d70f1-188">Escenarios</span><span class="sxs-lookup"><span data-stu-id="d70f1-188">Scenarios</span></span>
* [<span data-ttu-id="d70f1-189">Spark with BI: Realizar el análisis de datos interactivos con Spark en HDInsight con las herramientas de BI</span><span class="sxs-lookup"><span data-stu-id="d70f1-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="d70f1-190">Creación de aplicaciones de Aprendizaje automático con Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="d70f1-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="d70f1-191">Spark con aprendizaje automático: uso de Spark en HDInsight para predecir los resultados de la inspección de alimentos</span><span class="sxs-lookup"><span data-stu-id="d70f1-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="d70f1-192">Streaming con Spark: uso de Spark en HDInsight para compilar aplicaciones de streaming en tiempo real</span><span class="sxs-lookup"><span data-stu-id="d70f1-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="d70f1-193">Análisis del registro del sitio web con Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="d70f1-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="d70f1-194">Creación y ejecución de aplicaciones</span><span class="sxs-lookup"><span data-stu-id="d70f1-194">Create and run applications</span></span>
* [<span data-ttu-id="d70f1-195">Crear una aplicación independiente con Scala</span><span class="sxs-lookup"><span data-stu-id="d70f1-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="d70f1-196">Ejecutar trabajos de forma remota en un clúster de Spark mediante Livy</span><span class="sxs-lookup"><span data-stu-id="d70f1-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="d70f1-197">Herramientas y extensiones</span><span class="sxs-lookup"><span data-stu-id="d70f1-197">Tools and extensions</span></span>
* [<span data-ttu-id="d70f1-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications (Uso del complemento de herramientas de HDInsight para IntelliJ IDEA para crear y enviar aplicaciones Scala Spark)</span><span class="sxs-lookup"><span data-stu-id="d70f1-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="d70f1-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely (Uso del complemento de herramientas de HDInsight para IntelliJ IDEA para depurar aplicaciones de Spark de forma remota)</span><span class="sxs-lookup"><span data-stu-id="d70f1-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="d70f1-200">Uso de cuadernos de Zeppelin con un clúster Spark en HDInsight</span><span class="sxs-lookup"><span data-stu-id="d70f1-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="d70f1-201">Kernels disponibles para el cuaderno de Jupyter en el clúster Spark para HDInsight</span><span class="sxs-lookup"><span data-stu-id="d70f1-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="d70f1-202">Uso de paquetes externos con cuadernos de Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="d70f1-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="d70f1-203">Instalación de un cuaderno de Jupyter Notebook en el equipo y conexión al clúster de Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="d70f1-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="d70f1-204">Administración de recursos</span><span class="sxs-lookup"><span data-stu-id="d70f1-204">Manage resources</span></span>
* [<span data-ttu-id="d70f1-205">Administración de recursos para el clúster Apache Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="d70f1-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="d70f1-206">Track and debug jobs running on an Apache Spark cluster in HDInsight (Seguimiento y depuración de trabajos que se ejecutan en un clúster de Apache Spark en HDInsight)</span><span class="sxs-lookup"><span data-stu-id="d70f1-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="d70f1-207">[Problemas conocidos de Apache Spark en Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="d70f1-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
