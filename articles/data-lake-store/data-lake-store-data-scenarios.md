---
title: Escenarios de datos relacionados con Data Lake Store | Microsoft Docs
description: "Comprender los diferentes escenarios y herramientas mediante los cuales los datos se pueden recopilar, procesar, descargar y visualizar en un Almacén de Data Lake"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: 2a2801e5c506dcc8aa9ca2ecd275b52c72d5fbbf
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/29/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="9ffcf-103">Uso del Almacén de Azure Data Lake para requisitos de macrodatos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="9ffcf-104">Hay cuatro fases principales en el procesamiento de macrodatos:</span><span class="sxs-lookup"><span data-stu-id="9ffcf-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="9ffcf-105">Introducción de grandes cantidades de datos en un almacén de datos, en tiempo real o por lotes</span><span class="sxs-lookup"><span data-stu-id="9ffcf-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="9ffcf-106">Procesamiento de los datos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-106">Processing the data</span></span>
* <span data-ttu-id="9ffcf-107">Descarga de los datos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-107">Downloading the data</span></span>
* <span data-ttu-id="9ffcf-108">Visualización de los datos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-108">Visualizing the data</span></span>

<span data-ttu-id="9ffcf-109">En este artículo nos centramos en estas fases relativas al Almacén de Azure Data Lake para comprender las opciones y herramientas disponibles para satisfacer sus necesidades de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-109">In this article, we look at these stages with respect to Azure Data Lake Store to understand the options and tools available to meet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="9ffcf-110">Introducción de datos en el Almacén de Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="9ffcf-111">En esta sección se resaltan los distintos orígenes de datos y las distintas formas en que esos datos se pueden introducir en una cuenta de Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-111">This section highlights the different sources of data and the different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="9ffcf-112">![Ingesta de datos en Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingesta de datos en Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="9ffcf-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="9ffcf-113">Datos ad-hoc</span><span class="sxs-lookup"><span data-stu-id="9ffcf-113">Ad hoc data</span></span>
<span data-ttu-id="9ffcf-114">Representan conjuntos de datos más pequeños que se utilizan para la creación de un prototipo de una aplicación de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="9ffcf-115">Hay diferentes maneras de introducir datos ad hoc, según el origen de los datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-115">There are different ways of ingesting ad hoc data depending on the source of the data.</span></span>

| <span data-ttu-id="9ffcf-116">Origen de datos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-116">Data Source</span></span> | <span data-ttu-id="9ffcf-117">Introducir mediante</span><span class="sxs-lookup"><span data-stu-id="9ffcf-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="9ffcf-118">Equipo local</span><span class="sxs-lookup"><span data-stu-id="9ffcf-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="9ffcf-119">Portal de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="9ffcf-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="9ffcf-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="9ffcf-121">CLI multiplataforma de Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="9ffcf-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="9ffcf-122">Usar herramientas de Data Lake para Visual Studio</span><span class="sxs-lookup"><span data-stu-id="9ffcf-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="9ffcf-123">Blob de almacenamiento de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="9ffcf-124">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="9ffcf-125">herramienta AdlCopy</span><span class="sxs-lookup"><span data-stu-id="9ffcf-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="9ffcf-126">DistCp ejecutándose en un clúster de HDInsight</span><span class="sxs-lookup"><span data-stu-id="9ffcf-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="9ffcf-127">Datos de streaming</span><span class="sxs-lookup"><span data-stu-id="9ffcf-127">Streamed data</span></span>
<span data-ttu-id="9ffcf-128">Representa los datos que se pueden generar por diversos orígenes, como aplicaciones, dispositivos o sensores, entre otros. Estos datos los pueden introducir distintas herramientas en un Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="9ffcf-129">Estas herramientas normalmente capturan y procesan los datos en eventos individuales y en tiempo real y, después, escriben los eventos en lotes en el Almacén de Data Lake para que puedan procesarse posteriormente.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-129">These tools will usually capture and process the data on an event-by-event basis in real-time, and then write the events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="9ffcf-130">A continuación, se muestran las herramientas que se pueden usar:</span><span class="sxs-lookup"><span data-stu-id="9ffcf-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="9ffcf-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md): los eventos que se recopilan en Event Hubs se pueden escribir en Azure Data Lake con resultados de Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written to Azure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="9ffcf-132">[Storm de HDInsight de Azure](../hdinsight/hdinsight-storm-write-data-lake-store.md) : se pueden escribir los datos directamente en el Almacén de Data Lake desde el clúster de Storm.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly to Data Lake Store from the Storm cluster.</span></span>
* <span data-ttu-id="9ffcf-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md): se pueden recibir eventos desde Event Hubs y, después, escribirlos en Data Lake Store con el [SDK de .NET para Data Lake Store](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="9ffcf-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it to Data Lake Store using the [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="9ffcf-134">Datos relacionales</span><span class="sxs-lookup"><span data-stu-id="9ffcf-134">Relational data</span></span>
<span data-ttu-id="9ffcf-135">También se pueden originar datos desde bases de datos relacionales.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-135">You can also source data from relational databases.</span></span> <span data-ttu-id="9ffcf-136">Durante un tiempo, las bases de datos relacionales recopilan grandes cantidades de datos que pueden proporcionar información clave si se procesan a través de una canalización de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="9ffcf-137">Puede usar las herramientas siguientes para mover estos datos al Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-137">You can use the following tools to move such data into Data Lake Store.</span></span>

* [<span data-ttu-id="9ffcf-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="9ffcf-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="9ffcf-139">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="9ffcf-140">Datos de registro de servidor web (carga mediante aplicaciones personalizadas)</span><span class="sxs-lookup"><span data-stu-id="9ffcf-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="9ffcf-141">Este tipo de conjunto de datos es específicamente necesario porque el análisis de los datos de registro del servidor web es un caso de uso común para aplicaciones de macrodatos y requiere que se carguen grandes volúmenes de archivos de registro en el Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files to be uploaded to the Data Lake Store.</span></span> <span data-ttu-id="9ffcf-142">Puede utilizar cualquiera de las herramientas siguientes para escribir sus propios scripts o aplicaciones para cargar dichos datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-142">You can use any of the following tools to write your own scripts or applications to upload such data.</span></span>

* [<span data-ttu-id="9ffcf-143">CLI multiplataforma de Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="9ffcf-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="9ffcf-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="9ffcf-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="9ffcf-145">SDK para .NET del Almacén de Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="9ffcf-146">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="9ffcf-147">Para cargar datos de registro del servidor web y también para cargar otros tipos de datos (por ejemplo, datos de opiniones sociales), un buen enfoque es escribir sus propios aplicaciones o scripts personalizados, porque le ofrece la flexibilidad de incluir el componente que carga los datos como parte de su aplicación de macrodatos mayor.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach to write your own custom scripts/applications because it gives you the flexibility to include your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="9ffcf-148">En algunos casos, este código puede adoptar la forma de un script o de una utilidad de línea de comandos simple.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-148">In some cases this code may take the form of a script or simple command line utility.</span></span> <span data-ttu-id="9ffcf-149">En otros casos, el código puede utilizarse para integrar el procesamiento de macrodatos en una aplicación o solución de negocio.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-149">In other cases, the code may be used to integrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="9ffcf-150">Datos asociados con los clústeres de HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="9ffcf-151">La mayoría de los tipos de clúster de HDInsight (Hadoop, HBase, Storm) admiten el Almacén de Data Lake como un repositorio de almacenamiento de datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="9ffcf-152">Los clústeres de HDInsight acceden a los datos de blobs de Almacenamiento de Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="9ffcf-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="9ffcf-153">Para mejorar el rendimiento, puede copiar los datos de WASB a una cuenta de Almacén de Data Lake asociada con el clúster.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-153">For better performance, you can copy the data from WASB into a Data Lake Store account associated with the cluster.</span></span> <span data-ttu-id="9ffcf-154">Puede usar las herramientas siguientes para copiar los datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-154">You can use the following tools to copy the data.</span></span>

* [<span data-ttu-id="9ffcf-155">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="9ffcf-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="9ffcf-156">Servicio de AdlCopy</span><span class="sxs-lookup"><span data-stu-id="9ffcf-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="9ffcf-157">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="9ffcf-158">Datos almacenados en clústeres locales o de IaaS de Hadoop</span><span class="sxs-lookup"><span data-stu-id="9ffcf-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="9ffcf-159">Es posible que haya grandes cantidades de datos almacenados en clústeres de Hadoop existentes, de forma local en los equipos mediante HDFS.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="9ffcf-160">Los clústeres de Hadoop pueden encontrarse en una implementación local o dentro de un clúster de IaaS en Azure.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-160">The Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="9ffcf-161">Podrían existir requisitos para copiar estos datos en el Almacén de Azure Data Lake de forma puntual o periódica.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-161">There could be requirements to copy such data to Azure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="9ffcf-162">Existen diversas opciones que puede usar para lograr esto.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-162">There are various options that you can use to achieve this.</span></span> <span data-ttu-id="9ffcf-163">A continuación se muestra una lista de alternativas, además de las ventajas y desventajas asociadas.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-163">Below is a list of alternatives and the associated trade-offs.</span></span>

| <span data-ttu-id="9ffcf-164">Enfoque</span><span class="sxs-lookup"><span data-stu-id="9ffcf-164">Approach</span></span> | <span data-ttu-id="9ffcf-165">Detalles</span><span class="sxs-lookup"><span data-stu-id="9ffcf-165">Details</span></span> | <span data-ttu-id="9ffcf-166">Ventajas</span><span class="sxs-lookup"><span data-stu-id="9ffcf-166">Advantages</span></span> | <span data-ttu-id="9ffcf-167">Consideraciones</span><span class="sxs-lookup"><span data-stu-id="9ffcf-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="9ffcf-168">Usar Data Factory de Azure (ADF) para copiar datos directamente desde los clústeres de Hadoop al Almacén de Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-168">Use Azure Data Factory (ADF) to copy data directly from Hadoop clusters to Azure Data Lake Store</span></span> |[<span data-ttu-id="9ffcf-169">ADF admite HDFS como origen de datos</span><span class="sxs-lookup"><span data-stu-id="9ffcf-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="9ffcf-170">ADF proporciona compatibilidad inmediata con HDFS, así como una supervisión y administración integrales y de primera clase.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="9ffcf-171">Requiere que se implemente Data Management Gateway localmente o en el clúster de IaaS.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-171">Requires Data Management Gateway to be deployed on-premises or in the IaaS cluster</span></span> |
| <span data-ttu-id="9ffcf-172">Exportar datos desde Hadoop como archivos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="9ffcf-173">Después copiar los archivos en el Almacén de Azure Data Lake con el mecanismo adecuado.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-173">Then copy the files to Azure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="9ffcf-174">Puede copiar archivos al Almacén de Azure Data Lake por medio de: </span><span class="sxs-lookup"><span data-stu-id="9ffcf-174">You can copy files to Azure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="9ffcf-175">Azure PowerShell para SO Windows</span><span class="sxs-lookup"><span data-stu-id="9ffcf-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="9ffcf-176">CLI multiplataforma de Azure 2.0 para sistemas operativos distintos de Windows</span><span class="sxs-lookup"><span data-stu-id="9ffcf-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="9ffcf-177">Aplicación personalizada con cualquier SDK de Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="9ffcf-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="9ffcf-178">Se empieza rápido.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-178">Quick to get started.</span></span> <span data-ttu-id="9ffcf-179">Se pueden usar cargas personalizadas.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-179">Can do customized uploads</span></span> |<span data-ttu-id="9ffcf-180">Proceso de varios pasos en el que participan varias tecnologías.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="9ffcf-181">La administración y la supervisión presentarán dificultades con el tiempo, dada la naturaleza personalizada de las herramientas.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-181">Management and monitoring will grow to be a challenge over time given the customized nature of the tools</span></span> |
| <span data-ttu-id="9ffcf-182">Usar Distcp para copiar datos de Hadoop en Almacenamiento de Azure.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-182">Use Distcp to copy data from Hadoop to Azure Storage.</span></span> <span data-ttu-id="9ffcf-183">Después copiar los datos de Almacenamiento de Azure al Almacén de Data Lake con el mecanismo adecuado.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-183">Then copy data from Azure Storage to Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="9ffcf-184">Puede copiar datos de Almacenamiento de Azure a Azure Data Lake Store por medio de: </span><span class="sxs-lookup"><span data-stu-id="9ffcf-184">You can copy data from Azure Storage to Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="9ffcf-185">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="9ffcf-186">herramienta AdlCopy</span><span class="sxs-lookup"><span data-stu-id="9ffcf-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="9ffcf-187">Apache DistCp ejecutándose en clústeres de HDInsight</span><span class="sxs-lookup"><span data-stu-id="9ffcf-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="9ffcf-188">Puede usar herramientas de código abierto.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-188">You can use open-source tools.</span></span> |<span data-ttu-id="9ffcf-189">Proceso de varios pasos en el que participan varias tecnologías.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="9ffcf-190">Conjuntos de datos realmente grandes</span><span class="sxs-lookup"><span data-stu-id="9ffcf-190">Really large datasets</span></span>
<span data-ttu-id="9ffcf-191">Para cargar conjuntos de datos cuyo tamaño oscila en varios terabytes, el uso de los métodos descritos anteriormente puede a veces resultar lento y costoso.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-191">For uploading datasets that range in several terabytes, using the methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="9ffcf-192">En tales casos, puede utilizar las opciones siguientes.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-192">In such cases, you can use the options below.</span></span>

* <span data-ttu-id="9ffcf-193">**Uso de Azure ExpressRoute**.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="9ffcf-194">Azure ExpressRoute permite crear conexiones privadas entre los centros de datos de Azure y la infraestructura de un entorno local.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="9ffcf-195">Esto ofrece una opción confiable para transferir grandes cantidades de datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="9ffcf-196">Para obtener más información, consulte la [documentación de Azure ExpressRoute](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="9ffcf-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="9ffcf-197">**Carga "sin conexión" de los datos**.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="9ffcf-198">Si por cualquier razón no es posible utilizar Azure ExpressRoute, puede usar el [servicio Importación/Exportación de Azure](../storage/common/storage-import-export-service.md) para enviar unidades de disco duro con sus datos a un centro de datos de Azure.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) to ship hard disk drives with your data to an Azure data center.</span></span> <span data-ttu-id="9ffcf-199">Los datos se cargan primero a Blobs de almacenamiento de Azure.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-199">Your data is first uploaded to Azure Storage Blobs.</span></span> <span data-ttu-id="9ffcf-200">Después, puede usar [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) o la [herramienta AdlCopy](data-lake-store-copy-data-azure-storage-blob.md) para copiar datos desde Azure Storage Blobs a Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) to copy data from Azure Storage Blobs to Data Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="9ffcf-201">Al usar el servicio Import/Export, el tamaño de los archivos en los discos que se envían al centro de datos de Azure no debe ser mayor que 195 GB.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-201">While using the Import/Export service, the file sizes on the disks that you ship to Azure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="9ffcf-202">Procesamiento de los datos almacenados en el Almacén de Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="9ffcf-203">Cuando los datos están disponibles en el Almacén de Data Lake, puede ejecutar un análisis en esos datos mediante las aplicaciones de macrodatos admitidas.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-203">Once the data is available in Data Lake Store you can run analysis on that data using the supported big data applications.</span></span> <span data-ttu-id="9ffcf-204">Actualmente, se pueden utilizar HDInsight de Azure y Análisis de Azure Data Lake para ejecutar trabajos de análisis de datos en los datos almacenados en el Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics to run data analysis jobs on the data stored in Data Lake Store.</span></span>

<span data-ttu-id="9ffcf-205">![Análisis de datos en Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Análisis de datos en Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="9ffcf-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="9ffcf-206">Puede buscar en los ejemplos siguientes.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-206">You can look at the following examples.</span></span>

* [<span data-ttu-id="9ffcf-207">Creación de un clúster de HDInsight con Almacén de Data Lake como almacenamiento</span><span class="sxs-lookup"><span data-stu-id="9ffcf-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="9ffcf-208">Uso de Análisis de Azure Data Lake con el Almacén de Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="9ffcf-209">Descarga de datos del Almacén de Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="9ffcf-210">También puede descargar o mover datos del Almacén de Azure Data Lake para situaciones como:</span><span class="sxs-lookup"><span data-stu-id="9ffcf-210">You might also want to download or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="9ffcf-211">Mover datos a otros repositorios para interactuar con las canalizaciones de procesamiento de datos existentes.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-211">Move data to other repositories to interface with your existing data processing pipelines.</span></span> <span data-ttu-id="9ffcf-212">Por ejemplo, puede mover los datos del Almacén de Data Lake a Base de datos SQL de Azure o a SQL Server local.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-212">For example, you might want to move data from Data Lake Store to Azure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="9ffcf-213">Descargar datos en el equipo local para procesarlos en entornos IDE durante la creación de prototipos de aplicaciones.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-213">Download data to your local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="9ffcf-214">![Salida de datos de Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Salida de datos de Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="9ffcf-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="9ffcf-215">En tales casos, puede utilizar cualquiera de las opciones siguientes.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-215">In such cases, you can use any of the following options:</span></span>

* [<span data-ttu-id="9ffcf-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="9ffcf-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="9ffcf-217">Factoría de datos de Azure</span><span class="sxs-lookup"><span data-stu-id="9ffcf-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="9ffcf-218">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="9ffcf-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="9ffcf-219">También puede utilizar los métodos siguientes para escribir su propio script o aplicación para descargar datos desde el Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-219">You can also use the following methods to write your own script/application to download data from Data Lake Store.</span></span>

* [<span data-ttu-id="9ffcf-220">CLI multiplataforma de Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="9ffcf-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="9ffcf-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="9ffcf-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="9ffcf-222">SDK para .NET del Almacén de Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="9ffcf-223">Visualización de datos en el Almacén de Data Lake</span><span class="sxs-lookup"><span data-stu-id="9ffcf-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="9ffcf-224">Puede utilizar una combinación de servicios para crear representaciones visuales de los datos almacenados en el Almacén de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-224">You can use a mix of services to create visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="9ffcf-225">![Visualización de datos de Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualización de datos de Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="9ffcf-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="9ffcf-226">Para empezar, puede usar [Azure Data Factory para mover datos desde Data Lake Store a Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="9ffcf-226">You can start by using [Azure Data Factory to move data from Data Lake Store to Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="9ffcf-227">Después, puede [integrar Power BI con Almacenamiento de datos SQL de Azure](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) para crear una representación visual de los datos.</span><span class="sxs-lookup"><span data-stu-id="9ffcf-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) to create visual representation of the data.</span></span>
