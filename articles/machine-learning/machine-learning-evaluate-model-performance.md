---
title: "Evaluación del rendimiento de un modelo en Machine Learning | Microsoft Docs"
description: "Explica cómo evaluar el rendimiento de un modelo en Aprendizaje automático de Azure."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="a45fc-103">Evaluación del rendimiento de un modelo en Aprendizaje automático de Azure</span><span class="sxs-lookup"><span data-stu-id="a45fc-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="a45fc-104">En este artículo se muestra cómo evaluar el rendimiento de un modelo en Azure Machine Learning Studio y se proporciona una breve explicación de las métricas disponibles para esta tarea.</span><span class="sxs-lookup"><span data-stu-id="a45fc-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="a45fc-105">Se presentan tres escenarios comunes de aprendizaje supervisado:</span><span class="sxs-lookup"><span data-stu-id="a45fc-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="a45fc-106">regresión</span><span class="sxs-lookup"><span data-stu-id="a45fc-106">regression</span></span>
* <span data-ttu-id="a45fc-107">clasificación binaria</span><span class="sxs-lookup"><span data-stu-id="a45fc-107">binary classification</span></span> 
* <span data-ttu-id="a45fc-108">clasificación multiclase</span><span class="sxs-lookup"><span data-stu-id="a45fc-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="a45fc-109">La evaluación del rendimiento de un modelo es una de las fases principales en el proceso de ciencia de datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="a45fc-110">Indica el nivel de acierto de las puntuaciones (predicciones) de un conjunto de datos mediante un modelo entrenado.</span><span class="sxs-lookup"><span data-stu-id="a45fc-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="a45fc-111">Azure Machine Learning admite la evaluación de modelos a través de dos de sus módulos principales de aprendizaje automático: [Evaluar modelo][evaluate-model] y [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="a45fc-112">Estos módulos permiten ver el rendimiento del modelo como un número de métricas que se usan habitualmente en estadísticas y aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="a45fc-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="a45fc-113">Evaluación frente a Validación cruzada</span><span class="sxs-lookup"><span data-stu-id="a45fc-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="a45fc-114">La evaluación y la validación cruzada son métodos estándares para medir el rendimiento de un modelo.</span><span class="sxs-lookup"><span data-stu-id="a45fc-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="a45fc-115">Ambos generan métricas de evaluación que puede inspeccionar o comparar con las de otros modelos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="a45fc-116">[Evaluar modelo][evaluate-model] espera un conjunto de datos puntuado como entrada (o 2 en caso de que quiera comparar el rendimiento de 2 modelos distintos).</span><span class="sxs-lookup"><span data-stu-id="a45fc-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="a45fc-117">Esto implica que debe entrenar el modelo mediante el módulo [Train Model][train-model] (Entrenar modelo) y realizar predicciones sobre algún conjunto de datos con el módulo [Puntuar modelo][score-model], antes de poder evaluar los resultados.</span><span class="sxs-lookup"><span data-stu-id="a45fc-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="a45fc-118">La evaluación se basa en las etiquetas y probabilidades puntuadas junto con las etiquetas verdaderas, las cuales son el resultado del módulo [Puntuar modelo][score-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="a45fc-119">De forma alternativa, es posible usar la validación cruzada para realizar automáticamente varias operaciones de entrenamiento, puntuación y evaluación (10 subconjuntos) en distintos subconjuntos de los datos de entrada.</span><span class="sxs-lookup"><span data-stu-id="a45fc-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="a45fc-120">Los datos de entrada se dividen en 10 partes, donde una se reserva para las pruebas y las otras 9 para el entrenamiento.</span><span class="sxs-lookup"><span data-stu-id="a45fc-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="a45fc-121">Este proceso se repite 10 veces y se calcula el promedio de las métricas de evaluación.</span><span class="sxs-lookup"><span data-stu-id="a45fc-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="a45fc-122">Esto ayuda a determinar el nivel al que un modelo se podría generalizar para nuevos conjuntos de datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="a45fc-123">El módulo [Validar modelo de forma cruzada][cross-validate-model] toma un modelo sin entrenar y algunos conjuntos de datos con etiquetas y genera los resultados de la evaluación de cada uno de los 10 subconjuntos, además de los resultados promediados.</span><span class="sxs-lookup"><span data-stu-id="a45fc-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="a45fc-124">En las siguientes secciones, se crearán modelos de clasificación y regresión simples, y se evaluará su rendimiento con los módulos [Evaluar modelo][evaluate-model] y [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="a45fc-125">Evaluación de un modelo de regresión</span><span class="sxs-lookup"><span data-stu-id="a45fc-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="a45fc-126">Supongamos que quiere predecir el precio de un automóvil mediante algunas características, como sus dimensiones, caballos de potencia, especificaciones del motor, etc.</span><span class="sxs-lookup"><span data-stu-id="a45fc-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="a45fc-127">Se trata de un problema de regresión típico, donde la variable objetivo (*price*) es un valor numérico continuo.</span><span class="sxs-lookup"><span data-stu-id="a45fc-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="a45fc-128">Podemos generar un modelo de regresión lineal simple que, dados los valores de las características de un automóvil determinado, pueda predecir el precio de ese automóvil.</span><span class="sxs-lookup"><span data-stu-id="a45fc-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="a45fc-129">Este modelo de regresión se puede usar para puntuar el mismo conjunto de datos con que se entrenó.</span><span class="sxs-lookup"><span data-stu-id="a45fc-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="a45fc-130">Cuando se tienen los precios predichos de todos los automóviles, se puede evaluar el rendimiento del modelo con una comparación de cuánto se desvían en promedio las predicciones de los precios reales.</span><span class="sxs-lookup"><span data-stu-id="a45fc-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="a45fc-131">Para ilustrar esto, se usa el conjunto de datos *Información sobre los precios de los automóviles (datos sin procesar)* disponible en la sección **Conjuntos de datos almacenados** en Estudio de aprendizaje automático de Azure.</span><span class="sxs-lookup"><span data-stu-id="a45fc-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="a45fc-132">Creación del experimento</span><span class="sxs-lookup"><span data-stu-id="a45fc-132">Creating the Experiment</span></span>
<span data-ttu-id="a45fc-133">Agregue los módulos siguientes al área de trabajo en Estudio de aprendizaje automático de Azure:</span><span class="sxs-lookup"><span data-stu-id="a45fc-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="a45fc-134">Información sobre los precios de los automóviles (datos sin procesar)</span><span class="sxs-lookup"><span data-stu-id="a45fc-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="a45fc-135">[Regresión lineal][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="a45fc-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="a45fc-136">[Train Model][train-model] (Entrenar modelo)</span><span class="sxs-lookup"><span data-stu-id="a45fc-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="a45fc-137">[Puntuar modelo][score-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="a45fc-138">[Evaluar modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="a45fc-139">Conecte los puertos, tal y como se muestra en la Ilustración 1 y establezca la columna de etiqueta del módulo [Train Model][train-model] (Entrenar modelo) en *price*.</span><span class="sxs-lookup"><span data-stu-id="a45fc-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Evaluación de un modelo de regresión](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="a45fc-141">Figura 1.</span><span class="sxs-lookup"><span data-stu-id="a45fc-141">Figure 1.</span></span> <span data-ttu-id="a45fc-142">Evaluación de un modelo de regresión.</span><span class="sxs-lookup"><span data-stu-id="a45fc-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="a45fc-143">Inspección de los resultados de la evaluación</span><span class="sxs-lookup"><span data-stu-id="a45fc-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="a45fc-144">Después de ejecutar el experimento, puede hacer clic en el puerto de salida del módulo [Evaluar modelo][evaluate-model] y seleccionar *Visualizar* para ver los resultados de la evaluación.</span><span class="sxs-lookup"><span data-stu-id="a45fc-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="a45fc-145">Las métricas de evaluación disponibles para los modelos de regresión son: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error* y *Coefficient of Determination*.</span><span class="sxs-lookup"><span data-stu-id="a45fc-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="a45fc-146">El término "error" representa aquí la diferencia entre el valor predicho y el valor verdadero.</span><span class="sxs-lookup"><span data-stu-id="a45fc-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="a45fc-147">Normalmente, se calcula el valor absoluto o el cuadrado de esta diferencia para capturar la magnitud total de errores en todas las instancias, dado que la diferencia entre el valor verdadero y el predicho puede ser negativa en algunos casos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="a45fc-148">Las métricas de error miden el rendimiento de predicción de un modelo de regresión en cuanto a la desviación media de sus predicciones a partir de los valores reales.</span><span class="sxs-lookup"><span data-stu-id="a45fc-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="a45fc-149">Los valores de error más bajos implican que el modelo es más preciso a la hora de realizar predicciones.</span><span class="sxs-lookup"><span data-stu-id="a45fc-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="a45fc-150">Una métrica de error general de 0 significa que el modelo se ajusta a los datos perfectamente.</span><span class="sxs-lookup"><span data-stu-id="a45fc-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="a45fc-151">El coeficiente de determinación, que también se conoce como R cuadrado, es también una manera estándar de medir cuánto se adapta el modelo a los datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="a45fc-152">Se puede interpretar como la proporción de la variación que explica el modelo.</span><span class="sxs-lookup"><span data-stu-id="a45fc-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="a45fc-153">Una mayor proporción es mejor en este caso, donde 1 indica un ajuste perfecto.</span><span class="sxs-lookup"><span data-stu-id="a45fc-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Métricas de evaluación de regresión lineal](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="a45fc-155">Ilustración 2.</span><span class="sxs-lookup"><span data-stu-id="a45fc-155">Figure 2.</span></span> <span data-ttu-id="a45fc-156">Métricas de evaluación de regresión lineal.</span><span class="sxs-lookup"><span data-stu-id="a45fc-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="a45fc-157">Uso de la validación cruzada</span><span class="sxs-lookup"><span data-stu-id="a45fc-157">Using Cross Validation</span></span>
<span data-ttu-id="a45fc-158">Como se mencionó anteriormente, puede realizar entrenamientos, puntuaciones y evaluaciones de forma repetida y automática mediante el módulo [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="a45fc-159">Lo único que necesita en este caso es un conjunto de datos, un modelo sin entrenar y un módulo [Validar modelo de forma cruzada][cross-validate-model] (consulte la ilustración siguiente).</span><span class="sxs-lookup"><span data-stu-id="a45fc-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="a45fc-160">Tenga en cuenta que debe establecer la columna de etiqueta en *price* en las propiedades del módulo [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Validación cruzada de un modelo de regresión](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="a45fc-162">Figura 3.</span><span class="sxs-lookup"><span data-stu-id="a45fc-162">Figure 3.</span></span> <span data-ttu-id="a45fc-163">Validación cruzada de un modelo de regresión.</span><span class="sxs-lookup"><span data-stu-id="a45fc-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="a45fc-164">Después de ejecutar el experimento, puede inspeccionar los resultados de la evaluación haciendo clic en el puerto de salida derecho del módulo [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="a45fc-165">Esto proporcionará una vista detallada de las métricas de cada iteración (subconjunto) y los resultados promediados de cada una de las métricas (Figura 4).</span><span class="sxs-lookup"><span data-stu-id="a45fc-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Resultados de la validación cruzada de un modelo de regresión](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="a45fc-167">Figura 4.</span><span class="sxs-lookup"><span data-stu-id="a45fc-167">Figure 4.</span></span> <span data-ttu-id="a45fc-168">Resultados de la validación cruzada de un modelo de regresión.</span><span class="sxs-lookup"><span data-stu-id="a45fc-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="a45fc-169">Evaluación de un modelo de clasificación binaria</span><span class="sxs-lookup"><span data-stu-id="a45fc-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="a45fc-170">En un escenario de clasificación binaria, la variable objetivo tiene solo dos resultados posibles, por ejemplo: {0, 1} o {false, true}, {negative, positive}.</span><span class="sxs-lookup"><span data-stu-id="a45fc-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="a45fc-171">Suponga que tiene un conjunto de datos de empleados adultos con algunas variables demográficas y de empleo, y se le pide que prediga el nivel de ingresos, una variable binaria con los valores {“<=50K”, “>50K”}.</span><span class="sxs-lookup"><span data-stu-id="a45fc-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="a45fc-172">En otras palabras, la clase negativa representa a los empleados que tienen un sueldo menor o igual a 50.000 al año y la clase positiva representa a los demás empleados.</span><span class="sxs-lookup"><span data-stu-id="a45fc-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="a45fc-173">Al igual que en el escenario de regresión, se entrenaría un modelo, se puntuarían algunos datos y se evaluarían los resultados.</span><span class="sxs-lookup"><span data-stu-id="a45fc-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="a45fc-174">La principal diferencia es la elección de las métricas que Aprendizaje automático de Azure calcula y da como resultado.</span><span class="sxs-lookup"><span data-stu-id="a45fc-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="a45fc-175">Para ilustrar el escenario de predicción del nivel de ingresos, se usará el conjunto de datos [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) para crear un experimento de Aprendizaje automático de Azure y evaluar el rendimiento de un modelo de regresión logística de dos clases, un clasificador binario que se usa con frecuencia.</span><span class="sxs-lookup"><span data-stu-id="a45fc-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="a45fc-176">Creación del experimento</span><span class="sxs-lookup"><span data-stu-id="a45fc-176">Creating the Experiment</span></span>
<span data-ttu-id="a45fc-177">Agregue los módulos siguientes al área de trabajo en Estudio de aprendizaje automático de Azure:</span><span class="sxs-lookup"><span data-stu-id="a45fc-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="a45fc-178">Conjunto de datos de clasificación binaria de ingresos en el censo de adultos</span><span class="sxs-lookup"><span data-stu-id="a45fc-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="a45fc-179">[Regresión logística de dos clases][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="a45fc-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="a45fc-180">[Train Model][train-model] (Entrenar modelo)</span><span class="sxs-lookup"><span data-stu-id="a45fc-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="a45fc-181">[Puntuar modelo][score-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="a45fc-182">[Evaluar modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="a45fc-183">Conecte los puertos tal y como se muestra en la Ilustración 5 y establezca la columna de etiqueta del módulo [Train Model][train-model] (Entrenar modelo) en *income*.</span><span class="sxs-lookup"><span data-stu-id="a45fc-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Evaluación de un modelo de clasificación binaria](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="a45fc-185">Figura 5.</span><span class="sxs-lookup"><span data-stu-id="a45fc-185">Figure 5.</span></span> <span data-ttu-id="a45fc-186">Evaluación de un modelo de clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="a45fc-187">Inspección de los resultados de la evaluación</span><span class="sxs-lookup"><span data-stu-id="a45fc-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="a45fc-188">Después de ejecutar el experimento, puede hacer clic en el puerto de salida del módulo [Evaluar modelo][evaluate-model] y seleccionar *Visualizar* para ver los resultados de la evaluación (ilustración 7).</span><span class="sxs-lookup"><span data-stu-id="a45fc-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="a45fc-189">Las métricas de evaluación disponibles para los modelos de clasificación binaria son: *Accuracy*, *Precision*, *Recall*, *F1 Score* y *AUC*.</span><span class="sxs-lookup"><span data-stu-id="a45fc-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="a45fc-190">Además, el módulo genera una matriz de confusión que muestra el número de positivos verdaderos, falsos negativos, falsos positivos y negativos verdaderos, así como curvas *ROC*, *Precision/Recall* y *Lift*.</span><span class="sxs-lookup"><span data-stu-id="a45fc-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="a45fc-191">La precisión es simplemente la proporción de instancias clasificadas correctamente.</span><span class="sxs-lookup"><span data-stu-id="a45fc-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="a45fc-192">Suele ser la primera métrica que se comprueba al evaluar un clasificador.</span><span class="sxs-lookup"><span data-stu-id="a45fc-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="a45fc-193">Sin embargo, si los datos de prueba están descompensados (en el caso en que la mayoría de las instancias pertenecen a una de las clases) o está más interesado en el rendimiento de una de las clases, la precisión no captura realmente la eficacia de un clasificador.</span><span class="sxs-lookup"><span data-stu-id="a45fc-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="a45fc-194">En el escenario de clasificación del nivel de ingresos, suponga que está realizando pruebas en datos donde el 99 % de las instancias representan personas con un sueldo menor o igual a 50.000 al año.</span><span class="sxs-lookup"><span data-stu-id="a45fc-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="a45fc-195">Es posible conseguir una precisión de 0,99 al predecir la clase "<=50.000" para todas las instancias.</span><span class="sxs-lookup"><span data-stu-id="a45fc-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="a45fc-196">En este caso, el clasificador parece hacer un buen trabajo global, pero en realidad no clasifica correctamente ninguno de las personas con ingresos elevados (1 %) correctamente.</span><span class="sxs-lookup"><span data-stu-id="a45fc-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="a45fc-197">Por ese motivo, es útil calcular métricas adicionales que capturen aspectos más específicos de la evaluación.</span><span class="sxs-lookup"><span data-stu-id="a45fc-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="a45fc-198">Antes de entrar a los detalles de dichas métricas, es importante comprender la matriz de confusión de una evaluación de clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="a45fc-199">Las etiquetas de clase en el conjunto de entrenamiento pueden tomar solo dos valores posibles, a los que normalmente podemos referirnos como positivo o negativo.</span><span class="sxs-lookup"><span data-stu-id="a45fc-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="a45fc-200">Las instancias positivas y negativas que un clasificador predice correctamente se denominan positivos verdaderos (TP) y negativos verdaderos (TN), respectivamente.</span><span class="sxs-lookup"><span data-stu-id="a45fc-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="a45fc-201">De forma similar, las instancias clasificadas incorrectamente se denominan falsos positivos (FP) y falsos negativos (FN).</span><span class="sxs-lookup"><span data-stu-id="a45fc-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="a45fc-202">La matriz de confusión es simplemente una tabla que muestra el número de instancias que se encuentran bajo cada una de estas cuatro categorías.</span><span class="sxs-lookup"><span data-stu-id="a45fc-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="a45fc-203">Aprendizaje automático de Azure decide automáticamente cuál de las dos clases en el conjunto de datos es la clase positiva.</span><span class="sxs-lookup"><span data-stu-id="a45fc-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="a45fc-204">Si las etiquetas de clase son valores booleanos o enteros, se asignan las instancias etiquetadas como 'true' o '1' a la clase positiva.</span><span class="sxs-lookup"><span data-stu-id="a45fc-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="a45fc-205">Si las etiquetas son cadenas, como en el caso del conjunto de datos de los ingresos, las etiquetas se ordenan alfabéticamente y se elige que el primer nivel sea la clase negativa, mientras que el segundo nivel es la clase positiva.</span><span class="sxs-lookup"><span data-stu-id="a45fc-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Matriz de confusión de la clasificación binaria](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="a45fc-207">Figura 6.</span><span class="sxs-lookup"><span data-stu-id="a45fc-207">Figure 6.</span></span> <span data-ttu-id="a45fc-208">Matriz de confusión de la clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="a45fc-209">Volviendo al problema de clasificación de ingresos, existen varias preguntas de evaluación que querríamos preguntar para ayudarnos a comprender el rendimiento del clasificador utilizado.</span><span class="sxs-lookup"><span data-stu-id="a45fc-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="a45fc-210">Una pregunta muy natural es: "De los individuos que el modelo predijo que ganan >50.000 (TP+FP), cuántos se han clasificado correctamente (TP)?"</span><span class="sxs-lookup"><span data-stu-id="a45fc-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="a45fc-211">Puede responder esta pregunta observando la **Precisión** del modelo, que es la proporción de positivos que se han clasificado correctamente: TP/(TP+FP).</span><span class="sxs-lookup"><span data-stu-id="a45fc-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="a45fc-212">Otra pregunta común es "De todos los empleados con ingresos >50.000 (TP+FN), ¿cuántos predijo el clasificador correctamente (TP)?".</span><span class="sxs-lookup"><span data-stu-id="a45fc-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="a45fc-213">Esto es en realidad la **Recuperación** o la tasa de positivos verdaderos: TP/(TP+FN) del clasificador.</span><span class="sxs-lookup"><span data-stu-id="a45fc-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="a45fc-214">Observará que hay una evidente compensación entre la precisión y la recuperación.</span><span class="sxs-lookup"><span data-stu-id="a45fc-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="a45fc-215">Por ejemplo, dado un conjunto de datos relativamente equilibrado, un clasificador que prediga principalmente instancias positivas tendría una recuperación alta, pero una precisión más baja, ya que muchas de las instancias negativas se clasificarían incorrectamente y se produciría un número mayor de falsos positivos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="a45fc-216">Para ver un gráfico de cómo varían estas dos métricas, haga clic en la curva de "PRECISIÓN/RECUPERACIÓN" en la página de salida de resultados de evaluación (parte superior izquierda de la Figura 7).</span><span class="sxs-lookup"><span data-stu-id="a45fc-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Resultados de la evaluación de clasificación binaria](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="a45fc-218">Ilustración 7.</span><span class="sxs-lookup"><span data-stu-id="a45fc-218">Figure 7.</span></span> <span data-ttu-id="a45fc-219">Resultados de la evaluación de clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="a45fc-220">Otra métrica relacionada que se usa con frecuencia es **F1 Score**, que tiene en cuenta la precisión y la recuperación.</span><span class="sxs-lookup"><span data-stu-id="a45fc-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="a45fc-221">Es la media armónica de estas 2 métricas y se calcula como tal: F1 = 2 (precisión x recuperación) / (precisión + recuperación).</span><span class="sxs-lookup"><span data-stu-id="a45fc-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="a45fc-222">La puntuación de F1 score es una buena forma de resumir la evaluación en un número único, pero siempre es una práctica recomendada comprobar la precisión y la recuperación juntas para comprender mejor cómo se comporta un clasificador.</span><span class="sxs-lookup"><span data-stu-id="a45fc-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="a45fc-223">Además, es posible inspeccionar la tasa de positivos verdaderos frente a la de falsos positivos en la curva **Característica operativa del receptor (ROC)** y el valor del **área bajo la curva (AUC)** correspondiente.</span><span class="sxs-lookup"><span data-stu-id="a45fc-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="a45fc-224">Cuanto más se acerque esta curva a la esquina superior izquierda, mejor será el rendimiento del clasificador (es decir, se maximiza la tasa de positivos verdaderos a la vez que se minimiza la de falsos positivos).</span><span class="sxs-lookup"><span data-stu-id="a45fc-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="a45fc-225">Las curvas que están cerca de la diagonal del gráfico son el resultado de los clasificadores que tienden a realizar predicciones que se acercan a una estimación aleatoria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="a45fc-226">Uso de la validación cruzada</span><span class="sxs-lookup"><span data-stu-id="a45fc-226">Using Cross Validation</span></span>
<span data-ttu-id="a45fc-227">Como en el ejemplo de regresión, podemos realizar una validación cruzada para entrenar, puntuar y evaluar de forma repetida y automática diferentes subconjuntos de datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="a45fc-228">De forma similar, es posible usar el módulo [Validar modelo de forma cruzada][cross-validate-model], un modelo de regresión logística sin entrenar y un conjunto de datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="a45fc-229">La columna de etiqueta debe establecerse en *income* en las propiedades del módulo [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="a45fc-230">Después de ejecutar el experimento y hacer clic en el puerto de la salida derecha del módulo [Validar modelo de forma cruzada][cross-validate-model], es posible ver los valores de métricas de clasificación binaria de cada subconjunto, además de las desviaciones media y estándar de cada uno.</span><span class="sxs-lookup"><span data-stu-id="a45fc-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Validación cruzada de un modelo de clasificación binaria](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="a45fc-232">Figura 8.</span><span class="sxs-lookup"><span data-stu-id="a45fc-232">Figure 8.</span></span> <span data-ttu-id="a45fc-233">Validación cruzada de un modelo de clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-233">Cross-Validating a Binary Classification Model.</span></span>

![Resultados de la validación cruzada de un clasificador binario](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="a45fc-235">Figura 9.</span><span class="sxs-lookup"><span data-stu-id="a45fc-235">Figure 9.</span></span> <span data-ttu-id="a45fc-236">Resultados de la validación cruzada de un clasificador binario.</span><span class="sxs-lookup"><span data-stu-id="a45fc-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="a45fc-237">Evaluación de un modelo de clasificación multiclase</span><span class="sxs-lookup"><span data-stu-id="a45fc-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="a45fc-238">En este experimento se usará el conocido conjunto de datos [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris "), que contiene las instancias de tres tipos (clases) distintos de la planta iris.</span><span class="sxs-lookup"><span data-stu-id="a45fc-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="a45fc-239">Hay 4 valores de características (longitud y ancho del sépalo y del pétalo) para cada instancia.</span><span class="sxs-lookup"><span data-stu-id="a45fc-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="a45fc-240">En los experimentos anteriores se entrenaron y probaron los modelos con los mismos conjuntos de datos.</span><span class="sxs-lookup"><span data-stu-id="a45fc-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="a45fc-241">Aquí usaremos el módulo [Split Data][split] (Dividir datos) para crear dos subconjuntos de los datos, con el fin de entrenar en el primero y puntuar y evaluar en el segundo.</span><span class="sxs-lookup"><span data-stu-id="a45fc-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="a45fc-242">El conjunto de datos Iris está disponible públicamente en [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html) (Repositorio de aprendizaje automático de UCI) y se puede descargar mediante un módulo [Importar datos][import-data].</span><span class="sxs-lookup"><span data-stu-id="a45fc-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="a45fc-243">Creación del experimento</span><span class="sxs-lookup"><span data-stu-id="a45fc-243">Creating the Experiment</span></span>
<span data-ttu-id="a45fc-244">Agregue los módulos siguientes al área de trabajo en Estudio de aprendizaje automático de Azure:</span><span class="sxs-lookup"><span data-stu-id="a45fc-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="a45fc-245">[Importar datos][import-data]</span><span class="sxs-lookup"><span data-stu-id="a45fc-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="a45fc-246">[Bosque de decisión multiclase][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="a45fc-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="a45fc-247">[Split Data][split] (Dividir datos)</span><span class="sxs-lookup"><span data-stu-id="a45fc-247">[Split Data][split]</span></span>
* <span data-ttu-id="a45fc-248">[Train Model][train-model] (Entrenar modelo)</span><span class="sxs-lookup"><span data-stu-id="a45fc-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="a45fc-249">[Puntuar modelo][score-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="a45fc-250">[Evaluar modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="a45fc-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="a45fc-251">Conecte los puertos tal como se muestra a continuación en la Figura 10.</span><span class="sxs-lookup"><span data-stu-id="a45fc-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="a45fc-252">Establezca el índice de la columna de etiqueta del módulo [Train Model][train-model] (Entrenar modelo) en 5.</span><span class="sxs-lookup"><span data-stu-id="a45fc-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="a45fc-253">El conjunto de datos no tiene fila de encabezado, pero se sabe que las etiquetas de clase están en la quinta columna.</span><span class="sxs-lookup"><span data-stu-id="a45fc-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="a45fc-254">Haga clic en el módulo [Importar datos][import-data] y establezca la propiedad *Origen de datos* en *Dirección URL web a través de HTTP*, y la dirección *URL* en http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="a45fc-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="a45fc-255">Establezca la fracción de instancias que se usará para el entrenamiento en el módulo [Split Data][split] (Dividir datos) (0,7 por ejemplo).</span><span class="sxs-lookup"><span data-stu-id="a45fc-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![Evaluar un clasificador multiclase](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="a45fc-257">Figura 10.</span><span class="sxs-lookup"><span data-stu-id="a45fc-257">Figure 10.</span></span> <span data-ttu-id="a45fc-258">Evaluar un clasificador multiclase</span><span class="sxs-lookup"><span data-stu-id="a45fc-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="a45fc-259">Inspección de los resultados de la evaluación</span><span class="sxs-lookup"><span data-stu-id="a45fc-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="a45fc-260">Ejecute el experimento y haga clic en el puerto de salida de [Evaluar modelo][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="a45fc-261">En este caso, los resultados de la evaluación se presentan en forma de una matriz de confusión.</span><span class="sxs-lookup"><span data-stu-id="a45fc-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="a45fc-262">La matriz muestra las instancias reales frente a las predichas para las tres clases.</span><span class="sxs-lookup"><span data-stu-id="a45fc-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Resultados de la evaluación de clasificación multiclase](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="a45fc-264">Figura 11.</span><span class="sxs-lookup"><span data-stu-id="a45fc-264">Figure 11.</span></span> <span data-ttu-id="a45fc-265">Resultados de la evaluación de clasificación multiclase.</span><span class="sxs-lookup"><span data-stu-id="a45fc-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="a45fc-266">Uso de la validación cruzada</span><span class="sxs-lookup"><span data-stu-id="a45fc-266">Using Cross Validation</span></span>
<span data-ttu-id="a45fc-267">Como se mencionó anteriormente, puede realizar entrenamientos, puntuaciones y evaluaciones de forma repetida y automática mediante el módulo [Validar modelo de forma cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="a45fc-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="a45fc-268">Necesitaría un conjunto de datos, un modelo sin entrenar y un módulo [Validar modelo de forma cruzada][cross-validate-model] (consulte la ilustración siguiente).</span><span class="sxs-lookup"><span data-stu-id="a45fc-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="a45fc-269">De nuevo, debe establecer la columna de etiqueta del módulo [Evaluar modelo de forma cruzada][cross-validate-model] (en este caso, índice 5 de columna).</span><span class="sxs-lookup"><span data-stu-id="a45fc-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="a45fc-270">Después de ejecutar el experimento y hacer clic en el puerto de salida derecho de [Validar modelo de forma cruzada][cross-validate-model], puede inspeccionar los valores de métricas de cada subconjunto, así como las desviaciones media y estándar.</span><span class="sxs-lookup"><span data-stu-id="a45fc-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="a45fc-271">Las métricas que se muestran aquí son similares a las descritas en el caso de clasificación binaria.</span><span class="sxs-lookup"><span data-stu-id="a45fc-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="a45fc-272">Sin embargo, tenga en cuenta que en la clasificación multiclase, se realiza el cálculo de los positivos y negativos verdaderos, y de los falsos positivos y negativos con un recuento por clase, ya que no existe ninguna clase general positiva o negativa.</span><span class="sxs-lookup"><span data-stu-id="a45fc-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="a45fc-273">Por ejemplo, al calcular la precisión o la recuperación de la clase 'Iris-setosa', se supone que se trata de la clase positiva y que todas las demás son negativas.</span><span class="sxs-lookup"><span data-stu-id="a45fc-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Validación cruzada de un modelo de clasificación multiclase](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="a45fc-275">Ilustración 12.</span><span class="sxs-lookup"><span data-stu-id="a45fc-275">Figure 12.</span></span> <span data-ttu-id="a45fc-276">Validación cruzada de un modelo de clasificación multiclase.</span><span class="sxs-lookup"><span data-stu-id="a45fc-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Resultados de una validación cruzada de un modelo de clasificación multiclase](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="a45fc-278">Ilustración 13.</span><span class="sxs-lookup"><span data-stu-id="a45fc-278">Figure 13.</span></span> <span data-ttu-id="a45fc-279">Resultados de una validación cruzada de un modelo de clasificación multiclase.</span><span class="sxs-lookup"><span data-stu-id="a45fc-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

