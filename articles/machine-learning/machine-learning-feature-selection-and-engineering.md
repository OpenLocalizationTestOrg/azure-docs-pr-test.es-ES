---
title: "Diseño y selección de características en Machine Learning de Azure | Microsoft Docs"
description: "Explica el propósito del diseño y la selección de características, además de dar ejemplos de su rol en el proceso de mejora de los datos del aprendizaje automático."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 9ceb524d-842e-4f77-9eae-a18e599442d6
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/18/2017
ms.author: zhangya;bradsev
ROBOTS: NOINDEX
redirect_url: machine-learning-data-science-create-features
redirect_document_id: TRUE
ms.openlocfilehash: 51a5d8fed492cb9301e048c2b6a721e4573a47d9
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 07/11/2017
---
# <a name="feature-engineering-and-selection-in-azure-machine-learning"></a><span data-ttu-id="db02b-103">Diseño y selección de características en Aprendizaje automático de Azure</span><span class="sxs-lookup"><span data-stu-id="db02b-103">Feature engineering and selection in Azure Machine Learning</span></span>
<span data-ttu-id="db02b-104">En este tema se explica el propósito del diseño y la selección de características en el proceso de mejora de los datos del aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="db02b-104">This topic explains the purposes of feature engineering and feature selection in the data-enhancement process of machine learning.</span></span> <span data-ttu-id="db02b-105">Este tema muestra lo que implican estos procesos con ejemplos que ofrece Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="db02b-105">It illustrates what these processes involve by using examples provided by Azure Machine Learning Studio.</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="db02b-106">Los datos de entrenamiento que se usan en el aprendizaje automático a menudo pueden mejorarse gracias a la selección o extracción de características desde los datos sin procesar que se han recopilado.</span><span class="sxs-lookup"><span data-stu-id="db02b-106">The training data used in machine learning can often be enhanced by the selection or extraction of features from the raw data collected.</span></span> <span data-ttu-id="db02b-107">Un ejemplo de una característica diseñada en el contexto de aprender cómo clasificar las imágenes de caracteres manuscritos es un mapa de densidad de bits construido a partir de los datos de distribución de bits sin procesar.</span><span class="sxs-lookup"><span data-stu-id="db02b-107">An example of an engineered feature in the context of learning how to classify the images of handwritten characters is a bit-density map constructed from the raw bit distribution data.</span></span> <span data-ttu-id="db02b-108">Este mapa puede ayudar a ubicar los bordes de los caracteres de manera más eficiente que la distribución sin procesar.</span><span class="sxs-lookup"><span data-stu-id="db02b-108">This map can help locate the edges of the characters more efficiently than the raw distribution.</span></span>

<span data-ttu-id="db02b-109">Las funciones diseñadas y seleccionadas aumentan la eficiencia del proceso de entrenamiento, el que intenta extraer la información clave contenida en los datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-109">Engineered and selected features increase the efficiency of the training process, which attempts to extract the key information contained in the data.</span></span> <span data-ttu-id="db02b-110">También mejoran la eficacia de estos modelos para clasificar los datos de entrada de manera precisa y para predecir resultados de interés de manera más sólida.</span><span class="sxs-lookup"><span data-stu-id="db02b-110">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</span></span> <span data-ttu-id="db02b-111">El diseño y la selección de características también se pueden combinar para que sea posible hacer un mejor seguimiento computacional del aprendizaje.</span><span class="sxs-lookup"><span data-stu-id="db02b-111">Feature engineering and selection can also combine to make the learning more computationally tractable.</span></span> <span data-ttu-id="db02b-112">Para ello, mejora y luego reduce el número de características que se necesitan para calibrar o entrenar un modelo.</span><span class="sxs-lookup"><span data-stu-id="db02b-112">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</span></span> <span data-ttu-id="db02b-113">Matemáticamente hablando, las características seleccionadas para entrenar el modelo son un conjunto mínimo de variables independientes que explican los patrones existentes en los datos y, a continuación, predicen correctamente los resultados.</span><span class="sxs-lookup"><span data-stu-id="db02b-113">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</span></span>

<span data-ttu-id="db02b-114">El diseño y la selección de las características es solo una parte de un proceso más grande, el que normalmente consta de cuatro pasos:</span><span class="sxs-lookup"><span data-stu-id="db02b-114">The engineering and selection of features is one part of a larger process, which typically consists of four steps:</span></span>

* <span data-ttu-id="db02b-115">Colección de datos</span><span class="sxs-lookup"><span data-stu-id="db02b-115">Data collection</span></span>
* <span data-ttu-id="db02b-116">Mejora de datos</span><span class="sxs-lookup"><span data-stu-id="db02b-116">Data enhancement</span></span>
* <span data-ttu-id="db02b-117">Construcción del modelo</span><span class="sxs-lookup"><span data-stu-id="db02b-117">Model construction</span></span>
* <span data-ttu-id="db02b-118">Posprocesamiento</span><span class="sxs-lookup"><span data-stu-id="db02b-118">Post-processing</span></span>

<span data-ttu-id="db02b-119">El diseño y la selección componen el paso de mejora de datos del aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="db02b-119">Engineering and selection make up the data enhancement step of machine learning.</span></span> <span data-ttu-id="db02b-120">Para nuestros propósitos, es posible distinguir tres aspectos de este proceso:</span><span class="sxs-lookup"><span data-stu-id="db02b-120">Three aspects of this process may be distinguished for our purposes:</span></span>

* <span data-ttu-id="db02b-121">**Preprocesamiento de los datos**: este proceso intenta asegurarse de que los datos recopilados estén limpios y sean coherentes.</span><span class="sxs-lookup"><span data-stu-id="db02b-121">**Data pre-processing**: This process tries to ensure that the collected data is clean and consistent.</span></span> <span data-ttu-id="db02b-122">Incluye tareas como la integración de varios conjuntos de datos, el control de los datos que faltan, el control de datos incoherentes y la conversión de los tipos de datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-122">It includes tasks such as integrating multiple data sets, handling missing data, handling inconsistent data, and converting data types.</span></span>
* <span data-ttu-id="db02b-123">**Diseño de características**: este proceso intenta crear características pertinentes adicionales a partir de características existentes sin procesar en los datos y mejorar la eficacia predictiva del algoritmo de aprendizaje.</span><span class="sxs-lookup"><span data-stu-id="db02b-123">**Feature engineering**: This process attempts to create additional relevant features from the existing raw features in the data and to increase predictive power to the learning algorithm.</span></span>
* <span data-ttu-id="db02b-124">**Selección de características**: este proceso selecciona el subconjunto de claves de las características de datos originales en un intento por reducir la dimensionalidad del problema de entrenamiento.</span><span class="sxs-lookup"><span data-stu-id="db02b-124">**Feature selection**: This process selects the key subset of original data features to reduce the dimensionality of the training problem.</span></span>

<span data-ttu-id="db02b-125">En este tema solo se abarcan los aspectos de diseño y selección de funciones del proceso de mejora de los datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-125">This topic only covers the feature engineering and feature selection aspects of the data enhancement process.</span></span> <span data-ttu-id="db02b-126">Para obtener información adicional sobre el paso de preprocesamiento de los datos, vea el vídeo [Pre-processing data in Azure Machine Learning Studio](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/) (Preprocesamiento de datos en Azure Machine Learning Studio).</span><span class="sxs-lookup"><span data-stu-id="db02b-126">For more information on the data pre-processing step, see [Pre-processing data in Azure Machine Learning Studio](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/).</span></span>

## <a name="creating-features-from-your-data--feature-engineering"></a><span data-ttu-id="db02b-127">Creación de características a partir de sus datos: diseño de características</span><span class="sxs-lookup"><span data-stu-id="db02b-127">Creating features from your data--feature engineering</span></span>
<span data-ttu-id="db02b-128">Los datos de entrenamiento constan de una matriz compuesta de ejemplos (registros u observaciones almacenados en filas), cada uno de los cuales cuenta con un conjunto de características (variables o campos almacenados en columnas).</span><span class="sxs-lookup"><span data-stu-id="db02b-128">The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</span></span> <span data-ttu-id="db02b-129">Se espera que las características especificadas en el diseño experimental caractericen los patrones de los datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-129">The features specified in the experimental design are expected to characterize the patterns in the data.</span></span> <span data-ttu-id="db02b-130">A pesar de que muchos de los campos de datos sin procesar se pueden incluir directamente en el conjunto de características seleccionado que se usa para entrenar un modelo, con frecuencia es preciso construir características adicionales (diseñadas) a partir de las características existentes en los datos sin procesar para generar un conjunto de datos de entrenamiento mejorado.</span><span class="sxs-lookup"><span data-stu-id="db02b-130">Although many of the raw data fields can be directly included in the selected feature set used to train a model, additional engineered features often need to be constructed from the features in the raw data to generate an enhanced training data set.</span></span>

<span data-ttu-id="db02b-131">¿Qué tipo de características se deben crear para mejorar el conjunto de datos cuando se entrena un modelo?</span><span class="sxs-lookup"><span data-stu-id="db02b-131">What kind of features should be created to enhance the data set when training a model?</span></span> <span data-ttu-id="db02b-132">Las características diseñadas que mejoran el entrenamiento proporcionan información que ayuda a diferenciar de mejor manera los patrones de los datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-132">Engineered features that enhance the training provide information that better differentiates the patterns in the data.</span></span> <span data-ttu-id="db02b-133">Se espera que las características nuevas den información adicional que no está claramente capturada o no resulta fácilmente reconocible en el conjunto de características original o existente, pero este proceso es casi un arte.</span><span class="sxs-lookup"><span data-stu-id="db02b-133">You expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set, but this process is something of an art.</span></span> <span data-ttu-id="db02b-134">Las decisiones acertadas y productivas a menudo requieren cierto conocimiento especializado.</span><span class="sxs-lookup"><span data-stu-id="db02b-134">Sound and productive decisions often require some domain expertise.</span></span>

<span data-ttu-id="db02b-135">Al comenzar con Azure Machine Learning, la forma más fácil de comprender este proceso es plantearlo de manera concreta, con los ejemplos que ofrece Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="db02b-135">When starting with Azure Machine Learning, it is easiest to grasp this process concretely by using samples provided in Machine Learning Studio.</span></span> <span data-ttu-id="db02b-136">Aquí se muestran dos ejemplos:</span><span class="sxs-lookup"><span data-stu-id="db02b-136">Two examples are presented here:</span></span>

* <span data-ttu-id="db02b-137">Un ejemplo de regresión ([predicción del número de bicicletas alquiladas](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4)) en un experimento supervisado en el que se conocen los valores del objetivo</span><span class="sxs-lookup"><span data-stu-id="db02b-137">A regression example ([Prediction of the number of bike rentals](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4)) in a supervised experiment where the target values are known</span></span>
* <span data-ttu-id="db02b-138">Un ejemplo de clasificación de minería de texto con [Hash de características][feature-hashing]</span><span class="sxs-lookup"><span data-stu-id="db02b-138">A text-mining classification example using [Feature Hashing][feature-hashing]</span></span>

### <a name="example-1-adding-temporal-features-for-a-regression-model"></a><span data-ttu-id="db02b-139">Ejemplo 1: Incorporación de características temporales para un modelo de regresión</span><span class="sxs-lookup"><span data-stu-id="db02b-139">Example 1: Adding temporal features for a regression model</span></span>
<span data-ttu-id="db02b-140">Usemos el experimento "Previsión de demanda de bicicletas" en Azure Machine Learning Studio para mostrar cómo diseñar funciones para una tarea de regresión.</span><span class="sxs-lookup"><span data-stu-id="db02b-140">To demonstrate how to engineer features for a regression task, let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio.</span></span> <span data-ttu-id="db02b-141">El objetivo de este experimento es predecir la demanda de bicicletas, es decir, el número de bicicletas alquiladas dentro de un mes, día u hora específico.</span><span class="sxs-lookup"><span data-stu-id="db02b-141">The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month, day, or hour.</span></span> <span data-ttu-id="db02b-142">El conjunto de datos **Bike Rental UCI data set** se usa como los datos de entrada sin procesar.</span><span class="sxs-lookup"><span data-stu-id="db02b-142">The data set **Bike Rental UCI data set** is used as the raw input data.</span></span>

<span data-ttu-id="db02b-143">Este conjunto de datos se basa en datos reales provenientes de la empresa Capital Bikeshare que mantiene una red de alquiler de bicicletas en Washington DC, en Estados Unidos.</span><span class="sxs-lookup"><span data-stu-id="db02b-143">This data set is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</span></span> <span data-ttu-id="db02b-144">El conjunto de datos representa el número de bicicletas alquiladas dentro de una hora específica durante un día en el año 2011 a 2012 y contiene 17379 filas y 17 columnas.</span><span class="sxs-lookup"><span data-stu-id="db02b-144">The data set represents the number of bike rentals within a specific hour of a day, from 2011 to 2012, and it contains 17379 rows and 17 columns.</span></span> <span data-ttu-id="db02b-145">El conjunto de características sin procesar contiene condiciones climáticas (temperatura, humedad, velocidad del viento) y el tipo de día (festivo, día de semana).</span><span class="sxs-lookup"><span data-stu-id="db02b-145">The raw feature set contains weather conditions (temperature, humidity, wind speed) and the type of the day (holiday or weekday).</span></span> <span data-ttu-id="db02b-146">El campo para la predicción es **cnt**, un contador que representa las bicicletas alquiladas dentro de una hora específica y cuyos intervalos van de 1 a 977.</span><span class="sxs-lookup"><span data-stu-id="db02b-146">The field to predict is **cnt**, a count that represents the bike rentals within a specific hour and that ranges from 1 to 977.</span></span>

<span data-ttu-id="db02b-147">Para construir características eficaces en los datos de entrenamiento, se crean cuatro modelos de regresión con el mismo algoritmo, pero con cuatro conjuntos de datos de entrenamiento distintos.</span><span class="sxs-lookup"><span data-stu-id="db02b-147">To construct effective features in the training data, four regression models are built by using the same algorithm, but with four different training data sets.</span></span> <span data-ttu-id="db02b-148">Los cuatro conjuntos de datos representan los mismos datos de entrada sin procesar, pero con un número creciente del conjunto de características.</span><span class="sxs-lookup"><span data-stu-id="db02b-148">The four data sets represent the same raw input data, but with an increasing number of features set.</span></span> <span data-ttu-id="db02b-149">Estas características se agrupan en cuatro categorías:</span><span class="sxs-lookup"><span data-stu-id="db02b-149">These features are grouped into four categories:</span></span>

1. <span data-ttu-id="db02b-150">A = características de clima + festivo + día de semana + fin de semana correspondiente al día de la predicción</span><span class="sxs-lookup"><span data-stu-id="db02b-150">A = weather + holiday + weekday + weekend features for the predicted day</span></span>
2. <span data-ttu-id="db02b-151">B = el número de bicicletas alquiladas en cada una de las 12 horas anteriores</span><span class="sxs-lookup"><span data-stu-id="db02b-151">B = number of bikes that were rented in each of the previous 12 hours</span></span>
3. <span data-ttu-id="db02b-152">C = el número de bicicletas alquiladas en cada uno de los 12 días anteriores a la misma hora</span><span class="sxs-lookup"><span data-stu-id="db02b-152">C = number of bikes that were rented in each of the previous 12 days at the same hour</span></span>
4. <span data-ttu-id="db02b-153">D = el número de bicicletas arrendadas en cada una de las 12 semanas anteriores a la misma hora y el mismo día</span><span class="sxs-lookup"><span data-stu-id="db02b-153">D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</span></span>

<span data-ttu-id="db02b-154">Aparte del conjunto de funciones A, que ya existe en los datos sin procesar originales, los otros tres conjuntos de funciones se crean mediante el proceso de diseño de funciones.</span><span class="sxs-lookup"><span data-stu-id="db02b-154">Besides feature set A, which already exists in the original raw data, the other three sets of features are created through the feature engineering process.</span></span> <span data-ttu-id="db02b-155">El conjunto de funciones B captura la demanda de bicicletas reciente.</span><span class="sxs-lookup"><span data-stu-id="db02b-155">Feature set B captures the recent demand for the bikes.</span></span> <span data-ttu-id="db02b-156">El conjunto de características C captura la demanda de bicicletas en una hora específica.</span><span class="sxs-lookup"><span data-stu-id="db02b-156">Feature set C captures the demand for bikes at a particular hour.</span></span> <span data-ttu-id="db02b-157">El conjunto de características D captura la demanda de bicicletas en una hora específica y un día de la semana específico.</span><span class="sxs-lookup"><span data-stu-id="db02b-157">Feature set D captures demand for bikes at particular hour and particular day of the week.</span></span> <span data-ttu-id="db02b-158">Cada uno de los cuatro conjuntos de datos de entrenamiento incluye, respectivamente, el conjunto de características A, A+B, A+B+C y A+B+C+D.</span><span class="sxs-lookup"><span data-stu-id="db02b-158">Each of the four training data sets includes feature sets A, A+B, A+B+C, and A+B+C+D, respectively.</span></span>

<span data-ttu-id="db02b-159">En el experimento de Azure Machine Learning, estos cuatro conjuntos de datos de entrenamiento se forman a través de cuatro ramas del conjunto de datos de entrada procesado previamente.</span><span class="sxs-lookup"><span data-stu-id="db02b-159">In the Azure Machine Learning experiment, these four training data sets are formed via four branches from the pre-processed input data set.</span></span> <span data-ttu-id="db02b-160">Con la excepción de la rama que se encuentra más a la izquierda, cada una de estas ramas contiene un módulo [Ejecutar script R][execute-r-script], en el que un conjunto de características derivadas (conjuntos de características B, C y D) se construye y anexa respectivamente al conjunto de datos importado.</span><span class="sxs-lookup"><span data-stu-id="db02b-160">Except for the leftmost branch, each of these branches contains an [Execute R Script][execute-r-script] module in which a set of derived features (feature sets B, C, and D) is respectively constructed and appended to the imported data set.</span></span> <span data-ttu-id="db02b-161">En la siguiente figura se muestra el script de R que se usa para crear el conjunto de características B en la segunda rama a la izquierda.</span><span class="sxs-lookup"><span data-stu-id="db02b-161">The following figure demonstrates the R script used to create feature set B in the second left branch.</span></span>

![Creación de un conjunto de características](./media/machine-learning-feature-selection-and-engineering/addFeature-Rscripts.png)

<span data-ttu-id="db02b-163">En la tabla siguiente se resume la comparación de los resultados de rendimiento de los cuatro modelos.</span><span class="sxs-lookup"><span data-stu-id="db02b-163">The following table summarizes the comparison of the performance results of the four models.</span></span> <span data-ttu-id="db02b-164">Las características A+B+C muestran los mejores resultados.</span><span class="sxs-lookup"><span data-stu-id="db02b-164">The best results are shown by features A+B+C.</span></span> <span data-ttu-id="db02b-165">Observe que la tasa de errores disminuye cuando se incluyen conjuntos de características adicionales en los datos de entrenamiento.</span><span class="sxs-lookup"><span data-stu-id="db02b-165">Note that the error rate decreases when additional feature sets are included in the training data.</span></span> <span data-ttu-id="db02b-166">Esto comprueba nuestra presunción con respecto a que los conjuntos de características B y C dan información pertinente adicional para la tarea de regresión.</span><span class="sxs-lookup"><span data-stu-id="db02b-166">This verifies our presumption that the feature sets B and C provide additional relevant information for the regression task.</span></span> <span data-ttu-id="db02b-167">Pero, agregar el conjunto de características D no parece reducir de ningún modo la tasa de errores.</span><span class="sxs-lookup"><span data-stu-id="db02b-167">Adding the D feature set does not seem to provide any additional reduction in the error rate.</span></span>

![Comparar los resultados de rendimiento](./media/machine-learning-feature-selection-and-engineering/result1.png)

### <span data-ttu-id="db02b-169"><a name="example2"></a> Ejemplo 2: Creación de características en minería de texto</span><span class="sxs-lookup"><span data-stu-id="db02b-169"><a name="example2"></a> Example 2: Creating features in text mining</span></span>
<span data-ttu-id="db02b-170">El diseño de características se aplica ampliamente en las tareas relacionadas con la minería de texto, como la clasificación de documentos y el análisis de opiniones.</span><span class="sxs-lookup"><span data-stu-id="db02b-170">Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</span></span> <span data-ttu-id="db02b-171">Por ejemplo, si desea clasificar documentos en varias categorías, una hipótesis típica es que las palabras o frases incluidas que se encuentran en una categoría de documento tienen menos probabilidades de presentarse en otra categoría de documento.</span><span class="sxs-lookup"><span data-stu-id="db02b-171">For example, when you want to classify documents into several categories, a typical assumption is that the words or phrases included in one document category are less likely to occur in another document category.</span></span> <span data-ttu-id="db02b-172">Dicho de otro modo, la frecuencia de la distribución de palabras o frases puede caracterizar distintas categorías de documento.</span><span class="sxs-lookup"><span data-stu-id="db02b-172">In other words, the frequency of the word or phrase distribution is able to characterize different document categories.</span></span> <span data-ttu-id="db02b-173">En las aplicaciones de minería de texto, es necesario el proceso de diseño de características para crear las características que implican las frecuencias de palabras o frases; esto se debe a que partes individuales de contenidos de texto normalmente sirven como datos de entrada.</span><span class="sxs-lookup"><span data-stu-id="db02b-173">In text mining applications, the feature engineering process is needed to create the features involving word or phrase frequencies because individual pieces of text-contents usually serve as the input data.</span></span>

<span data-ttu-id="db02b-174">Para llevar a cabo esta tarea, se aplica una técnica llamada *hash de características* que permite convertir eficazmente las características arbitrarias de texto en índices.</span><span class="sxs-lookup"><span data-stu-id="db02b-174">To achieve this task, a technique called *feature hashing* is applied to efficiently turn arbitrary text features into indices.</span></span> <span data-ttu-id="db02b-175">En lugar de asociar cada característica de texto (palabras o frases) a un índice determinado, este método funciona mediante la aplicación de una función de hash a las características y el uso de sus valores de hash como índices directamente.</span><span class="sxs-lookup"><span data-stu-id="db02b-175">Instead of associating each text feature (words or phrases) to a particular index, this method functions by applying a hash function to the features and by using their hash values as indices directly.</span></span>

<span data-ttu-id="db02b-176">En Azure Machine Learning, existe un módulo de [Hash de características][feature-hashing] que crea estas características de palabras o frases.</span><span class="sxs-lookup"><span data-stu-id="db02b-176">In Azure Machine Learning, there is a [Feature Hashing][feature-hashing] module that creates these word or phrase features.</span></span> <span data-ttu-id="db02b-177">La figura siguiente muestra un ejemplo del uso de este módulo.</span><span class="sxs-lookup"><span data-stu-id="db02b-177">The following figure shows an example of using this module.</span></span> <span data-ttu-id="db02b-178">El conjunto de datos de entrada contiene dos columnas: la clasificación de libro, que va de 1 a 5, y el contenido mismo de la reseña.</span><span class="sxs-lookup"><span data-stu-id="db02b-178">The input data set contains two columns: the book rating ranging from 1 to 5 and the actual review content.</span></span> <span data-ttu-id="db02b-179">El objetivo de este módulo de [Hash de características][feature-hashing] es recuperar características nuevas que muestran la frecuencia de repetición de las palabras o frases correspondientes dentro de la reseña de ese libro en especial.</span><span class="sxs-lookup"><span data-stu-id="db02b-179">The goal of this [Feature Hashing][feature-hashing] module is to retrieve new features that show the occurrence frequency of the corresponding words or phrases within the particular book review.</span></span> <span data-ttu-id="db02b-180">Para usar este módulo, es necesario realizar los siguientes pasos:</span><span class="sxs-lookup"><span data-stu-id="db02b-180">To use this module, you need to complete the following steps:</span></span>

1. <span data-ttu-id="db02b-181">Seleccione la columna que contiene el texto de entrada (**Col2** en este ejemplo).</span><span class="sxs-lookup"><span data-stu-id="db02b-181">Select the column that contains the input text (**Col2** in this example).</span></span>
2. <span data-ttu-id="db02b-182">Establezca el *Tamaño de bits de hash* en 8, lo que significa que se crearán 2^8=256 características.</span><span class="sxs-lookup"><span data-stu-id="db02b-182">Set *Hashing bitsize* to 8, which means 2^8=256 features are created.</span></span> <span data-ttu-id="db02b-183">La palabra o frase en el texto tendrá hash en 256 índices.</span><span class="sxs-lookup"><span data-stu-id="db02b-183">The word or phrase in the text is then hashed to 256 indices.</span></span> <span data-ttu-id="db02b-184">El parámetro *Tamaño de bits de hash* va de 1 a 31.</span><span class="sxs-lookup"><span data-stu-id="db02b-184">The parameter *Hashing bitsize* ranges from 1 to 31.</span></span> <span data-ttu-id="db02b-185">Si el parámetro se establece en un número mayor, es menos probable que a las palabras o frases se les aplique un algoritmo hash en el mismo índice.</span><span class="sxs-lookup"><span data-stu-id="db02b-185">If the parameter is set to a larger number, the words or phrases are less likely to be hashed into the same index.</span></span>
3. <span data-ttu-id="db02b-186">Establezca el parámetro *N-gramas* en 2.</span><span class="sxs-lookup"><span data-stu-id="db02b-186">Set the parameter *N-grams* to 2.</span></span> <span data-ttu-id="db02b-187">Con esto se recupera la frecuencia de repetición de unigramas (una característica para cada palabra única) y bigramas (unas características para cada par de palabras adyacentes) a partir del texto de entrada.</span><span class="sxs-lookup"><span data-stu-id="db02b-187">This retrieves the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</span></span> <span data-ttu-id="db02b-188">El parámetro *N-gramas* va de 0 a 10, lo que indica el número máximo de palabras secuenciales que se incluirán en una característica.</span><span class="sxs-lookup"><span data-stu-id="db02b-188">The parameter *N-grams* ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</span></span>  

![Módulo de hash de características](./media/machine-learning-feature-selection-and-engineering/feature-Hashing1.png)

<span data-ttu-id="db02b-190">La figura siguiente muestra cómo se ven estas nuevas funciones.</span><span class="sxs-lookup"><span data-stu-id="db02b-190">The following figure shows what these new features look like.</span></span>

![Ejemplo de hash de características](./media/machine-learning-feature-selection-and-engineering/feature-Hashing2.png)

## <a name="filtering-features-from-your-data--feature-selection"></a><span data-ttu-id="db02b-192">Filtrado de características desde sus datos: selección de características</span><span class="sxs-lookup"><span data-stu-id="db02b-192">Filtering features from your data--feature selection</span></span>
<span data-ttu-id="db02b-193">La *selección de características* es un proceso que normalmente se aplica a la construcción de conjuntos de datos de entrenamiento para tareas de modelado predictivo, como las tareas de clasificación o de regresión.</span><span class="sxs-lookup"><span data-stu-id="db02b-193">*Feature selection* is a process that is commonly applied to the construction of training data sets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="db02b-194">El objetivo es seleccionar un subconjunto de las características a partir del conjunto de datos original que reduce sus dimensiones al usar un conjunto de características mínimo para que represente la cantidad máxima de varianza en los datos.</span><span class="sxs-lookup"><span data-stu-id="db02b-194">The goal is to select a subset of the features from the original data set that reduces its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</span></span> <span data-ttu-id="db02b-195">Este subconjunto de funciones contiene las únicas funciones que se incluirán para entrenar el modelo.</span><span class="sxs-lookup"><span data-stu-id="db02b-195">This subset of features contains the only features to be included to train the model.</span></span> <span data-ttu-id="db02b-196">La selección de características tiene dos propósitos principales:</span><span class="sxs-lookup"><span data-stu-id="db02b-196">Feature selection serves two main purposes:</span></span>

* <span data-ttu-id="db02b-197">La selección de características a menudo aumenta la precisión de la clasificación a través de la eliminación de características irrelevantes, redundantes o altamente correlacionadas.</span><span class="sxs-lookup"><span data-stu-id="db02b-197">Feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="db02b-198">La selección de características disminuye la cantidad de características, lo que hace que el proceso de entrenamiento del modelo sea más eficiente.</span><span class="sxs-lookup"><span data-stu-id="db02b-198">Feature selection decreases the number of features, which makes the model training process more efficient.</span></span> <span data-ttu-id="db02b-199">Esto resulta especialmente importante cuando se trata de sistemas aprendices que son costosos de entrenar, como las máquinas de vectores de soporte.</span><span class="sxs-lookup"><span data-stu-id="db02b-199">This is particularly important for learners that are expensive to train such as support vector machines.</span></span>

<span data-ttu-id="db02b-200">A pesar de que la selección de características pretende disminuir la cantidad de estas en el conjunto de datos que se usa para entrenar el modelo, no es frecuente referirse a ella con el término *reducción de la dimensionalidad*.</span><span class="sxs-lookup"><span data-stu-id="db02b-200">Although feature selection seeks to reduce the number of features in the data set used to train the model, it is not usually referred to by the term *dimensionality reduction.*</span></span> <span data-ttu-id="db02b-201">Los métodos de selección de características extraen un subconjunto de las características originales de los datos sin cambiarlas.</span><span class="sxs-lookup"><span data-stu-id="db02b-201">Feature selection methods extract a subset of original features in the data without changing them.</span></span>  <span data-ttu-id="db02b-202">Los métodos de reducción de dimensionalidad emplean características diseñadas que pueden transformar las características originales y, de ese modo, modificarlas.</span><span class="sxs-lookup"><span data-stu-id="db02b-202">Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</span></span> <span data-ttu-id="db02b-203">Algunos ejemplos de métodos de reducción de dimensionalidad incluyen el análisis del componente principal, el análisis de correlación canónica y la descomposición en valores singulares.</span><span class="sxs-lookup"><span data-stu-id="db02b-203">Examples of dimensionality reduction methods include principal component analysis, canonical correlation analysis, and singular value decomposition.</span></span>

<span data-ttu-id="db02b-204">Una categoría ampliamente aplicada de los métodos de selección de características en un contexto supervisado se llama selección de características basada en filtro.</span><span class="sxs-lookup"><span data-stu-id="db02b-204">One widely applied category of feature selection methods in a supervised context is filter-based feature selection.</span></span> <span data-ttu-id="db02b-205">Mediante la evaluación de la correlación entre cada característica y el atributo de destino, estos métodos aplican una medida estadística para asignar una puntuación a cada característica.</span><span class="sxs-lookup"><span data-stu-id="db02b-205">By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</span></span> <span data-ttu-id="db02b-206">A continuación, las características se clasifican según la puntuación, que puede usar con el fin de establecer el umbral para conservar o eliminar una característica específica.</span><span class="sxs-lookup"><span data-stu-id="db02b-206">The features are then ranked by the score, which you can use to set the threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="db02b-207">Algunos ejemplos de las medidas estadísticas que se usan en estos métodos incluyen la correlación de Pearson, la información mutua y la prueba de Chi-cuadrado.</span><span class="sxs-lookup"><span data-stu-id="db02b-207">Examples of the statistical measures used in these methods include Pearson Correlation, mutual information, and the Chi-squared test.</span></span>

<span data-ttu-id="db02b-208">Azure Machine Learning Studio incluye módulos para la selección de características.</span><span class="sxs-lookup"><span data-stu-id="db02b-208">Azure Machine Learning Studio provides modules for feature selection.</span></span> <span data-ttu-id="db02b-209">Tal como aparece en la figura siguiente, estos módulos incluyen [Selección de características basada en filtros][filter-based-feature-selection] y [Análisis discriminante lineal de Fisher][fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="db02b-209">As shown in the following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Ejemplo de selección de características](./media/machine-learning-feature-selection-and-engineering/feature-Selection.png)

<span data-ttu-id="db02b-211">Por ejemplo, use el módulo de [Selección de características basada en filtros][filter-based-feature-selection] con el ejemplo de minería de datos de texto descrito anteriormente.</span><span class="sxs-lookup"><span data-stu-id="db02b-211">For example, use the [Filter-Based Feature Selection][filter-based-feature-selection] module with the text mining example outlined previously.</span></span> <span data-ttu-id="db02b-212">Suponga que desea crear un modelo de regresión una vez creado un conjunto de 256 características mediante el módulo de [Hash de características][feature-hashing] y que la variable de respuesta es la **Col1** y representa una clasificación de las reseñas de libros, que van desde 1 a 5.</span><span class="sxs-lookup"><span data-stu-id="db02b-212">Assume that you want to build a regression model after a set of 256 features is created through the [Feature Hashing][feature-hashing] module, and that the response variable is **Col1** and represents a book review rating ranging from 1 to 5.</span></span> <span data-ttu-id="db02b-213">Establezca el **Método de puntuación de características** en **Correlación de Pearson**, la **Columna de destino** en **Col1** y el **Número de características deseadas** en **50**.</span><span class="sxs-lookup"><span data-stu-id="db02b-213">Set **Feature scoring method** to **Pearson Correlation**, **Target column** to **Col1**, and **Number of desired features** to **50**.</span></span> <span data-ttu-id="db02b-214">A continuación, el módulo de [Selección de funciones basada en filtros][filter-based-feature-selection] generará un conjunto de datos con 50 funciones, junto con el atributo de destino **Col1**.</span><span class="sxs-lookup"><span data-stu-id="db02b-214">The module [Filter-Based Feature Selection][filter-based-feature-selection] then produces a data set containing 50 features together with the target attribute **Col1**.</span></span> <span data-ttu-id="db02b-215">La figura siguiente muestra el flujo de este experimento y los parámetros de entrada.</span><span class="sxs-lookup"><span data-stu-id="db02b-215">The following figure shows the flow of this experiment and the input parameters.</span></span>

![Ejemplo de selección de características](./media/machine-learning-feature-selection-and-engineering/feature-Selection1.png)

<span data-ttu-id="db02b-217">La figura siguiente muestra los conjuntos de datos resultantes.</span><span class="sxs-lookup"><span data-stu-id="db02b-217">The following figure shows the resulting data sets.</span></span> <span data-ttu-id="db02b-218">Cada característica recibe una puntuación según la correlación de Pearson entre sí misma y el atributo de destino **Col1**.</span><span class="sxs-lookup"><span data-stu-id="db02b-218">Each feature is scored based on the Pearson Correlation between itself and the target attribute **Col1**.</span></span> <span data-ttu-id="db02b-219">Las características con las mayores puntuaciones se conservan.</span><span class="sxs-lookup"><span data-stu-id="db02b-219">The features with top scores are kept.</span></span>

![Conjuntos de datos de selección de características basada en filtros](./media/machine-learning-feature-selection-and-engineering/feature-Selection2.png)

<span data-ttu-id="db02b-221">La figura siguiente muestra las puntuaciones correspondientes de las características seleccionadas.</span><span class="sxs-lookup"><span data-stu-id="db02b-221">The following figure shows the corresponding scores of the selected features.</span></span>

![Puntuaciones de las características seleccionadas](./media/machine-learning-feature-selection-and-engineering/feature-Selection3.png)

<span data-ttu-id="db02b-223">Mediante la aplicación de este módulo de [Selección de características basada en filtros][filter-based-feature-selection], se seleccionan 50 de las 256 características, debido a que tienen más características correlacionadas con la variable de destino **Col1**, según el método de puntuación **Correlación de Pearson**.</span><span class="sxs-lookup"><span data-stu-id="db02b-223">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have the most features correlated with the target variable **Col1** based on the scoring method **Pearson Correlation**.</span></span>

## <a name="conclusion"></a><span data-ttu-id="db02b-224">Conclusión</span><span class="sxs-lookup"><span data-stu-id="db02b-224">Conclusion</span></span>
<span data-ttu-id="db02b-225">El diseño y la selección de características son dos pasos que se suelen completar para preparar los datos de entrenamiento cuando se crea un modelo de aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="db02b-225">Feature engineering and feature selection are two steps commonly performed to prepare the training data when building a machine learning model.</span></span> <span data-ttu-id="db02b-226">Normalmente, el diseño de características se aplica primero para generar características adicionales y, a continuación, se realiza el paso de selección de características para eliminar aquellas que son irrelevantes, redundantes o altamente correlacionadas.</span><span class="sxs-lookup"><span data-stu-id="db02b-226">Normally, feature engineering is applied first to generate additional features, and then the feature selection step is performed to eliminate irrelevant, redundant, or highly correlated features.</span></span>

<span data-ttu-id="db02b-227">No siempre es necesario realizar el diseño o la selección de funciones.</span><span class="sxs-lookup"><span data-stu-id="db02b-227">It is not always necessarily to perform feature engineering or feature selection.</span></span> <span data-ttu-id="db02b-228">Que sea o no necesario depende de los datos que se tienen o que hay que recopilar, del algoritmo elegido y del objetivo del experimento.</span><span class="sxs-lookup"><span data-stu-id="db02b-228">Whether it is needed depends on the data you have or collect, the algorithm you pick, and the objective of the experiment.</span></span>

<!-- Module References -->
[execute-r-script]: https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/
