---
title: "Información general sobre la ciencia de los datos con Spark en HDInsight de Azure | Microsoft Docs"
description: "El kit de herramientas MLlib de Spark ofrece importantes funciones de modelado de aprendizaje automático para el entorno distribuido de HDInsight."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="bec96-103">Información general sobre la ciencia de los datos con Spark en HDInsight de Azure</span><span class="sxs-lookup"><span data-stu-id="bec96-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="bec96-104">En este conjunto de temas se muestra cómo utilizar Spark en HDInsight para completar tareas comunes de ciencia de datos como la ingesta de datos, el diseño de características, el modelado y la evaluación de modelos.</span><span class="sxs-lookup"><span data-stu-id="bec96-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="bec96-105">Los datos que se utilizan son un ejemplo del conjunto de datos de carreras y tarifas de taxi de la ciudad de Nueva York en 2013</span><span class="sxs-lookup"><span data-stu-id="bec96-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="bec96-106">Los modelos creados incluyen regresión logística y lineal, bosques aleatorios y árboles impulsados por gradiente:</span><span class="sxs-lookup"><span data-stu-id="bec96-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="bec96-107">En los temas también se muestra cómo almacenar estos modelos en el Azure Blob Storage (WASB) y cómo puntuar y evaluar su rendimiento predictivo.</span><span class="sxs-lookup"><span data-stu-id="bec96-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="bec96-108">En los temas más avanzados se describe cómo se pueden entrenar los modelos mediante validación cruzada y barrido de hiperparámetros.</span><span class="sxs-lookup"><span data-stu-id="bec96-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="bec96-109">En este tema introductorio también se hace referencia al tema en el que se describe cómo configurar un clúster de Spark que se necesita para completar los pasos de los tutoriales proporcionados.</span><span class="sxs-lookup"><span data-stu-id="bec96-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="bec96-110">Spark y MLlib</span><span class="sxs-lookup"><span data-stu-id="bec96-110">Spark and MLlib</span></span>
<span data-ttu-id="bec96-111">[Spark](http://spark.apache.org/) es una plataforma de procesamiento paralelo de código abierto que admite el procesamiento en memoria para mejorar el rendimiento de las aplicaciones de análisis de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="bec96-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="bec96-112">El motor de procesamiento Spark se ha creado para ofrecer velocidad, facilidad de uso y análisis sofisticados.</span><span class="sxs-lookup"><span data-stu-id="bec96-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="bec96-113">Las capacidades de cálculo distribuido en memoria de Spark lo convierten en una buena opción para algoritmos iterativos en los cálculos de gráficos y aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="bec96-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="bec96-114">[MLlib](http://spark.apache.org/mllib/) es la biblioteca de aprendizaje automático escalable de Spark que ofrece funcionalidades de modelado algorítmico en este entorno distribuido.</span><span class="sxs-lookup"><span data-stu-id="bec96-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="bec96-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="bec96-115">HDInsight Spark</span></span>
<span data-ttu-id="bec96-116">[Spark en HDInsight](../hdinsight/hdinsight-apache-spark-overview.md) es la oferta de Spark de código abierto hospedada por Azure.</span><span class="sxs-lookup"><span data-stu-id="bec96-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="bec96-117">También incluye compatibilidad con **cuadernos de PySpark para Jupyter** en el clúster de Spark, que pueden ejecutar consultas interactivas de Spark SQL para transformar, filtrar y visualizar los datos almacenados en blobs de Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="bec96-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="bec96-118">PySpark es la API de Python para Spark.</span><span class="sxs-lookup"><span data-stu-id="bec96-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="bec96-119">Los fragmentos de código que proporcionan las soluciones y muestran los trazados relevantes para visualizar los datos aquí se ejecutan en cuadernos de Jupyter instalados en los clústeres de Spark.</span><span class="sxs-lookup"><span data-stu-id="bec96-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="bec96-120">En estos temas, los pasos de modelado también contienen código que muestra cómo entrenar, evaluar, guardar y usar cada tipo de modelo.</span><span class="sxs-lookup"><span data-stu-id="bec96-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="bec96-121">Programa de instalación: clústeres de Spark e instancias de Jupyter Notebooks</span><span class="sxs-lookup"><span data-stu-id="bec96-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="bec96-122">Los pasos de instalación y el código proporcionado en este tutorial son para HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="bec96-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="bec96-123">Sin embargo, Jupyter Notebooks se proporciona para clústeres de HDInsight Spark 1.6 y Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="bec96-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="bec96-124">Se proporciona una descripción de los cuadernos y de los vínculos a estos en el archivo [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) del repositorio de GitHub que los contiene.</span><span class="sxs-lookup"><span data-stu-id="bec96-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="bec96-125">No obstante, este código y los cuadernos vinculados son genéricos y deberían funcionar en cualquier clúster de Spark.</span><span class="sxs-lookup"><span data-stu-id="bec96-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="bec96-126">Los pasos de configuración y administración del clúster pueden ser ligeramente diferentes de los que se muestran aquí si no está usando Spark en HDInsight.</span><span class="sxs-lookup"><span data-stu-id="bec96-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="bec96-127">Para mayor comodidad, estos son los vínculos a los cuadernos de Jupyter para Spark 1.6 (para ejecutarse en el kernel pySpark del servidor de Jupyter Notebook) y Spark 2.0 (para ejecutarse en el kernel pySpark3 del servidor de Jupyter Notebook):</span><span class="sxs-lookup"><span data-stu-id="bec96-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="bec96-128">Cuadernos de Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="bec96-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="bec96-129">Estos cuadernos están indicados para ejecutarse en el kernel pySpark del servidor de cuadernos de Jupyter.</span><span class="sxs-lookup"><span data-stu-id="bec96-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="bec96-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): proporciona información sobre cómo realizar una exploración de datos, el modelado y la puntuación con diversos algoritmos.</span><span class="sxs-lookup"><span data-stu-id="bec96-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="bec96-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): incluye temas sobre el cuaderno 1 y sobre el desarrollo de modelos mediante el ajuste de hiperparámetros y la validación cruzada.</span><span class="sxs-lookup"><span data-stu-id="bec96-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="bec96-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): muestra cómo operacionalizar un modelo guardado con Python en clústeres de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="bec96-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="bec96-133">Cuadernos de Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="bec96-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="bec96-134">Estos cuadernos están indicados para ejecutarse en el kernel pySpark3 del servidor de cuadernos de Jupyter.</span><span class="sxs-lookup"><span data-stu-id="bec96-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="bec96-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): este archivo proporciona información sobre cómo realizar el modelado, la puntuación y la exploración de datos en clústeres de Spark 2.0 mediante el conjunto de datos de carreras y tarifas de taxis en Nueva York que se describe [aquí](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="bec96-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="bec96-136">Este cuaderno puede ser un buen punto de partida para explorar rápidamente el código proporcionado para Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="bec96-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="bec96-137">Para obtener un análisis más pormenorizado de los datos del cuaderno sobre taxis en Nueva York, vea el siguiente cuaderno de esta lista.</span><span class="sxs-lookup"><span data-stu-id="bec96-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="bec96-138">Vea las notas después de esta lista en las que se establece una comparación de estos cuadernos.</span><span class="sxs-lookup"><span data-stu-id="bec96-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="bec96-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): este archivo muestra cómo realizar la comparación de datos (Spark SQL y operaciones de trama de datos), la exploración, modelado y puntuación mediante el conjunto de datos de carreras y tarifas de NYC Taxi descrito [aquí](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="bec96-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="bec96-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): este archivo muestra cómo realizar la comparación de datos (Spark SQL y operaciones de trama de datos), la exploración, modelado y puntuación mediante el conocido conjunto de datos de salidas puntuales de líneas aéreas de 2011 y 2012.</span><span class="sxs-lookup"><span data-stu-id="bec96-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="bec96-141">Se ha integrado el conjunto de datos de las líneas aéreas con los datos climatológicos del aeropuerto (por ejemplo, velocidad del viento, temperatura, altitud, etc.), antes de realizar el modelado, para que estas características climatológicas puedan incluirse en el modelo.</span><span class="sxs-lookup"><span data-stu-id="bec96-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="bec96-142">El conjunto de datos de las líneas aéreas se agregó a los cuadernos de Spark 2.0 para ilustrar mejor el uso de algoritmos de clasificación.</span><span class="sxs-lookup"><span data-stu-id="bec96-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="bec96-143">Consulte los siguientes vínculos para obtener información sobre el conjunto de datos de salidas puntuales de las líneas aéreas y sobre el de datos climatológicos:</span><span class="sxs-lookup"><span data-stu-id="bec96-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="bec96-144">Datos de salida puntuales de líneas aéreas: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="bec96-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="bec96-145">Datos climatológicos del aeropuerto: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="bec96-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="bec96-146">Los cuadernos de Spark 2.0 sobre los conjuntos de datos de los taxis de Nueva York y de retrasos en los vuelos pueden tardar 10 minutos o más en ejecutarse (dependiendo del tamaño del clúster de HDI).</span><span class="sxs-lookup"><span data-stu-id="bec96-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="bec96-147">En el primer cuaderno de la lista anterior se reflejan muchos aspectos de la exploración de datos, la visualización y el entrenamiento del modelo de ML en un cuaderno que tarda menos tiempo en ejecutarse con el conjunto de datos de Nueva York muestreado, en el que los archivos de taxis y tarifas se han unido previamente: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) Este cuaderno tarda mucho menos tiempo en terminar (2-3 minutos) y puede ser un buen punto de partida para realizar una exploración rápida del código proporcionado para Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="bec96-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="bec96-148">Para obtener instrucciones sobre la operacionalización de un modelo de Spark 2.0 y el consumo de modelo para puntuación, consulte el [documento de Spark 1.6 sobre consumo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) para obtener un ejemplo que muestre los pasos necesarios.</span><span class="sxs-lookup"><span data-stu-id="bec96-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="bec96-149">Para utilizar esta opción en Spark 2.0, reemplace el archivo de código Python por [este archivo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="bec96-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="bec96-150">Requisitos previos</span><span class="sxs-lookup"><span data-stu-id="bec96-150">Prerequisites</span></span>
<span data-ttu-id="bec96-151">Los procedimientos siguientes están relacionados con Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="bec96-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="bec96-152">En la versión Spark 2.0, use los cuadernos descritos anteriormente, con sus correspondientes vínculos.</span><span class="sxs-lookup"><span data-stu-id="bec96-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="bec96-153">1. Debe tener una suscripción de Azure.</span><span class="sxs-lookup"><span data-stu-id="bec96-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="bec96-154">Si aún no tiene una, consulte [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)(Obtener una evaluación gratuita de Azure).</span><span class="sxs-lookup"><span data-stu-id="bec96-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="bec96-155">2. Necesita un clúster de Spark 1.6 para completar este tutorial.</span><span class="sxs-lookup"><span data-stu-id="bec96-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="bec96-156">Para crear uno, consulte las instrucciones proporcionadas en [Introducción: creación de clústeres de Apache Spark en HDInsight para Linux y ejecución de consultas interactivas mediante Spark SQL (versión preliminar)](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="bec96-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="bec96-157">En el menú **Seleccionar tipo de clúster** se especifica el tipo de clúster y la versión.</span><span class="sxs-lookup"><span data-stu-id="bec96-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Configuración del inicio de sesión del clúster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="bec96-159">Si quiere leer un tema que muestre cómo utilizar Scala en lugar de Python para completar las tareas de un proceso de ciencia de datos de un extremo a otro, consulte [Ciencia de datos mediante Scala con Spark de Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="bec96-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="bec96-160">Datos de taxis de Nueva York de 2013</span><span class="sxs-lookup"><span data-stu-id="bec96-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="bec96-161">Los datos de carreras de taxi de Nueva York son aproximadamente 20 GB de archivos comprimidos de valores separados por comas (CSV) (~48 GB sin comprimir), que incluyen más de 173 millones de carreras individuales y las tarifas pagadas por cada carrera.</span><span class="sxs-lookup"><span data-stu-id="bec96-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="bec96-162">Cada registro de carrera incluye la hora y la ubicación de recogida y de entrega, el número de licencia de (del conductor) anónimo y el número de ida y vuelta incluye la ubicación de entrega y recogida y el tiempo, la número de licencia y el número de identificador único del taxi.</span><span class="sxs-lookup"><span data-stu-id="bec96-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="bec96-163">Los datos cubren todos los viajes del año 2013 y se proporcionan en los dos conjuntos de datos siguientes para cada mes:</span><span class="sxs-lookup"><span data-stu-id="bec96-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="bec96-164">Los archivos CSV 'trip_data' contienen información detallada de las carreras, como el número de pasajeros, los puntos de recogida y destino, la duración de las carreras y la longitud del recorrido.</span><span class="sxs-lookup"><span data-stu-id="bec96-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="bec96-165">Estos son algunos registros de ejemplo:</span><span class="sxs-lookup"><span data-stu-id="bec96-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="bec96-166">Los archivos CSV 'trip_fare' contienen información detallada de la tarifa que se paga en cada carrera, como el tipo de pago, el importe de la tarifa, los suplementos e impuestos, las propinas y peajes, y el importe total pagado.</span><span class="sxs-lookup"><span data-stu-id="bec96-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="bec96-167">Estos son algunos registros de ejemplo:</span><span class="sxs-lookup"><span data-stu-id="bec96-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="bec96-168">Hemos tomado una muestra del 0,1 % de estos archivos y los hemos combinado en archivos CSV trip\_data and trip\_fare en un único conjunto de datos que se usará como conjunto de datos de entrada en este tutorial.</span><span class="sxs-lookup"><span data-stu-id="bec96-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="bec96-169">La clave única para unir trip\_data and trip\_fare se compone de los campos: medallion, hack\_licence and pickup\_datetime.</span><span class="sxs-lookup"><span data-stu-id="bec96-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="bec96-170">Cada registro del conjunto de datos contiene los siguientes atributos que representan una carrera de taxi de Nueva York:</span><span class="sxs-lookup"><span data-stu-id="bec96-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="bec96-171">Campo</span><span class="sxs-lookup"><span data-stu-id="bec96-171">Field</span></span> | <span data-ttu-id="bec96-172">Breve descripción</span><span class="sxs-lookup"><span data-stu-id="bec96-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="bec96-173">medallion</span><span class="sxs-lookup"><span data-stu-id="bec96-173">medallion</span></span> |<span data-ttu-id="bec96-174">Licencias de taxi anónimas (identificador único del taxi)</span><span class="sxs-lookup"><span data-stu-id="bec96-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="bec96-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="bec96-175">hack_license</span></span> |<span data-ttu-id="bec96-176">Número de licencia anónima de taxi londinense</span><span class="sxs-lookup"><span data-stu-id="bec96-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="bec96-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="bec96-177">vendor_id</span></span> |<span data-ttu-id="bec96-178">Identificador del proveedor del taxi</span><span class="sxs-lookup"><span data-stu-id="bec96-178">Taxi vendor id</span></span> |
| <span data-ttu-id="bec96-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="bec96-179">rate_code</span></span> |<span data-ttu-id="bec96-180">Categoría de tarifa de taxi de Nueva York</span><span class="sxs-lookup"><span data-stu-id="bec96-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="bec96-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="bec96-181">store_and_fwd_flag</span></span> |<span data-ttu-id="bec96-182">Indicador de “guardar y reenviar”</span><span class="sxs-lookup"><span data-stu-id="bec96-182">Store and forward flag</span></span> |
| <span data-ttu-id="bec96-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="bec96-183">pickup_datetime</span></span> |<span data-ttu-id="bec96-184">Fecha y hora de subida</span><span class="sxs-lookup"><span data-stu-id="bec96-184">Pick up date & time</span></span> |
| <span data-ttu-id="bec96-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="bec96-185">dropoff_datetime</span></span> |<span data-ttu-id="bec96-186">Fecha y hora de bajada</span><span class="sxs-lookup"><span data-stu-id="bec96-186">Dropoff date & time</span></span> |
| <span data-ttu-id="bec96-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="bec96-187">pickup_hour</span></span> |<span data-ttu-id="bec96-188">Hora de recogida</span><span class="sxs-lookup"><span data-stu-id="bec96-188">Pick up hour</span></span> |
| <span data-ttu-id="bec96-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="bec96-189">pickup_week</span></span> |<span data-ttu-id="bec96-190">Semana del año de subida</span><span class="sxs-lookup"><span data-stu-id="bec96-190">Pick up week of the year</span></span> |
| <span data-ttu-id="bec96-191">weekday</span><span class="sxs-lookup"><span data-stu-id="bec96-191">weekday</span></span> |<span data-ttu-id="bec96-192">Día de la semana (intervalo de 1 a 7)</span><span class="sxs-lookup"><span data-stu-id="bec96-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="bec96-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="bec96-193">passenger_count</span></span> |<span data-ttu-id="bec96-194">Número de pasajeros en una carrera de taxi</span><span class="sxs-lookup"><span data-stu-id="bec96-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="bec96-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="bec96-195">trip_time_in_secs</span></span> |<span data-ttu-id="bec96-196">Tiempo de la carrera, en segundos</span><span class="sxs-lookup"><span data-stu-id="bec96-196">Trip time in seconds</span></span> |
| <span data-ttu-id="bec96-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="bec96-197">trip_distance</span></span> |<span data-ttu-id="bec96-198">Distancia recorrida en la carrera, en millas</span><span class="sxs-lookup"><span data-stu-id="bec96-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="bec96-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="bec96-199">pickup_longitude</span></span> |<span data-ttu-id="bec96-200">Longitud del punto de subida</span><span class="sxs-lookup"><span data-stu-id="bec96-200">Pick up longitude</span></span> |
| <span data-ttu-id="bec96-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="bec96-201">pickup_latitude</span></span> |<span data-ttu-id="bec96-202">Latitud del punto de subida</span><span class="sxs-lookup"><span data-stu-id="bec96-202">Pick up latitude</span></span> |
| <span data-ttu-id="bec96-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="bec96-203">dropoff_longitude</span></span> |<span data-ttu-id="bec96-204">Longitud del punto de bajada</span><span class="sxs-lookup"><span data-stu-id="bec96-204">Dropoff longitude</span></span> |
| <span data-ttu-id="bec96-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="bec96-205">dropoff_latitude</span></span> |<span data-ttu-id="bec96-206">Latitud del punto de bajada</span><span class="sxs-lookup"><span data-stu-id="bec96-206">Dropoff latitude</span></span> |
| <span data-ttu-id="bec96-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="bec96-207">direct_distance</span></span> |<span data-ttu-id="bec96-208">Distancia directa entre las ubicaciones de subida y bajada</span><span class="sxs-lookup"><span data-stu-id="bec96-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="bec96-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="bec96-209">payment_type</span></span> |<span data-ttu-id="bec96-210">Tipo de pago (efectivo, tarjeta de crédito, etc.)</span><span class="sxs-lookup"><span data-stu-id="bec96-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="bec96-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="bec96-211">fare_amount</span></span> |<span data-ttu-id="bec96-212">Importe de la tarifa en</span><span class="sxs-lookup"><span data-stu-id="bec96-212">Fare amount in</span></span> |
| <span data-ttu-id="bec96-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="bec96-213">surcharge</span></span> |<span data-ttu-id="bec96-214">Suplemento</span><span class="sxs-lookup"><span data-stu-id="bec96-214">Surcharge</span></span> |
| <span data-ttu-id="bec96-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="bec96-215">mta_tax</span></span> |<span data-ttu-id="bec96-216">Impuestos de MTA</span><span class="sxs-lookup"><span data-stu-id="bec96-216">Mta tax</span></span> |
| <span data-ttu-id="bec96-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="bec96-217">tip_amount</span></span> |<span data-ttu-id="bec96-218">Importe de la propina</span><span class="sxs-lookup"><span data-stu-id="bec96-218">Tip amount</span></span> |
| <span data-ttu-id="bec96-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="bec96-219">tolls_amount</span></span> |<span data-ttu-id="bec96-220">Importe de los peajes</span><span class="sxs-lookup"><span data-stu-id="bec96-220">Tolls amount</span></span> |
| <span data-ttu-id="bec96-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="bec96-221">total_amount</span></span> |<span data-ttu-id="bec96-222">Importe total</span><span class="sxs-lookup"><span data-stu-id="bec96-222">Total amount</span></span> |
| <span data-ttu-id="bec96-223">tipped</span><span class="sxs-lookup"><span data-stu-id="bec96-223">tipped</span></span> |<span data-ttu-id="bec96-224">Con propina (0 o 1 para No o Sí)</span><span class="sxs-lookup"><span data-stu-id="bec96-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="bec96-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="bec96-225">tip_class</span></span> |<span data-ttu-id="bec96-226">Clase de propina (0: 0 $, 1: 0-5 $, 2: 6-10 $, 3: 11-20 $, 4: > 20 $)</span><span class="sxs-lookup"><span data-stu-id="bec96-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="bec96-227">Ejecución del código desde un Notebook de Jupyter en el clúster de Spark</span><span class="sxs-lookup"><span data-stu-id="bec96-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="bec96-228">Puede iniciar Jupyter Notebook desde el portal de Azure.</span><span class="sxs-lookup"><span data-stu-id="bec96-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="bec96-229">Busque el clúster de Spark en el panel y haga clic en él para entrar en la página de administración del clúster.</span><span class="sxs-lookup"><span data-stu-id="bec96-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="bec96-230">Después, haga clic en **Paneles de clúster** -> **Jupyter Notebook** para abrir el cuaderno asociado al clúster Spark.</span><span class="sxs-lookup"><span data-stu-id="bec96-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Paneles de clúster](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="bec96-232">También puede ir a ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** para acceder a los cuadernos de Jupyter Notebook.</span><span class="sxs-lookup"><span data-stu-id="bec96-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="bec96-233">Reemplace la parte CLUSTERNAME de esta dirección URL por el nombre de su propio clúster.</span><span class="sxs-lookup"><span data-stu-id="bec96-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="bec96-234">Necesitará la contraseña de su cuenta de administrador para acceder a los Notebooks.</span><span class="sxs-lookup"><span data-stu-id="bec96-234">You need the password for your admin account to access the notebooks.</span></span>

![Examinar cuadernos de Jupyter Notebook](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="bec96-236">Seleccione PySpark para ver un directorio que contenga algunos ejemplos de cuadernos previamente empaquetados que utilicen la API de PySpark. Los cuadernos que incluyen los ejemplos de código para este conjunto de aplicaciones de tema de Spark están disponibles en [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark).</span><span class="sxs-lookup"><span data-stu-id="bec96-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="bec96-237">Puede cargar los cuadernos directamente desde [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) en el servidor de Jupyter Notebook, en su clúster de Spark.</span><span class="sxs-lookup"><span data-stu-id="bec96-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="bec96-238">En la página principal de su instancia de Jupyter, haga clic en el botón **Cargar** de la parte derecha de la pantalla.</span><span class="sxs-lookup"><span data-stu-id="bec96-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="bec96-239">Se abre un explorador de archivos.</span><span class="sxs-lookup"><span data-stu-id="bec96-239">It opens a file explorer.</span></span> <span data-ttu-id="bec96-240">Pegue aquí la dirección URL de GitHub (contenido sin procesar) del cuaderno y haga clic en **Abrir**.</span><span class="sxs-lookup"><span data-stu-id="bec96-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="bec96-241">Verá el nombre de archivo en la lista de archivos de Jupyter de nuevo con un botón **Cargar** .</span><span class="sxs-lookup"><span data-stu-id="bec96-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="bec96-242">Haga clic en este botón **Cargar** .</span><span class="sxs-lookup"><span data-stu-id="bec96-242">Click this **Upload** button.</span></span> <span data-ttu-id="bec96-243">Ahora ya ha importado el cuaderno.</span><span class="sxs-lookup"><span data-stu-id="bec96-243">Now you have imported the notebook.</span></span> <span data-ttu-id="bec96-244">Repita estos pasos para cargar los otros cuadernos de este tutorial.</span><span class="sxs-lookup"><span data-stu-id="bec96-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="bec96-245">Puede hacer clic con el botón derecho del mouse en los vínculos del explorador y seleccionar **Copiar vínculo** para obtener la URL de contenido sin procesar de GitHub.</span><span class="sxs-lookup"><span data-stu-id="bec96-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="bec96-246">Puede pegar esta dirección URL en el cuadro de diálogo del explorador de carga de archivos de Jupyter.</span><span class="sxs-lookup"><span data-stu-id="bec96-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="bec96-247">Ahora puede:</span><span class="sxs-lookup"><span data-stu-id="bec96-247">Now you can:</span></span>

* <span data-ttu-id="bec96-248">Ver el código haciendo clic en el cuaderno.</span><span class="sxs-lookup"><span data-stu-id="bec96-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="bec96-249">Ejecutar cada celda presionando **MAYÚS+ENTRAR**.</span><span class="sxs-lookup"><span data-stu-id="bec96-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="bec96-250">Ejecutar todo el cuaderno haciendo clic en **Celda** -> **Run**.</span><span class="sxs-lookup"><span data-stu-id="bec96-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="bec96-251">Usar la visualización automática de consultas.</span><span class="sxs-lookup"><span data-stu-id="bec96-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="bec96-252">El kernel de PySpark visualiza automáticamente la salida de las consultas de SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="bec96-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="bec96-253">Tiene la opción de seleccionar entre diferentes tipos de visualizaciones (tabla, circular, línea, área o barra) mediante los botones del menú **Tipo** del cuaderno:</span><span class="sxs-lookup"><span data-stu-id="bec96-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Curva ROC de regresión logística para el enfoque genérico](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="bec96-255">Pasos siguientes</span><span class="sxs-lookup"><span data-stu-id="bec96-255">What's next?</span></span>
<span data-ttu-id="bec96-256">Ahora que ya ha configurado un clúster de HDInsight Spark y ha cargado los cuadernos de Jupyter Notebook, está listo para trabajar con los temas correspondientes a estos tres cuadernos de PySpark,</span><span class="sxs-lookup"><span data-stu-id="bec96-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="bec96-257">que muestran cómo explorar los datos y crear y utilizar los modelos.</span><span class="sxs-lookup"><span data-stu-id="bec96-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="bec96-258">El cuaderno de exploración y modelado de datos avanzado muestra cómo incluir la validación cruzada, el barrido de los hiperparámetros y la evaluación de modelos.</span><span class="sxs-lookup"><span data-stu-id="bec96-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="bec96-259">**Exploración de datos y modelado con Spark** : explore el conjunto de datos y cree los modelos de aprendizaje automático que se puntuarán y evaluarán aquí mediante el tema [Exploración y modelado de datos con Spark](machine-learning-data-science-spark-data-exploration-modeling.md).</span><span class="sxs-lookup"><span data-stu-id="bec96-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="bec96-260">**Consumo de modelos** : para saber cómo puntuar los modelos de clasificación y regresión creados en este tema, consulte [Puntuación de modelos de aprendizaje automático creados con Spark](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="bec96-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="bec96-261">**Validación cruzada y barrido de hiperparámetros**: Consulte [Exploración y modelado avanzados de datos con Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) sobre cómo pueden prepararse los modelos con el barrido de hiperparámetros y la validación cruzada.</span><span class="sxs-lookup"><span data-stu-id="bec96-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

