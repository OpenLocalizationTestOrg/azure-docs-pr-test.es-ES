---
title: "aaaGuide toohello Red neuronal redes de lenguaje de especificación | Documentos de Microsoft"
description: "Sintaxis de hello Net # neuronal redes de lenguaje de especificación, junto con ejemplos de cómo toocreate una red neuronal personalizada del modelo de aprendizaje automático de Azure de Microsoft con Net #"
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 3493247ecc39ca3a1382510ad520d7017159ff62
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 10/06/2017
---
# <a name="guide-toonet-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="80ac3-103">Guía de lenguaje de especificación de la red neuronal tooNet # para el aprendizaje automático de Azure</span><span class="sxs-lookup"><span data-stu-id="80ac3-103">Guide tooNet# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="80ac3-104">Información general</span><span class="sxs-lookup"><span data-stu-id="80ac3-104">Overview</span></span>
<span data-ttu-id="80ac3-105">NET # es un lenguaje desarrollado por Microsoft que es usado toodefine arquitecturas de red neuronal.</span><span class="sxs-lookup"><span data-stu-id="80ac3-105">Net# is a language developed by Microsoft that is used toodefine neural network architectures.</span></span> <span data-ttu-id="80ac3-106">Puede usar Net# en módulos de red neuronal de Microsoft Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="80ac3-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in hello MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in hello `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="80ac3-107">En este artículo, aprenderá los conceptos básicos necesarios toodevelop una red neuronal personalizada:</span><span class="sxs-lookup"><span data-stu-id="80ac3-107">In this article, you will learn basic concepts needed toodevelop a custom neural network:</span></span> 

* <span data-ttu-id="80ac3-108">Requisitos de red neuronal y cómo toodefine Hola componentes principales</span><span class="sxs-lookup"><span data-stu-id="80ac3-108">Neural network requirements and how toodefine hello primary components</span></span>
* <span data-ttu-id="80ac3-109">sintaxis de Hola y palabras clave del lenguaje de especificación de Net # Hola</span><span class="sxs-lookup"><span data-stu-id="80ac3-109">hello syntax and keywords of hello Net# specification language</span></span>
* <span data-ttu-id="80ac3-110">Ejemplos de redes neuronales personalizadas creadas mediante Net#</span><span class="sxs-lookup"><span data-stu-id="80ac3-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="80ac3-111">Conceptos básicos sobre redes neuronales</span><span class="sxs-lookup"><span data-stu-id="80ac3-111">Neural network basics</span></span>
<span data-ttu-id="80ac3-112">Formada por una estructura de red neuronal ***nodos*** que se organizan en ***capas***y ponderadas ***conexiones*** (o ***bordes***) entre nodos de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between hello nodes.</span></span> <span data-ttu-id="80ac3-113">conexiones de Hello son direccionales, y cada conexión tiene un ***origen*** nodo y un ***destino*** nodo.</span><span class="sxs-lookup"><span data-stu-id="80ac3-113">hello connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="80ac3-114">Cada una de las ***capas entrenables*** (una capa oculta o de salida) tiene uno o varios ***conjuntos de conexiones***.</span><span class="sxs-lookup"><span data-stu-id="80ac3-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="80ac3-115">Una agrupación de conexiones está formada por una capa de origen y una especificación de las conexiones de Hola desde esa capa de origen.</span><span class="sxs-lookup"><span data-stu-id="80ac3-115">A connection bundle consists of a source layer and a specification of hello connections from that source layer.</span></span> <span data-ttu-id="80ac3-116">Todas las conexiones de hello en un recurso compartido de paquete determinada Hola mismo ***capa de origen*** y Hola mismo ***capa de destino***.</span><span class="sxs-lookup"><span data-stu-id="80ac3-116">All hello connections in a given bundle share hello same ***source layer*** and hello same ***destination layer***.</span></span> <span data-ttu-id="80ac3-117">En Net #, una agrupación de conexiones se considera como capa de destino del paquete toohello que pertenecen.</span><span class="sxs-lookup"><span data-stu-id="80ac3-117">In Net#, a connection bundle is considered as belonging toohello bundle's destination layer.</span></span>  

<span data-ttu-id="80ac3-118">NET # admite distintos tipos de paquetes de conexión, que le permite personalizar la forma hello las entradas son asignadas toohidden capas y salidas de toohello asignado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-118">Net# supports various kinds of connection bundles, which lets you customize hello way inputs are mapped toohidden layers and mapped toohello outputs.</span></span>   

<span data-ttu-id="80ac3-119">predeterminado de Hola o agrupación estándar es un **agrupación completa**, en el que cada nodo de hello capa de origen es nodo de tooevery conectado en la capa de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-119">hello default or standard bundle is a **full bundle**, in which each node in hello source layer is connected tooevery node in hello destination layer.</span></span>  

<span data-ttu-id="80ac3-120">Además, Net # admite Hola después de cuatro tipos de agrupaciones avanzadas de conexión:</span><span class="sxs-lookup"><span data-stu-id="80ac3-120">Additionally, Net# supports hello following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="80ac3-121">**Conjuntos filtrados**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-121">**Filtered bundles**.</span></span> <span data-ttu-id="80ac3-122">usuario de Hello puede definir un predicado mediante ubicaciones Hola de nodo de nivel de origen de Hola y el nodo de nivel de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-122">hello user can define a predicate by using hello locations of hello source layer node and hello destination layer node.</span></span> <span data-ttu-id="80ac3-123">Los nodos están conectados siempre predicado hello es True.</span><span class="sxs-lookup"><span data-stu-id="80ac3-123">Nodes are connected whenever hello predicate is True.</span></span>
* <span data-ttu-id="80ac3-124">**Conjuntos convolucionales**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-124">**Convolutional bundles**.</span></span> <span data-ttu-id="80ac3-125">usuario de Hello puede definir grupos pequeños de nodos en la capa de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-125">hello user can define small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="80ac3-126">Cada nodo en la capa de destino de hello es conectado tooone entorno de nodos de nivel de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-126">Each node in hello destination layer is connected tooone neighborhood of nodes in hello source layer.</span></span>
* <span data-ttu-id="80ac3-127">**Conjuntos de agrupación** y **conjuntos de normalización de respuesta**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="80ac3-128">Se trata de agrupaciones de tooconvolutional similar en ese Hola usuario define grupos pequeños de nodos de nivel de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-128">These are similar tooconvolutional bundles in that hello user defines small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="80ac3-129">diferencia de Hello es que pesos Hola de bordes de hello en estos paquetes no son trainable.</span><span class="sxs-lookup"><span data-stu-id="80ac3-129">hello difference is that hello weights of hello edges in these bundles are not trainable.</span></span> <span data-ttu-id="80ac3-130">En su lugar, se aplica una función predefinida nodo de origen toohello valores del valor de nodo de destino de toodetermine Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-130">Instead, a predefined function is applied toohello source node values toodetermine hello destination node value.</span></span>  

<span data-ttu-id="80ac3-131">Con Net # toodefine Hola estructura de una red neuronal hace posible toodefine estructuras complejas, como redes neurales profundas o convoluciones de dimensiones arbitrarias, que se conocen el aprendizaje de tooimprove de datos, como imágenes, audio o vídeo.</span><span class="sxs-lookup"><span data-stu-id="80ac3-131">Using Net# toodefine hello structure of a neural network makes it possible toodefine complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known tooimprove learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="80ac3-132">Personalizaciones compatibles</span><span class="sxs-lookup"><span data-stu-id="80ac3-132">Supported customizations</span></span>
<span data-ttu-id="80ac3-133">arquitectura de Hola de modelos de red neuronal que cree en aprendizaje automático de Azure se puede personalizar ampliamente mediante Net #.</span><span class="sxs-lookup"><span data-stu-id="80ac3-133">hello architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="80ac3-134">Puede:</span><span class="sxs-lookup"><span data-stu-id="80ac3-134">You can:</span></span>  

* <span data-ttu-id="80ac3-135">Cree niveles ocultos y control hello número de nodos en cada capa.</span><span class="sxs-lookup"><span data-stu-id="80ac3-135">Create hidden layers and control hello number of nodes in each layer.</span></span>
* <span data-ttu-id="80ac3-136">Especifique cómo los niveles están toobe conectado tooeach otros.</span><span class="sxs-lookup"><span data-stu-id="80ac3-136">Specify how layers are toobe connected tooeach other.</span></span>
* <span data-ttu-id="80ac3-137">Definir estructuras de conectividad especial como convoluciones y conjuntos ponderados de uso compartido.</span><span class="sxs-lookup"><span data-stu-id="80ac3-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="80ac3-138">Especificar diferentes funciones de activación.</span><span class="sxs-lookup"><span data-stu-id="80ac3-138">Specify different activation functions.</span></span>  

<span data-ttu-id="80ac3-139">Para obtener detalles de la sintaxis del lenguaje de especificación de hello, consulte [especificación de la estructura](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="80ac3-139">For details of hello specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="80ac3-140">Para obtener ejemplos de definir redes neurales para algunas tareas, desde toocomplex símplex, de aprendizaje de automático comunes vea [ejemplos](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="80ac3-140">For examples of defining neural networks for some common machine learning tasks, from simplex toocomplex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="80ac3-141">Requisitos generales</span><span class="sxs-lookup"><span data-stu-id="80ac3-141">General requirements</span></span>
* <span data-ttu-id="80ac3-142">Debe haber exactamente una capa de salida, al menos una capa de entrada y ninguna o varias capas ocultas.</span><span class="sxs-lookup"><span data-stu-id="80ac3-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="80ac3-143">Cada capa tiene un número fijo de nodos, ordenados conceptualmente en una matriz rectangular de dimensiones arbitrarias.</span><span class="sxs-lookup"><span data-stu-id="80ac3-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="80ac3-144">Capas entradas no tienen asociados entrenados parámetros y representan punto Hola donde los datos de instancia entra en la red de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-144">Input layers have no associated trained parameters and represent hello point where instance data enters hello network.</span></span> 
* <span data-ttu-id="80ac3-145">Trainable capas (Hola niveles ocultos y salidas) tienen asociados parámetros entrenados, que se conocen como pesos e inclinaciones.</span><span class="sxs-lookup"><span data-stu-id="80ac3-145">Trainable layers (hello hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="80ac3-146">los nodos de origen y destino de Hello deben estar en capas independientes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-146">hello source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="80ac3-147">Las conexiones deben ser acíclicas; en otras palabras, no puede ser una cadena de conexiones iniciales toohello back-nodo de origen inicial.</span><span class="sxs-lookup"><span data-stu-id="80ac3-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back toohello initial source node.</span></span>
* <span data-ttu-id="80ac3-148">nivel de salida de Hello no puede ser una capa de origen de una agrupación de conexiones.</span><span class="sxs-lookup"><span data-stu-id="80ac3-148">hello output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="80ac3-149">Especificación de estructura</span><span class="sxs-lookup"><span data-stu-id="80ac3-149">Structure specifications</span></span>
<span data-ttu-id="80ac3-150">Una especificación de la estructura de red neuronal se compone de tres secciones: Hola **declaración de constante**, hello **capas declaración**, hello **declaración de conexión**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-150">A neural network structure specification is composed of three sections: hello **constant declaration**, hello **layer declaration**, hello **connection declaration**.</span></span> <span data-ttu-id="80ac3-151">También hay una sección de **declaración de uso compartido** opcional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="80ac3-152">secciones de Hello pueden especificarse en cualquier orden.</span><span class="sxs-lookup"><span data-stu-id="80ac3-152">hello sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="80ac3-153">Declaración constante</span><span class="sxs-lookup"><span data-stu-id="80ac3-153">Constant declaration</span></span>
<span data-ttu-id="80ac3-154">Una declaración de constante es opcional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-154">A constant declaration is optional.</span></span> <span data-ttu-id="80ac3-155">Proporciona un medio toodefine valores utilizados en otra parte en la definición de red neuronal de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-155">It provides a means toodefine values used elsewhere in hello neural network definition.</span></span> <span data-ttu-id="80ac3-156">instrucción de declaración de Hello consta de un identificador seguido por un signo igual y una expresión de valor.</span><span class="sxs-lookup"><span data-stu-id="80ac3-156">hello declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="80ac3-157">Por ejemplo, hello sigue instrucción define una constante **x**:</span><span class="sxs-lookup"><span data-stu-id="80ac3-157">For example, hello following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="80ac3-158">toodefine dos o más constantes simultáneamente, incluya los nombres de identificador hello y los valores entre llaves y sepárelas con punto y coma.</span><span class="sxs-lookup"><span data-stu-id="80ac3-158">toodefine two or more constants simultaneously, enclose hello identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="80ac3-159">Por ejemplo:</span><span class="sxs-lookup"><span data-stu-id="80ac3-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="80ac3-160">lado derecho de Hola de cada expresión de asignación puede ser un entero, un número real, un valor booleano (True o False) o una expresión matemática.</span><span class="sxs-lookup"><span data-stu-id="80ac3-160">hello right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="80ac3-161">Por ejemplo:</span><span class="sxs-lookup"><span data-stu-id="80ac3-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="80ac3-162">Declaración de capas</span><span class="sxs-lookup"><span data-stu-id="80ac3-162">Layer declaration</span></span>
<span data-ttu-id="80ac3-163">se requiere la declaración de la capa de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-163">hello layer declaration is required.</span></span> <span data-ttu-id="80ac3-164">Define el tamaño de Hola y el origen de capa de hello, incluidas sus agrupaciones de conexión y los atributos.</span><span class="sxs-lookup"><span data-stu-id="80ac3-164">It defines hello size and source of hello layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="80ac3-165">Hola empieza de instrucción de declaración con nombre de Hola de capa de hello (de entrada, oculto o de salida), a continuación, las dimensiones de Hola de capa de hello (una tupla de números enteros positivos).</span><span class="sxs-lookup"><span data-stu-id="80ac3-165">hello declaration statement starts with hello name of hello layer (input, hidden, or output), followed by hello dimensions of hello layer (a tuple of positive integers).</span></span> <span data-ttu-id="80ac3-166">Por ejemplo:</span><span class="sxs-lookup"><span data-stu-id="80ac3-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="80ac3-167">producto de Hola de dimensiones de hello es número Hola de nodos de nivel de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-167">hello product of hello dimensions is hello number of nodes in hello layer.</span></span> <span data-ttu-id="80ac3-168">En este ejemplo, hay dos dimensiones [5,20], lo que significa que hay 100 nodos de capa de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in hello layer.</span></span>
* <span data-ttu-id="80ac3-169">las capas de Hola se pueden declarar en cualquier orden, con una excepción: si se define más de un nivel de entrada, Hola orden en que se declaran debe coincidir con hello de características de los datos de entrada de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-169">hello layers can be declared in any order, with one exception: If more than one input layer is defined, hello order in which they are declared must match hello order of features in hello input data.</span></span>  

<span data-ttu-id="80ac3-170">toospecify que el número de nodos en una capa de hello ser determina automáticamente, use hello **automática** palabra clave.</span><span class="sxs-lookup"><span data-stu-id="80ac3-170">toospecify that hello number of nodes in a layer be determined automatically, use hello **auto** keyword.</span></span> <span data-ttu-id="80ac3-171">Hola **automática** palabra clave tiene efectos diferentes, dependiendo del nivel de hello:</span><span class="sxs-lookup"><span data-stu-id="80ac3-171">hello **auto** keyword has different effects, depending on hello layer:</span></span>  

* <span data-ttu-id="80ac3-172">En una declaración de nivel de entrada, el número de Hola de nodos es número Hola de características de los datos de entrada de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-172">In an input layer declaration, hello number of nodes is hello number of features in hello input data.</span></span>
* <span data-ttu-id="80ac3-173">En una declaración de nivel oculto, número de Hola de nodos es número Hola especificado por el valor del parámetro hello para **número de nodos ocultos**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-173">In a hidden layer declaration, hello number of nodes is hello number that is specified by hello parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="80ac3-174">En una declaración de nivel de salida, número de Hola de nodos es 2 para la clasificación de dos clases, 1 de regresión y toohello igual número de nodos de salida para la clasificación multiclase.</span><span class="sxs-lookup"><span data-stu-id="80ac3-174">In an output layer declaration, hello number of nodes is 2 for two-class classification, 1 for regression, and equal toohello number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="80ac3-175">Por ejemplo, hello siguiente definición de red permite Hola tamaño de todos los toobe capas determina automáticamente:</span><span class="sxs-lookup"><span data-stu-id="80ac3-175">For example, hello following network definition allows hello size of all layers toobe automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="80ac3-176">Una declaración de capa de una capa trainable (Hola niveles ocultos o de salida) puede incluir opcionalmente la función de salida de hello (también denominada una función de activación), cuyo valor predeterminado es demasiado**sigmoidea** para los modelos de clasificación y **lineal** para los modelos de regresión.</span><span class="sxs-lookup"><span data-stu-id="80ac3-176">A layer declaration for a trainable layer (hello hidden or output layers) can optionally include hello output function (also called an activation function), which defaults too**sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="80ac3-177">(Incluso si utiliza Hola predeterminado, se debe indicar explícitamente función de activación de hello, si lo desea para mayor claridad.)</span><span class="sxs-lookup"><span data-stu-id="80ac3-177">(Even if you use hello default, you can explicitly state hello activation function, if desired for clarity.)</span></span>

<span data-ttu-id="80ac3-178">Hello salida funciones siguientes se admiten:</span><span class="sxs-lookup"><span data-stu-id="80ac3-178">hello following output functions are supported:</span></span>  

* <span data-ttu-id="80ac3-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="80ac3-179">sigmoid</span></span>
* <span data-ttu-id="80ac3-180">linear</span><span class="sxs-lookup"><span data-stu-id="80ac3-180">linear</span></span>
* <span data-ttu-id="80ac3-181">softmax</span><span class="sxs-lookup"><span data-stu-id="80ac3-181">softmax</span></span>
* <span data-ttu-id="80ac3-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="80ac3-182">rlinear</span></span>
* <span data-ttu-id="80ac3-183">square</span><span class="sxs-lookup"><span data-stu-id="80ac3-183">square</span></span>
* <span data-ttu-id="80ac3-184">sqrt</span><span class="sxs-lookup"><span data-stu-id="80ac3-184">sqrt</span></span>
* <span data-ttu-id="80ac3-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="80ac3-185">srlinear</span></span>
* <span data-ttu-id="80ac3-186">abs</span><span class="sxs-lookup"><span data-stu-id="80ac3-186">abs</span></span>
* <span data-ttu-id="80ac3-187">tanh</span><span class="sxs-lookup"><span data-stu-id="80ac3-187">tanh</span></span> 
* <span data-ttu-id="80ac3-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="80ac3-188">brlinear</span></span>  

<span data-ttu-id="80ac3-189">Por ejemplo, hello siguiente declaración usa hello **softmax** función:</span><span class="sxs-lookup"><span data-stu-id="80ac3-189">For example, hello following declaration uses hello **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="80ac3-190">Declaración de conexiones</span><span class="sxs-lookup"><span data-stu-id="80ac3-190">Connection declaration</span></span>
<span data-ttu-id="80ac3-191">Inmediatamente después de definir capa trainable hello, debe declarar las conexiones entre las capas de Hola que ha definido.</span><span class="sxs-lookup"><span data-stu-id="80ac3-191">Immediately after defining hello trainable layer, you must declare connections among hello layers you have defined.</span></span> <span data-ttu-id="80ac3-192">declaración de agrupación de conexiones de Hello comienza con la palabra clave de hello **de**, seguido del nombre de Hola de los tipo de hello y capa de origen de agrupación de Hola de toocreate de agrupación de conexiones.</span><span class="sxs-lookup"><span data-stu-id="80ac3-192">hello connection bundle declaration starts with hello keyword **from**, followed by hello name of hello bundle's source layer and hello kind of connection bundle toocreate.</span></span>   

<span data-ttu-id="80ac3-193">Actualmente se admiten cinco tipos de conjuntos de conexiones:</span><span class="sxs-lookup"><span data-stu-id="80ac3-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="80ac3-194">**Completa** agrupaciones, indicados por la palabra clave de hello **todos**</span><span class="sxs-lookup"><span data-stu-id="80ac3-194">**Full** bundles, indicated by hello keyword **all**</span></span>
* <span data-ttu-id="80ac3-195">**Filtrar** agrupaciones, indicados por la palabra clave de hello **donde**, seguido de una expresión de predicado</span><span class="sxs-lookup"><span data-stu-id="80ac3-195">**Filtered** bundles, indicated by hello keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="80ac3-196">**Convolutional** agrupaciones, indicados por la palabra clave de hello **convolve**, seguido de los atributos de circunvolución Hola</span><span class="sxs-lookup"><span data-stu-id="80ac3-196">**Convolutional** bundles, indicated by hello keyword **convolve**, followed by hello convolution attributes</span></span>
* <span data-ttu-id="80ac3-197">**Agrupación de** agrupaciones, indicados por palabras clave de hello **max pool** o **significa grupo**</span><span class="sxs-lookup"><span data-stu-id="80ac3-197">**Pooling** bundles, indicated by hello keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="80ac3-198">**Normalización de respuesta** agrupaciones, indicados por la palabra clave de hello **norma de respuesta**</span><span class="sxs-lookup"><span data-stu-id="80ac3-198">**Response normalization** bundles, indicated by hello keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="80ac3-199">Conjuntos completos</span><span class="sxs-lookup"><span data-stu-id="80ac3-199">Full bundles</span></span>
<span data-ttu-id="80ac3-200">Un paquete de conexión completa incluye una conexión de cada nodo en nodo de tooeach de nivel de origen de hello en la capa de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-200">A full connection bundle includes a connection from each node in hello source layer tooeach node in hello destination layer.</span></span> <span data-ttu-id="80ac3-201">Se trata de un tipo de conexión de red de hello predeterminado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-201">This is hello default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="80ac3-202">Conjuntos filtrados</span><span class="sxs-lookup"><span data-stu-id="80ac3-202">Filtered bundles</span></span>
<span data-ttu-id="80ac3-203">Una especificación de conjunto de conexiones filtrado incluye un predicado, expresado sintácticamente de manera muy similar a una expresión lambda de C#.</span><span class="sxs-lookup"><span data-stu-id="80ac3-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="80ac3-204">Hello en el ejemplo siguiente se define dos paquetes de filtrado:</span><span class="sxs-lookup"><span data-stu-id="80ac3-204">hello following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="80ac3-205">En el predicado de Hola para *ByRow*, **s** es un parámetro que representa un índice en una matriz rectangular de Hola de nodos de nivel de entrada de hello, *píxeles*, y **d.**  es un parámetro que representa un índice en una matriz de Hola de nodos del nivel oculto de hello, *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-205">In hello predicate for *ByRow*, **s** is a parameter representing an index into hello rectangular array of nodes of hello input layer, *Pixels*, and **d** is a parameter representing an index into hello array of nodes of hello hidden layer, *ByRow*.</span></span> <span data-ttu-id="80ac3-206">Hola tipo de ambos **s** y **d.** es una tupla de enteros de longitud de dos.</span><span class="sxs-lookup"><span data-stu-id="80ac3-206">hello type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="80ac3-207">Conceptualmente, **s** intervalos sobre todos los pares de enteros con *0 <= s[0] < 10* y *0 <= s[1] < 20* y **d** intervalos de todos los pares de enteros con *0 <= d[0] < 10* y *0 <= d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="80ac3-208">En el lado derecho de Hola de expresión de predicado de hello, hay una condición.</span><span class="sxs-lookup"><span data-stu-id="80ac3-208">On hello right-hand side of hello predicate expression, there is a condition.</span></span> <span data-ttu-id="80ac3-209">En este ejemplo, para cada valor de **s** y **d.** esa condición hello es True, hay un borde Hola capa nodo toohello destino capa del nodo de origen.</span><span class="sxs-lookup"><span data-stu-id="80ac3-209">In this example, for every value of **s** and **d** such that hello condition is True, there is an edge from hello source layer node toohello destination layer node.</span></span> <span data-ttu-id="80ac3-210">Por lo tanto, esta expresión de filtro indica ese paquete Hola incluye una conexión desde el nodo de hello definido por **s** definido por el nodo de toohello **d.** en todos los casos donde s [0] es igual tood [0].</span><span class="sxs-lookup"><span data-stu-id="80ac3-210">Thus, this filter expression indicates that hello bundle includes a connection from hello node defined by **s** toohello node defined by **d** in all cases where s[0] is equal tood[0].</span></span>  

<span data-ttu-id="80ac3-211">También tiene la posibilidad de especificar un conjunto de ponderaciones para un conjunto filtrado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="80ac3-212">Hola valor para hello **pesos** atributo debe ser una tupla de los valores de punto con una longitud que coincida con el número de Hola de conexiones definidos por la agrupación de Hola flotante.</span><span class="sxs-lookup"><span data-stu-id="80ac3-212">hello value for hello **Weights** attribute must be a tuple of floating point values with a length that matches hello number of connections defined by hello bundle.</span></span> <span data-ttu-id="80ac3-213">De manera predeterminada, las ponderaciones se generan de manera aleatoria.</span><span class="sxs-lookup"><span data-stu-id="80ac3-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="80ac3-214">Los valores de peso se agrupan por su índice de nodo de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-214">Weight values are grouped by hello destination node index.</span></span> <span data-ttu-id="80ac3-215">Es decir, si está conectado el primer nodo de destino Hola tardó nodos de origen, Hola primero *K* elementos de hello **pesos** tupla son pesos de hello para el nodo de destino primera hello, en el orden de índice de origen.</span><span class="sxs-lookup"><span data-stu-id="80ac3-215">That is, if hello first destination node is connected tooK source nodes, hello first *K* elements of hello **Weights** tuple are hello weights for hello first destination node, in source index order.</span></span> <span data-ttu-id="80ac3-216">Hola que mismo se aplica a Hola restantes nodos de destino.</span><span class="sxs-lookup"><span data-stu-id="80ac3-216">hello same applies for hello remaining destination nodes.</span></span>  

<span data-ttu-id="80ac3-217">Es posible toospecify pesos directamente como valores constantes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-217">It's possible toospecify weights directly as constant values.</span></span> <span data-ttu-id="80ac3-218">Por ejemplo, si ha aprendido pesos Hola anteriormente, puede especificarlos como constantes con esta sintaxis:</span><span class="sxs-lookup"><span data-stu-id="80ac3-218">For example, if you learned hello weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="80ac3-219">Conjuntos convolucionales</span><span class="sxs-lookup"><span data-stu-id="80ac3-219">Convolutional bundles</span></span>
<span data-ttu-id="80ac3-220">Cuando los datos de entrenamiento de hello tienen una estructura homogénea, conexiones convolutional son características de alto nivel de uso frecuente toolearn de datos de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-220">When hello training data has a homogeneous structure, convolutional connections are commonly used toolearn high-level features of hello data.</span></span> <span data-ttu-id="80ac3-221">Por ejemplo, en datos de imagen, audio o vídeo, la dimensionalidad espacial o temporal puede ser bastante homogénea.</span><span class="sxs-lookup"><span data-stu-id="80ac3-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="80ac3-222">Agrupaciones de convolutional emplean rectangular **kernels** que son Deslizar las dimensiones de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-222">Convolutional bundles employ rectangular **kernels** that are slid through hello dimensions.</span></span> <span data-ttu-id="80ac3-223">Básicamente, cada núcleo define un conjunto de pesos que se aplican en los grupos locales, que se hace referencia tooas **aplicaciones de kernel**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred tooas **kernel applications**.</span></span> <span data-ttu-id="80ac3-224">Cada aplicación de kernel corresponde tooa nodo en la capa de origen de hello, que es lo que se conoce tooas hello **nodo central**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-224">Each kernel application corresponds tooa node in hello source layer, which is referred tooas hello **central node**.</span></span> <span data-ttu-id="80ac3-225">pesos de Hola de un núcleo se comparten entre muchas conexiones.</span><span class="sxs-lookup"><span data-stu-id="80ac3-225">hello weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="80ac3-226">En un paquete convolutional, cada núcleo es rectangular y todas las aplicaciones de kernel son Hola mismo tamaño.</span><span class="sxs-lookup"><span data-stu-id="80ac3-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are hello same size.</span></span>  

<span data-ttu-id="80ac3-227">Hola de soporte técnico de agrupaciones convolutional siguientes atributos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-227">Convolutional bundles support hello following attributes:</span></span>

<span data-ttu-id="80ac3-228">**InputShape** define la dimensionalidad de Hola de capa de origen de Hola para fines de Hola de este paquete convolutional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-228">**InputShape** defines hello dimensionality of hello source layer for hello purposes of this convolutional bundle.</span></span> <span data-ttu-id="80ac3-229">valor de Hello debe ser una tupla de números enteros positivos.</span><span class="sxs-lookup"><span data-stu-id="80ac3-229">hello value must be a tuple of positive integers.</span></span> <span data-ttu-id="80ac3-230">producto de Hola de enteros de hello debe ser igual a número Hola de nodos de nivel de origen de hello, pero en caso contrario, no es necesario dimensionalidad de hello toomatch declarado para el nivel del origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-230">hello product of hello integers must equal hello number of nodes in hello source layer, but otherwise, it does not need toomatch hello dimensionality declared for hello source layer.</span></span> <span data-ttu-id="80ac3-231">longitud de Hola de esta tupla se convierte en hello **aridad** valor para agrupación convolutional Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-231">hello length of this tuple becomes hello **arity** value for hello convolutional bundle.</span></span> <span data-ttu-id="80ac3-232">(Normalmente aridad hace referencia toohello número de argumentos o los operandos que puede llevar a cabo una función.)</span><span class="sxs-lookup"><span data-stu-id="80ac3-232">(Typically arity refers toohello number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="80ac3-233">forma de hello toodefine y ubicaciones de los kernels de hello, utilice atributos de hello **KernelShape**, **Stride**, **relleno**, **LowerPad**, y **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="80ac3-233">toodefine hello shape and locations of hello kernels, use hello attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="80ac3-234">**KernelShape**: dimensionalidad de hello define (obligatorio) de cada núcleo para agrupación convolutional Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-234">**KernelShape**: (required) Defines hello dimensionality of each kernel for hello convolutional bundle.</span></span> <span data-ttu-id="80ac3-235">valor de Hello debe ser una tupla de enteros positivos con una longitud igual a aridad Hola de agrupación de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-235">hello value must be a tuple of positive integers with a length that equals hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-236">Cada componente de este tupla debe ser no mayor que el componente correspondiente de Hola de **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-236">Each component of this tuple must be no greater than hello corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="80ac3-237">**STRIDE**: (opcional) Hola define deslizante tamaños de paso de circunvolución hello (tamaño de un paso para cada dimensión), que es la distancia de hello entre nodos central Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-237">**Stride**: (optional) Defines hello sliding step sizes of hello convolution (one step size for each dimension), that is hello distance between hello central nodes.</span></span> <span data-ttu-id="80ac3-238">valor de Hello debe ser una tupla de enteros positivos con una longitud de aridad Hola de agrupación de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-238">hello value must be a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-239">Cada componente de este tupla debe ser no mayor que el componente correspondiente de Hola de **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-239">Each component of this tuple must be no greater than hello corresponding component of **KernelShape**.</span></span> <span data-ttu-id="80ac3-240">valor predeterminado de Hello es una tupla con tooone igual de todos los componentes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-240">hello default value is a tuple with all components equal tooone.</span></span> 
* <span data-ttu-id="80ac3-241">**Uso compartido**: (opcional) peso de hello define para cada dimensión de circunvolución Hola de uso compartido.</span><span class="sxs-lookup"><span data-stu-id="80ac3-241">**Sharing**: (optional) Defines hello weight sharing for each dimension of hello convolution.</span></span> <span data-ttu-id="80ac3-242">Hola valor puede ser una tupla de valores booleanos con una longitud de aridad Hola de agrupación de Hola o de un solo valor booleano.</span><span class="sxs-lookup"><span data-stu-id="80ac3-242">hello value can be a single Boolean value or a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-243">Un solo valor booleano es extendido toobe una tupla de longitud correcta de Hola a todos los componentes toohello igual valor especificado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-243">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="80ac3-244">valor predeterminado de Hello es una tupla que consta de todos los valores True.</span><span class="sxs-lookup"><span data-stu-id="80ac3-244">hello default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="80ac3-245">**MapCount**: (opcional) número de hello define la desviación de la característica de mapas de agrupación convolutional Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-245">**MapCount**: (optional) Defines hello number of feature maps for hello convolutional bundle.</span></span> <span data-ttu-id="80ac3-246">Hola valor puede ser un número entero positivo o una tupla de enteros positivos con una longitud de aridad Hola de agrupación de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-246">hello value can be a single positive integer or a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-247">Un valor entero único se ha ampliado toobe una tupla de longitud correcta de hello con hello primera componentes igual toohello especifica el valor y todos Hola restantes tooone igual de componentes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-247">A single integer value is extended toobe a tuple of hello correct length with hello first components equal toohello specified value and all hello remaining components equal tooone.</span></span> <span data-ttu-id="80ac3-248">valor predeterminado de Hello es uno.</span><span class="sxs-lookup"><span data-stu-id="80ac3-248">hello default value is one.</span></span> <span data-ttu-id="80ac3-249">número total de Hola de asignaciones de función es producto Hola de componentes de Hola de tupla Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-249">hello total number of feature maps is hello product of hello components of hello tuple.</span></span> <span data-ttu-id="80ac3-250">Hola factorización de este número total en componentes de hello determina cómo se agrupan los valores de asignación de características de hello en nodos de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-250">hello factoring of this total number across hello components determines how hello feature map values are grouped in hello destination nodes.</span></span> 
* <span data-ttu-id="80ac3-251">**Pesos**: (opcional) define Hola inicial los pesos para agrupación Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-251">**Weights**: (optional) Defines hello initial weights for hello bundle.</span></span> <span data-ttu-id="80ac3-252">valor de Hello debe ser una tupla de los valores de punto con una longitud Hola número de núcleos veces Hola pesos por núcleo, tal como se define más adelante en este artículo flotante.</span><span class="sxs-lookup"><span data-stu-id="80ac3-252">hello value must be a tuple of floating point values with a length that is hello number of kernels times hello number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="80ac3-253">pesos de Hello predeterminado se generan de forma aleatoria.</span><span class="sxs-lookup"><span data-stu-id="80ac3-253">hello default weights are randomly generated.</span></span>  

<span data-ttu-id="80ac3-254">Hay dos conjuntos de propiedades que controlan el relleno, propiedades de hello son mutuamente excluyentes:</span><span class="sxs-lookup"><span data-stu-id="80ac3-254">There are two sets of properties that control padding, hello properties being mutually exclusive:</span></span>

* <span data-ttu-id="80ac3-255">**Relleno**: (opcional) determina si Hola de entrada se debe controlar mediante el uso de un **esquema de relleno predeterminado**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-255">**Padding**: (optional) Determines whether hello input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="80ac3-256">valor de Hello puede ser un solo valor booleano, o puede ser una tupla de valores booleanos con una longitud de aridad Hola de agrupación de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-256">hello value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-257">Un solo valor booleano es extendido toobe una tupla de longitud correcta de Hola a todos los componentes toohello igual valor especificado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-257">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="80ac3-258">Si el valor de Hola para una dimensión es True, origen Hola lógicamente se rellena en esa dimensión con aplicaciones de kernel adicional de toosupport celdas con valor cero, tal que Hola central nodos de kernels primeros y últimos de hello en esa dimensión son Hola primero y último en la dimensión en la capa de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-258">If hello value for a dimension is True, hello source is logically padded in that dimension with zero-valued cells toosupport additional kernel applications, such that hello central nodes of hello first and last kernels in that dimension are hello first and last nodes in that dimension in hello source layer.</span></span> <span data-ttu-id="80ac3-259">Por lo tanto, número de Hola de nodos "ficticios" en cada dimensión es determina automáticamente, toofit exactamente *(InputShape [d] - 1) / Stride [d] + 1* kernels en la capa de origen de hello rellenado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-259">Thus, hello number of "dummy" nodes in each dimension is determined automatically, toofit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into hello padded source layer.</span></span> <span data-ttu-id="80ac3-260">Si el valor de Hola para una dimensión es False, Hola kernels se definen para que sea el número de Hola de nodos en cada lado que se dejan fuera igual Hola (arriba tooa diferencia de 1).</span><span class="sxs-lookup"><span data-stu-id="80ac3-260">If hello value for a dimension is False, hello kernels are defined so that hello number of nodes on each side that are left out is hello same (up tooa difference of 1).</span></span> <span data-ttu-id="80ac3-261">valor predeterminado de Hola de este atributo es una tupla con tooFalse igual de todos los componentes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-261">hello default value of this attribute is a tuple with all components equal tooFalse.</span></span>
* <span data-ttu-id="80ac3-262">**UpperPad** y **LowerPad**: (opcional) proporcionar mayor control sobre la cantidad de Hola de toouse de relleno.</span><span class="sxs-lookup"><span data-stu-id="80ac3-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over hello amount of padding toouse.</span></span> <span data-ttu-id="80ac3-263">**Importante:** estos atributos se pueden definir si y solo si hello **relleno** propiedad anterior es ***no*** definido.</span><span class="sxs-lookup"><span data-stu-id="80ac3-263">**Important:** These attributes can be defined if and only if hello **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="80ac3-264">valores de Hello deberían tuplas con valor entero con longitudes de aridad Hola de agrupación de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-264">hello values should be integer-valued tuples with lengths that are hello arity of hello bundle.</span></span> <span data-ttu-id="80ac3-265">Cuando se especifican estos atributos, se agregan nodos "ficticios" toohello inferior y extremos superiores de cada dimensión del programa Hola a nivel de entrada.</span><span class="sxs-lookup"><span data-stu-id="80ac3-265">When these attributes are specified, "dummy" nodes are added toohello lower and upper ends of each dimension of hello input layer.</span></span> <span data-ttu-id="80ac3-266">número de nodos Hello agregado toohello inferior y superior termina en cada dimensión viene determinado por **LowerPad**[i] y **UpperPad**[i] respectivamente.</span><span class="sxs-lookup"><span data-stu-id="80ac3-266">hello number of nodes added toohello lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="80ac3-267">debe cumplirse tooensure que kernels corresponden nodos solo demasiado "reales" y no demasiado de "ficticio", hello condiciones siguientes:</span><span class="sxs-lookup"><span data-stu-id="80ac3-267">tooensure that kernels correspond only too"real" nodes and not too"dummy" nodes, hello following conditions must be met:</span></span>
  * <span data-ttu-id="80ac3-268">Cada componente de **LowerPad** debe ser estrictamente inferior a KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="80ac3-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="80ac3-269">Ningún componente de **UpperPad** puede ser superior a KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="80ac3-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="80ac3-270">valor predeterminado de Hola de estos atributos es una tupla con too0 igual de todos los componentes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-270">hello default value of these attributes is a tuple with all components equal too0.</span></span> 

<span data-ttu-id="80ac3-271">configuración de Hello **relleno** = true, se permiten como el relleno sea necesario tookeep Hola "center" del kernel de hello dentro de Hola "real" de entrada.</span><span class="sxs-lookup"><span data-stu-id="80ac3-271">hello setting **Padding** = true allows as much padding as is needed tookeep hello "center" of hello kernel inside hello "real" input.</span></span> <span data-ttu-id="80ac3-272">Esto cambia matemáticas Hola un poco para calcular el tamaño de la salida de hello.</span><span class="sxs-lookup"><span data-stu-id="80ac3-272">This changes hello math a bit for computing hello output size.</span></span> <span data-ttu-id="80ac3-273">Por lo general, el tamaño de la salida de hello *d.* se calcula como *d. = (I - K) / S + 1*, donde *I* tamaño de entrada de hello, *K* tamaño de kernel hello, *S* es stride hello, y  */*  es la división de enteros (redondear hacia cero).</span><span class="sxs-lookup"><span data-stu-id="80ac3-273">Generally, hello output size *D* is computed as *D = (I - K) / S + 1*, where *I* is hello input size, *K* is hello kernel size, *S* is hello stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="80ac3-274">Si establece UpperPad = [1, 1], tamaño de la entrada de hello *I* es efectivamente 29 y, por tanto, *d. = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-274">If you set UpperPad = [1, 1], hello input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="80ac3-275">Sin embargo, cuando **Padding** = true, esencialmente *I* aumenta en *K - 1*; por lo tanto, *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="80ac3-276">Al especificar valores para **UpperPad** y **LowerPad** obtener un mayor control sobre Hola relleno que if acabas de configurar **relleno** = true.</span><span class="sxs-lookup"><span data-stu-id="80ac3-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over hello padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="80ac3-277">Para obtener más información acerca de las redes convolucionales y sus aplicaciones, consulte estos artículos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="80ac3-278">http://deeplearning.net/tutorial/lenet.html </span><span class="sxs-lookup"><span data-stu-id="80ac3-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="80ac3-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span><span class="sxs-lookup"><span data-stu-id="80ac3-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="80ac3-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span><span class="sxs-lookup"><span data-stu-id="80ac3-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="80ac3-281">Conjuntos de agrupación</span><span class="sxs-lookup"><span data-stu-id="80ac3-281">Pooling bundles</span></span>
<span data-ttu-id="80ac3-282">A **agrupación agrupación** aplica conectividad tooconvolutional similar de geometría, pero usa funciones predefinidas toosource nodo valores tooderive Hola nodo valor de destino.</span><span class="sxs-lookup"><span data-stu-id="80ac3-282">A **pooling bundle** applies geometry similar tooconvolutional connectivity, but it uses predefined functions toosource node values tooderive hello destination node value.</span></span> <span data-ttu-id="80ac3-283">Por tanto, los conjuntos de agrupación no tienen estado entrenable (ponderaciones o sesgos).</span><span class="sxs-lookup"><span data-stu-id="80ac3-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="80ac3-284">Agrupación de soporte técnico de agrupaciones Hola a todos los atributos convolutional excepto **compartir**, **MapCount**, y **pesos**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-284">Pooling bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="80ac3-285">Por lo general, no se superponen los kernels de hello resumidos por unidades de agrupación adyacentes.</span><span class="sxs-lookup"><span data-stu-id="80ac3-285">Typically, hello kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="80ac3-286">Si Stride [d] es igual tooKernelShape [d] en cada dimensión, nivel de hello obtenido es Hola tradicional local agrupación capa, que normalmente se emplea en redes neurales convolutional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-286">If Stride[d] is equal tooKernelShape[d] in each dimension, hello layer obtained is hello traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="80ac3-287">Cada nodo de destino calcula Hola máximo o promedio de Hola de actividades de Hola de su kernel en la capa de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-287">Each destination node computes hello maximum or hello mean of hello activities of its kernel in hello source layer.</span></span>  

<span data-ttu-id="80ac3-288">Hola de ejemplo siguiente muestra un paquete de agrupación:</span><span class="sxs-lookup"><span data-stu-id="80ac3-288">hello following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="80ac3-289">Hola aridad de agrupación de hello es 3 (Hola longitud de tuplas de hello **InputShape**, **KernelShape**, y **Stride**).</span><span class="sxs-lookup"><span data-stu-id="80ac3-289">hello arity of hello bundle is 3 (hello length of hello tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="80ac3-290">Hola número de nodos de nivel de origen de hello es *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-290">hello number of nodes in hello source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="80ac3-291">Esto es un nivel de agrupación local tradicional porque **KernelShape** y **Stride** son iguales.</span><span class="sxs-lookup"><span data-stu-id="80ac3-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="80ac3-292">Hola número de nodos de nivel de destino de hello es *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-292">hello number of nodes in hello destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="80ac3-293">Para obtener más información acerca de las capas de agrupación, consulte estos artículos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="80ac3-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Sección 3.4)</span><span class="sxs-lookup"><span data-stu-id="80ac3-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="80ac3-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span><span class="sxs-lookup"><span data-stu-id="80ac3-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="80ac3-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span><span class="sxs-lookup"><span data-stu-id="80ac3-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="80ac3-297">Conjuntos de normalización de respuesta</span><span class="sxs-lookup"><span data-stu-id="80ac3-297">Response normalization bundles</span></span>
<span data-ttu-id="80ac3-298">**Normalización de respuesta** es un esquema de normalización local que apareció por primera vez por Geoffrey Hinton, et al., en papel de hello [ImageNet Classiﬁcation con profundidad redes neurales Convolutional](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="80ac3-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in hello paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="80ac3-299">Normalización de respuesta es generalización tooaid usado en las redes neurales.</span><span class="sxs-lookup"><span data-stu-id="80ac3-299">Response normalization is used tooaid generalization in neural nets.</span></span> <span data-ttu-id="80ac3-300">Cuando se genera una neurona en un nivel muy alto de activación, una capa de normalización de respuesta local suprime el nivel de activación de Hola de Hola que rodean las neuronas.</span><span class="sxs-lookup"><span data-stu-id="80ac3-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses hello activation level of hello surrounding neurons.</span></span> <span data-ttu-id="80ac3-301">Esto se realiza mediante tres parámetros (***α***, ***β*** y ***k***) y una estructura convolutional (o forma de entorno).</span><span class="sxs-lookup"><span data-stu-id="80ac3-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="80ac3-302">Cada neurona de capa de destino de hello ***y*** corresponde tooa neurona ***x*** en la capa de origen de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-302">Every neuron in hello destination layer ***y*** corresponds tooa neuron ***x*** in hello source layer.</span></span> <span data-ttu-id="80ac3-303">Hola a nivel de activación de ***y*** viene dado por hello después de la fórmula, donde ***f*** es Hola de nivel de activación de una neurona y ***Nx*** es kernel hello (o conjunto de Hola que contiene Hola neuronas en el entorno de Hola de ***x***), tal como se define por hello siguiendo convolutional estructura:</span><span class="sxs-lookup"><span data-stu-id="80ac3-303">hello activation level of ***y*** is given by hello following formula, where ***f*** is hello activation level of a neuron, and ***Nx*** is hello kernel (or hello set that contains hello neurons in hello neighborhood of ***x***), as defined by hello following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="80ac3-304">Agrupaciones de normalización de respuesta compatible con todos los atributos de hello convolutional excepto **compartir**, **MapCount**, y **pesos**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-304">Response normalization bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="80ac3-305">Si kernel hello contiene neuronas de hello mismo asignar como ***x***, esquema de normalización de hello es que se hace referencia tooas **mismo mapa normalización**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-305">If hello kernel contains neurons in hello same map as ***x***, hello normalization scheme is referred tooas **same map normalization**.</span></span> <span data-ttu-id="80ac3-306">toodefine mismo mapa normalización, primera coordenada de hello en **InputShape** debe tener el valor de hello 1.</span><span class="sxs-lookup"><span data-stu-id="80ac3-306">toodefine same map normalization, hello first coordinate in **InputShape** must have hello value 1.</span></span>
* <span data-ttu-id="80ac3-307">Si el núcleo de hello contiene neuronas de Hola misma posición espacial que ***x***, pero neuronas Hola están en otros mapas, se denomina esquema de normalización de hello **asigna a través de normalización**.</span><span class="sxs-lookup"><span data-stu-id="80ac3-307">If hello kernel contains neurons in hello same spatial position as ***x***, but hello neurons are in other maps, hello normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="80ac3-308">Este tipo de normalización de respuesta implementa un formulario de inhibición lateral inspirado en hello encontró un tipo de neuronas reales, crear la competición por los niveles de activación grande entre salidas neurona calculadas en diferentes asignaciones.</span><span class="sxs-lookup"><span data-stu-id="80ac3-308">This type of response normalization implements a form of lateral inhibition inspired by hello type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="80ac3-309">toodefine a través de normalización asigna, primera coordenada de hello debe ser un entero mayor que uno y no mayor que el número de Hola de mapas y, rest Hola de coordenadas de hello debe tener el valor de hello 1.</span><span class="sxs-lookup"><span data-stu-id="80ac3-309">toodefine across maps normalization, hello first coordinate must be an integer greater than one and no greater than hello number of maps, and hello rest of hello coordinates must have hello value 1.</span></span>  

<span data-ttu-id="80ac3-310">Dado que los paquetes de normalización de respuesta aplican un valor de nodo función predefinida toosource nodo valores toodetermine Hola destino, no tienen ningún estado trainable (pesos o inclinaciones).</span><span class="sxs-lookup"><span data-stu-id="80ac3-310">Because response normalization bundles apply a predefined function toosource node values toodetermine hello destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="80ac3-311">**Alerta**: nodos de hello en la capa de destino de hello corresponden tooneurons que son nodos central Hola kernels Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-311">**Alert**: hello nodes in hello destination layer correspond tooneurons that are hello central nodes of hello kernels.</span></span> <span data-ttu-id="80ac3-312">Por ejemplo, si KernelShape [d] es impar, a continuación, *KernelShape [d] / 2* corresponde toohello nodo de kernel central.</span><span class="sxs-lookup"><span data-stu-id="80ac3-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds toohello central kernel node.</span></span> <span data-ttu-id="80ac3-313">Si *KernelShape [d]* es par, es el nodo central hello en *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-313">If *KernelShape[d]* is even, hello central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="80ac3-314">Por lo tanto, si **relleno**[d] es False, Hola primero y último Hola *KernelShape [d] / 2* nodos no tienen nodos correspondientes en la capa de destino de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-314">Therefore, if **Padding**[d] is False, hello first and hello last *KernelShape[d]/2* nodes do not have corresponding nodes in hello destination layer.</span></span> <span data-ttu-id="80ac3-315">tooavoid esta situación, definir **relleno** como [es true, true,..., true].</span><span class="sxs-lookup"><span data-stu-id="80ac3-315">tooavoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="80ac3-316">Además toohello cuatro atributos describen anteriormente, agrupaciones de normalización de respuesta también Hola de compatibilidad siguientes atributos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-316">In addition toohello four attributes described earlier, response normalization bundles also support hello following attributes:</span></span>  

* <span data-ttu-id="80ac3-317">**Alfa**: (obligatorio) especifica un valor de punto flotante que corresponde demasiado***α*** en la fórmula anterior Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-317">**Alpha**: (required) Specifies a floating-point value that corresponds too***α*** in hello previous formula.</span></span> 
* <span data-ttu-id="80ac3-318">**Beta**: (obligatorio) especifica un valor de punto flotante que corresponde demasiado***β*** en la fórmula anterior Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-318">**Beta**: (required) Specifies a floating-point value that corresponds too***β*** in hello previous formula.</span></span> 
* <span data-ttu-id="80ac3-319">**Desplazamiento**: (opcional) especifica un valor de punto flotante que corresponde demasiado***k*** en la fórmula anterior Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-319">**Offset**: (optional) Specifies a floating-point value that corresponds too***k*** in hello previous formula.</span></span> <span data-ttu-id="80ac3-320">El valor predeterminado es too1.</span><span class="sxs-lookup"><span data-stu-id="80ac3-320">It defaults too1.</span></span>  

<span data-ttu-id="80ac3-321">Hello en el ejemplo siguiente se define una agrupación de normalización de respuesta con estos atributos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-321">hello following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="80ac3-322">capa de origen de Hello incluye cinco asignaciones, cada uno con la dimensión de aof de 12 x 12, calcular los totales en nodos de 1440.</span><span class="sxs-lookup"><span data-stu-id="80ac3-322">hello source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="80ac3-323">Hola valo **KernelShape** indica que se trata de una misma capa de normalización de mapa, donde el entorno de hello es un rectángulo de 3 x 3.</span><span class="sxs-lookup"><span data-stu-id="80ac3-323">hello value of **KernelShape** indicates that this is a same map normalization layer, where hello neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="80ac3-324">Hola valor predeterminado de **relleno** es False, lo que capa de destino de hello tiene solo 10 nodos en cada dimensión.</span><span class="sxs-lookup"><span data-stu-id="80ac3-324">hello default value of **Padding** is False, thus hello destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="80ac3-325">tooinclude un nodo de capa de destino de hello correspondiente nodo tooevery en la capa de origen de hello, agregar relleno = [true, true, true]; y cambiar el tamaño de Hola de RN1 demasiado [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="80ac3-325">tooinclude one node in hello destination layer that corresponds tooevery node in hello source layer, add Padding = [true, true, true]; and change hello size of RN1 too[5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="80ac3-326">Declaración de uso compartido</span><span class="sxs-lookup"><span data-stu-id="80ac3-326">Share declaration</span></span>
<span data-ttu-id="80ac3-327">Net# admite opcionalmente la definición de varios conjuntos con ponderaciones compartidas.</span><span class="sxs-lookup"><span data-stu-id="80ac3-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="80ac3-328">pesos de Hola de los dos paquetes pueden compartirse Si sus estructuras son Hola igual.</span><span class="sxs-lookup"><span data-stu-id="80ac3-328">hello weights of any two bundles can be shared if their structures are hello same.</span></span> <span data-ttu-id="80ac3-329">Hola sintaxis define agrupaciones con pesos compartidos:</span><span class="sxs-lookup"><span data-stu-id="80ac3-329">hello following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="80ac3-330">Por ejemplo, hello siguiente declaración de recurso compartido especifica nombres de las capas hello, que indica que se deben compartir pesos e inclinaciones:</span><span class="sxs-lookup"><span data-stu-id="80ac3-330">For example, hello following share-declaration specifies hello layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="80ac3-331">características de entrada de Hola se dividen en dos niveles de entrada con tamaño iguales.</span><span class="sxs-lookup"><span data-stu-id="80ac3-331">hello input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="80ac3-332">capas de Hello ocultado, a continuación, calculan las características de nivel superior en dos niveles de entrada Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-332">hello hidden layers then compute higher level features on hello two input layers.</span></span> 
* <span data-ttu-id="80ac3-333">declaración de recurso compartido de Hello especifica que *H1* y *H2* debe calcularse en hello igual de sus respectivas entradas.</span><span class="sxs-lookup"><span data-stu-id="80ac3-333">hello share-declaration specifies that *H1* and *H2* must be computed in hello same way from their respective inputs.</span></span>  

<span data-ttu-id="80ac3-334">Es posible también especificarlo con dos declaraciones de uso compartido independientes, del modo siguiente:</span><span class="sxs-lookup"><span data-stu-id="80ac3-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="80ac3-335">Puede usar la forma abreviada de hello cuando las capas de hello contienen un único lote.</span><span class="sxs-lookup"><span data-stu-id="80ac3-335">You can use hello short form only when hello layers contain a single bundle.</span></span> <span data-ttu-id="80ac3-336">En general, es posible compartir sólo cuando la estructura relevante hello es idéntica, lo que significa que tienen Hola mismo tamaño, misma geometría convolutional y así sucesivamente.</span><span class="sxs-lookup"><span data-stu-id="80ac3-336">In general, sharing is possible only when hello relevant structure is identical, meaning that they have hello same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="80ac3-337">Ejemplos de uso de Net#</span><span class="sxs-lookup"><span data-stu-id="80ac3-337">Examples of Net# usage</span></span>
<span data-ttu-id="80ac3-338">En esta sección se proporciona algunos ejemplos de cómo puede usar Net # capas tooadd oculta, definir la manera en que Hola que interactúan con otras capas niveles ocultos y crear redes convolutional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-338">This section provides some examples of how you can use Net# tooadd hidden layers, define hello way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="80ac3-339">Definición de una red neuronal sencilla personalizada: ejemplo "Hello World"</span><span class="sxs-lookup"><span data-stu-id="80ac3-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="80ac3-340">Este ejemplo demuestra cómo toocreate un neural network modelo que tiene una sola capa oculta.</span><span class="sxs-lookup"><span data-stu-id="80ac3-340">This simple example demonstrates how toocreate a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="80ac3-341">ejemplo de Hola muestra algunos comandos básicos como sigue:</span><span class="sxs-lookup"><span data-stu-id="80ac3-341">hello example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="80ac3-342">primera línea Hello define nivel de entrada de hello (denominado *datos*).</span><span class="sxs-lookup"><span data-stu-id="80ac3-342">hello first line defines hello input layer (named *Data*).</span></span> <span data-ttu-id="80ac3-343">Cuando usas hello **automática** palabra clave, Red neuronal de hello incluye automáticamente todas las columnas de característica en los ejemplos de entrada de Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-343">When you use hello  **auto** keyword, hello neural network automatically includes all feature columns in hello input examples.</span></span> 
* <span data-ttu-id="80ac3-344">Hola segunda línea crea capa oculta Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-344">hello second line creates hello hidden layer.</span></span> <span data-ttu-id="80ac3-345">nombre de Hello *H* se asigna el nivel oculto toohello, que tiene 200 nodos.</span><span class="sxs-lookup"><span data-stu-id="80ac3-345">hello name *H* is assigned toohello hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="80ac3-346">Este nivel es el nivel de entrada de toohello conectados de forma continua.</span><span class="sxs-lookup"><span data-stu-id="80ac3-346">This layer is fully connected toohello input layer.</span></span>
* <span data-ttu-id="80ac3-347">tercera línea de Hello define el nivel de salida de hello (denominado *O*), que contiene 10 nodos de salida.</span><span class="sxs-lookup"><span data-stu-id="80ac3-347">hello third line defines hello output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="80ac3-348">Si se usa la red neuronal de hello para la clasificación, hay un nodo de salida por clase.</span><span class="sxs-lookup"><span data-stu-id="80ac3-348">If hello neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="80ac3-349">Hola palabra clave **sigmoidea** indica que la función de salida de hello es nivel de salida de toohello aplicado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-349">hello keyword **sigmoid** indicates that hello output function is applied toohello output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="80ac3-350">Definición de varias capas ocultas: ejemplo de visión de equipo</span><span class="sxs-lookup"><span data-stu-id="80ac3-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="80ac3-351">Hello ejemplo siguiente se muestra cómo toodefine una red neuronal ligeramente más compleja, con varios niveles ocultos personalizados.</span><span class="sxs-lookup"><span data-stu-id="80ac3-351">hello following example demonstrates how toodefine a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define hello input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define hello first two hidden layers, using data only from hello Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define hello third hidden layer, which uses as source hello hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define hello output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="80ac3-352">En este ejemplo se muestra varias características del lenguaje de especificación de redes neurales hello:</span><span class="sxs-lookup"><span data-stu-id="80ac3-352">This example illustrates several features of hello neural networks specification language:</span></span>  

* <span data-ttu-id="80ac3-353">estructura de Hello tiene dos niveles de entrada, *píxeles* y *metadatos*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-353">hello structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="80ac3-354">Hola *píxeles* capa es una capa de origen para dos paquetes de conexión, con capas de destino, *ByRow* y *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-354">hello *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="80ac3-355">Hola capas *recopilar* y *resultado* son capas de destino en varios paquetes de conexión.</span><span class="sxs-lookup"><span data-stu-id="80ac3-355">hello layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="80ac3-356">nivel de salida de Hello, *resultado*, es una capa de destino en dos agrupaciones de conexión, uno con hello de segundo nivel oculto (recopilación) como una capa de destino y otro con el nivel de entrada de Hola (MetaData) Hola como una capa de destino.</span><span class="sxs-lookup"><span data-stu-id="80ac3-356">hello output layer, *Result*, is a destination layer in two connection bundles; one with hello second level hidden (Gather) as a destination layer, and hello other with hello input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="80ac3-357">Hola niveles ocultos, *ByRow* y *ByCol*, especificar la conectividad filtrado mediante expresiones de predicado.</span><span class="sxs-lookup"><span data-stu-id="80ac3-357">hello hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="80ac3-358">Más concretamente, el nodo de hello en *ByRow* en [x, y] está conectado toohello nodos *píxeles* que tienen x de coordenadas, primer Hola índice toohello igual coordenadas del primer nodo.</span><span class="sxs-lookup"><span data-stu-id="80ac3-358">More precisely, hello node in *ByRow* at [x, y] is connected toohello nodes in *Pixels* that have hello first index coordinate equal toohello node's first coordinate, x.</span></span> <span data-ttu-id="80ac3-359">De forma similar, el nodo de hello en *ByCol en [x, y] es nodos conectados toohello _Pixels* que tienen coordenadas de hello segundo índice dentro de una segunda coordenada del nodo de hello, y.</span><span class="sxs-lookup"><span data-stu-id="80ac3-359">Similarly, hello node in *ByCol at [x, y] is connected toohello nodes in _Pixels* that have hello second index coordinate within one of hello node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="80ac3-360">Defina una red de circunvolución para la clasificación multiclass: ejemplo de reconocimiento de dígitos</span><span class="sxs-lookup"><span data-stu-id="80ac3-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="80ac3-361">definición de Hola de hello después de la red es números toorecognize diseñada e ilustra algunas técnicas avanzadas para personalizar una red neuronal.</span><span class="sxs-lookup"><span data-stu-id="80ac3-361">hello definition of hello following network is designed toorecognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="80ac3-362">estructura de Hello tiene un único nivel de entrada, *imagen*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-362">hello structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="80ac3-363">Hola palabra clave **convolve** indica que las capas de hello denominen *Conv1* y *Conv2* son capas convolutional.</span><span class="sxs-lookup"><span data-stu-id="80ac3-363">hello keyword **convolve** indicates that hello layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="80ac3-364">Cada una de estas declaraciones capa va seguida de una lista de atributos de circunvolución Hola.</span><span class="sxs-lookup"><span data-stu-id="80ac3-364">Each of these layer declarations is followed by a list of hello convolution attributes.</span></span>
* <span data-ttu-id="80ac3-365">Hola net tiene una tercera ocultas capa, *Hid3*, que está completamente conectado toohello segunda capa oculta, *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-365">hello net has a third hidden layer, *Hid3*, which is fully connected toohello second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="80ac3-366">nivel de salida de Hello, *dígitos*, está conectado toohello solo tercera capa oculta, *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-366">hello output layer, *Digit*, is connected only toohello third hidden layer, *Hid3*.</span></span> <span data-ttu-id="80ac3-367">Hola palabra clave **todos los** indica dicho nivel de salida de hello esté conectada totalmente demasiado*Hid3*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-367">hello keyword **all** indicates that hello output layer is fully connected too*Hid3*.</span></span>
* <span data-ttu-id="80ac3-368">Hello aridad de circunvolución hello es tres (Hola longitud de tuplas de hello **InputShape**, **KernelShape**, **Stride**, y **compartir**).</span><span class="sxs-lookup"><span data-stu-id="80ac3-368">hello arity of hello convolution is three (hello length of hello tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="80ac3-369">número de Hola de pesos por núcleo es *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[2] = 1 + 1 * 5 * 5 = 26. o bien 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-369">hello number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="80ac3-370">Puede calcular nodos hello en cada capa oculta como sigue:</span><span class="sxs-lookup"><span data-stu-id="80ac3-370">You can calculate hello nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="80ac3-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="80ac3-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="80ac3-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="80ac3-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="80ac3-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="80ac3-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="80ac3-374">Hello número total de nodos puede calcularse mediante el uso de hello declarado dimensionalidad de hello las capas, [50, 5, 5], como se indica a continuación:  ***MapCount** * **NodeCount** \[ 0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="80ac3-374">hello total number of nodes can be calculated by using hello declared dimensionality of hello layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="80ac3-375">Porque **compartir**[d] es False solo para *d. == 0*, número de Hola de kernels es  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="80ac3-375">Because **Sharing**[d] is False only for *d == 0*, hello number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="80ac3-376">Agradecimientos</span><span class="sxs-lookup"><span data-stu-id="80ac3-376">Acknowledgements</span></span>
<span data-ttu-id="80ac3-377">Hola lenguaje Net # para personalizar la arquitectura de Hola de las redes neurales fue desarrollado en Microsoft por Shon Katzenberger (arquitecto, aprendizaje automático) y Alexey Kamenev (ingeniero de Software, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="80ac3-377">hello Net# language for customizing hello architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="80ac3-378">Se usa internamente para proyectos y aplicaciones que abarcan desde el análisis de tootext de detección de imagen de aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="80ac3-378">It is used internally for machine learning projects and applications ranging from image detection tootext analytics.</span></span> <span data-ttu-id="80ac3-379">Para obtener más información, vea [redes neurales en Azure ML - Introducción tooNet #](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="80ac3-379">For more information, see [Neural Nets in Azure ML - Introduction tooNet#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif

