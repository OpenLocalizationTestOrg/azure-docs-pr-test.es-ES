---
title: "selección de aaaFeature Hola proceso de ciencia de datos de equipo | Documentos de Microsoft"
description: "Explica el propósito de Hola de selección de características y proporciona ejemplos de su función en el proceso de mejora de hello datos de aprendizaje automático."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="527e3-103">Selección de características en hello proceso de ciencia de datos de equipo (TDSP)</span><span class="sxs-lookup"><span data-stu-id="527e3-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="527e3-104">En este artículo se explica con fines de Hola de selección de características y proporciona ejemplos de su función en el proceso de mejora de hello datos de aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="527e3-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="527e3-105">Estos ejemplos se extraen de Estudio de aprendizaje automático de Azure.</span><span class="sxs-lookup"><span data-stu-id="527e3-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="527e3-106">Hola de ingeniería y selección de características es una parte del programa Hola a ciencia de datos de equipo proceso (TDSP) que se describen en [¿qué es hello proceso de ciencia de datos de equipo?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="527e3-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="527e3-107">Característica ingeniería y selección son partes de hello **desarrollar características** paso de hello TDSP.</span><span class="sxs-lookup"><span data-stu-id="527e3-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="527e3-108">**característica ingeniería**: características adicionales de relevante toocreate características sin formato existente de hello en datos de Hola y algoritmo de aprendizaje de toohello tooincrease predictiva de intentos de este proceso.</span><span class="sxs-lookup"><span data-stu-id="527e3-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="527e3-109">**selección de características**: este proceso selecciona subconjunto de clave de Hola de características de datos original en una dimensionalidad de hello tooreduce intento de problema de entrenamiento de Hola.</span><span class="sxs-lookup"><span data-stu-id="527e3-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="527e3-110">Normalmente **característica ingeniería** es aplicado primeras características adicionales de toogenerate y, a continuación, hello **selección de características** paso es realizar tooeliminate altamente correlacionada, redundante o irrelevante características.</span><span class="sxs-lookup"><span data-stu-id="527e3-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="527e3-111">Filtrado de características desde sus datos: selección de características</span><span class="sxs-lookup"><span data-stu-id="527e3-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="527e3-112">Selección de características es un proceso que se suele aplicar para la construcción de Hola de conjuntos de datos de entrenamiento para tareas de modelado de predicción, como tareas de clasificación o regresión.</span><span class="sxs-lookup"><span data-stu-id="527e3-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="527e3-113">objetivo de Hello es un subconjunto de características de Hola de conjunto de datos original de Hola que reducen sus dimensiones mediante el uso de un conjunto mínimo de cantidad máxima Hola de características toorepresent de varianza en los datos de hello tooselect.</span><span class="sxs-lookup"><span data-stu-id="527e3-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="527e3-114">Este subconjunto de características son, a continuación, Hola solo características toobe incluye el modelo de hello tootrain.</span><span class="sxs-lookup"><span data-stu-id="527e3-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="527e3-115">La selección de características tiene dos propósitos principales.</span><span class="sxs-lookup"><span data-stu-id="527e3-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="527e3-116">En primer lugar, la selección de características a menudo aumenta la precisión de la clasificación a través de la eliminación de características irrelevantes, redundantes o altamente correlacionadas.</span><span class="sxs-lookup"><span data-stu-id="527e3-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="527e3-117">En segundo lugar, se reduce el número de Hola de características que hace que el proceso de entrenamiento del modelo sea más eficaces.</span><span class="sxs-lookup"><span data-stu-id="527e3-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="527e3-118">Esto es especialmente importante para aprendices que son costosa tootrain como las máquinas de vectores de soporte técnico.</span><span class="sxs-lookup"><span data-stu-id="527e3-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="527e3-119">Aunque la selección de características de búsqueda número de hello tooreduce de funciones hello conjunto de datos usado tootrain Hola modelo, no es normalmente lo que se conoce tooby Hola término "reducción de dimensionalidad".</span><span class="sxs-lookup"><span data-stu-id="527e3-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="527e3-120">Métodos de selección de características extraen un subconjunto de características originales de los datos de hello sin modificarlas.</span><span class="sxs-lookup"><span data-stu-id="527e3-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="527e3-121">Métodos de reducción de dimensionalidad utilizan funciones de ingeniería que se pueden transformar características original de hello y, por tanto, modificarlos.</span><span class="sxs-lookup"><span data-stu-id="527e3-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="527e3-122">Algunos ejemplos de los métodos de reducción de dimensionalidad incluyen el análisis del componente principal, el análisis de correlación canónica y la descomposición en valores singulares.</span><span class="sxs-lookup"><span data-stu-id="527e3-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="527e3-123">Entre otros aspectos, una categoría ampliamente aplicada de los métodos de selección de categorías en un contexto supervisado se llama "selección de características basada en filtro".</span><span class="sxs-lookup"><span data-stu-id="527e3-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="527e3-124">Mediante la evaluación de correlación de hello entre cada atributo de destino hello y características, estos métodos aplican un tooassign medida estadística una característica de tooeach de puntuación.</span><span class="sxs-lookup"><span data-stu-id="527e3-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="527e3-125">características de Hello, a continuación, se clasifican por puntuación de hello, que puede ser el umbral de hello establecido toohelp usado para mantener o eliminar una característica específica.</span><span class="sxs-lookup"><span data-stu-id="527e3-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="527e3-126">Algunos ejemplos de medidas estadísticas Hola utilizados en estos métodos son correlación persona, la información mutua y prueba de hello Chi cuadrado.</span><span class="sxs-lookup"><span data-stu-id="527e3-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="527e3-127">En Estudio de aprendizaje automático de Azure, estos son los módulos proporcionados para la selección de características.</span><span class="sxs-lookup"><span data-stu-id="527e3-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="527e3-128">Como se muestra en la figura siguiente de Hola, estos módulos incluyen [selección de características basada en filtros] [ filter-based-feature-selection] y [análisis discriminante lineal de Fisher] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="527e3-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Ejemplo de selección de características](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="527e3-130">Considere, por ejemplo, uso de Hola de hello [selección de características basada en filtros] [ filter-based-feature-selection] módulo.</span><span class="sxs-lookup"><span data-stu-id="527e3-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="527e3-131">A fin de Hola de comodidad, seguimos ejemplo de minería de datos de texto toouse Hola descrita anteriormente.</span><span class="sxs-lookup"><span data-stu-id="527e3-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="527e3-132">Supongamos que queremos toobuild un modelo de regresión después de un conjunto de 256 características creadas a través de hello [hash de características] [ feature-hashing] módulo y esa variable de respuesta de hello es "Col1" hello y representa un libro Revise las clasificaciones que van desde 1 too5.</span><span class="sxs-lookup"><span data-stu-id="527e3-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="527e3-133">Estableciendo "Método de puntuación de la característica" toobe "Correlación de Pearson" Hola "Columna de destino" toobe "Col1" y Hola "Número de características deseadas" too50.</span><span class="sxs-lookup"><span data-stu-id="527e3-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="527e3-134">A continuación, el módulo de hello [selección de características basada en filtros] [ filter-based-feature-selection] generará un conjunto de datos que contiene 50 características junto con el atributo de destino de Hola "Col1".</span><span class="sxs-lookup"><span data-stu-id="527e3-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="527e3-135">Hola a continuación figura muestra hello flujo de este experimento y Hola parámetros de entrada que acabamos de describir.</span><span class="sxs-lookup"><span data-stu-id="527e3-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Ejemplo de selección de características](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="527e3-137">Hello en la ilustración siguiente se muestra hello conjuntos de datos resultante.</span><span class="sxs-lookup"><span data-stu-id="527e3-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="527e3-138">Cada característica es una puntuación basada en hello correlación de Pearson entre sí y Hola "Col1" del atributo de destino.</span><span class="sxs-lookup"><span data-stu-id="527e3-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="527e3-139">características de Hello con puntuaciones más altas se mantienen.</span><span class="sxs-lookup"><span data-stu-id="527e3-139">hello features with top scores are kept.</span></span>

![Ejemplo de selección de características](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="527e3-141">puntuaciones correspondiente Hola de características de hello seleccionado se muestran en hello figura siguiente.</span><span class="sxs-lookup"><span data-stu-id="527e3-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Ejemplo de selección de características](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="527e3-143">Aplicando esto [selección de características basada en filtros] [ filter-based-feature-selection] módulo, 50 fuera de 256 características están seleccionadas porque han Hola más características correlacionadas con variable de destino de Hola "Col1", en función de la puntuación de Hola método "Correlación de Pearson".</span><span class="sxs-lookup"><span data-stu-id="527e3-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="527e3-144">Conclusión</span><span class="sxs-lookup"><span data-stu-id="527e3-144">Conclusion</span></span>
<span data-ttu-id="527e3-145">Ingeniería de característica y selección de características son dos habitualmente de ingeniería y características seleccionadas aumentan la eficacia de Hola de hello entrenamiento proceso que intenta tooextract Hola clave la información contenida en los datos de Hola.</span><span class="sxs-lookup"><span data-stu-id="527e3-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="527e3-146">También mejoran la potencia de Hola de estos datos de entrada de modelos tooclassify Hola con precisión y resultados de toopredict de interesan más Fortalezca de forma.</span><span class="sxs-lookup"><span data-stu-id="527e3-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="527e3-147">Característica ingeniería y la selección también pueden combinar aprendizaje de hello toomake manejable más procesamiento.</span><span class="sxs-lookup"><span data-stu-id="527e3-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="527e3-148">Para ello, mejorar y, a continuación, lo que reduce número Hola de características necesario toocalibrate o entrenar un modelo.</span><span class="sxs-lookup"><span data-stu-id="527e3-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="527e3-149">Matemáticamente hablando, modelo de Hola de hello características tootrain seleccionados son un conjunto mínimo de variables independientes que expliquen los patrones de hello en los datos de hello y, a continuación, predecir correctamente los resultados.</span><span class="sxs-lookup"><span data-stu-id="527e3-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="527e3-150">Tenga en cuenta que no siempre es necesariamente tooperform selección de ingeniería o una característica de característica.</span><span class="sxs-lookup"><span data-stu-id="527e3-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="527e3-151">Si es necesario o no depende de datos de hello disponemos o recopilar, hemos elegido, el algoritmo de Hola y Hola objetivo del experimento de Hola.</span><span class="sxs-lookup"><span data-stu-id="527e3-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

