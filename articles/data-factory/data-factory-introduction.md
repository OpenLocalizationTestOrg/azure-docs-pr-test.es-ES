---
title: "Introducción a Data Factory, un servicio de integración de datos | Microsoft Docs"
description: "Sepa lo que es Azure Data Factory: un servicio de integración de datos basado en la nube que organiza y automatiza el movimiento y la transformación de datos."
keywords: "integración de datos, integración de datos de nube, qué es azure data factory"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="28551-104">Introducción a la Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="28551-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="28551-105">¿Qué es Azure Data Factory?</span><span class="sxs-lookup"><span data-stu-id="28551-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="28551-106">En el mundo de los macrodatos, ¿cómo aprovechan las empresas los datos existentes?</span><span class="sxs-lookup"><span data-stu-id="28551-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="28551-107">¿Es posible enriquecer los datos generados en la nube mediante el uso de datos de referencia de orígenes de datos locales u otros orígenes de datos dispares?</span><span class="sxs-lookup"><span data-stu-id="28551-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="28551-108">Por ejemplo, una empresa de juegos recopila muchos registros generados por juegos en la nube.</span><span class="sxs-lookup"><span data-stu-id="28551-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="28551-109">Quieren analizar estos registros para obtener información sobre las preferencias de los clientes, la demografía, el comportamiento de uso, etc. a fin de identificar oportunidades de venta cruzada e incremento de ventas, desarrollar nuevas y atractivas características para impulsar el crecimiento del negocio y proporcionar una experiencia mejor a los clientes.</span><span class="sxs-lookup"><span data-stu-id="28551-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="28551-110">Para analizar estos registros, la empresa debe usar los datos de referencia, como información de clientes, información de juegos o información de campañas de marketing, que se encuentran en un almacén de datos local.</span><span class="sxs-lookup"><span data-stu-id="28551-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="28551-111">Por lo tanto, desean ingerir datos de registro del almacén de datos en la nube y datos de referencia del almacén de datos local.</span><span class="sxs-lookup"><span data-stu-id="28551-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="28551-112">A continuación, procesarán los datos mediante Hadoop en la nube (Azure HDInsight) y publicarán los datos de resultados en un almacén de datos en la nube, como Azure SQL Data Warehouse, o en un almacén de datos local, como SQL Server.</span><span class="sxs-lookup"><span data-stu-id="28551-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="28551-113">Quieren que este flujo de trabajo se ejecute una vez a la semana.</span><span class="sxs-lookup"><span data-stu-id="28551-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="28551-114">Lo que se necesita es una plataforma que permita a la empresa crear un flujo de trabajo que pueda ingerir datos de ambos almacenes, local y en la nube, transformar o procesar los datos mediante servicios de proceso existentes, como Hadoop, y publicar los resultados en un almacén de datos local o en la nube para su consumo por parte de las aplicaciones BI.</span><span class="sxs-lookup"><span data-stu-id="28551-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Introducción a Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="28551-116">Azure Data Factory es la plataforma para esta clase de escenarios.</span><span class="sxs-lookup"><span data-stu-id="28551-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="28551-117">Se trata de un **servicio de integración de datos basado en la nube que le permite crear flujos de trabajo orientados a datos en la nube a fin de coordinar y automatizar el movimiento y la transformación de datos**.</span><span class="sxs-lookup"><span data-stu-id="28551-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="28551-118">Mediante Azure Data Factory, puede crear y programar flujos de trabajo orientados a datos (llamados canalizaciones) que pueden ingerir datos de almacenes de datos dispares, procesar o transformar los datos mediante servicios de proceso, como Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics y Azure Machine Learning, y publicar datos de salida en almacenes de datos, como Azure SQL Data Warehouse para que los consuman las aplicaciones de inteligencia empresarial (BI).</span><span class="sxs-lookup"><span data-stu-id="28551-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="28551-119">Es más una plataforma Extraer y cargar (EL) y luego Transformar y cargar (TL) que una plataforma tradicional Extraer, transformar y cargar (ETL).</span><span class="sxs-lookup"><span data-stu-id="28551-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="28551-120">Las transformaciones que se realizan van a transformar/procesar los datos mediante servicios de proceso, en lugar de realizar transformaciones como las de agregar columnas derivadas, contar el número de filas, ordenar datos, etc.</span><span class="sxs-lookup"><span data-stu-id="28551-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="28551-121">Actualmente, en Azure Data Factory, los datos que se consumen y generan en los flujos de trabajo son **datos fragmentados por tiempo** (por hora, día, semana, etc.).</span><span class="sxs-lookup"><span data-stu-id="28551-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="28551-122">Por ejemplo, una canalización puede leer datos de entrada, procesar datos y generar datos de salida una vez al día.</span><span class="sxs-lookup"><span data-stu-id="28551-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="28551-123">También puede ejecutar un flujo de trabajo una sola vez.</span><span class="sxs-lookup"><span data-stu-id="28551-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="28551-124">¿Cómo funciona?</span><span class="sxs-lookup"><span data-stu-id="28551-124">How does it work?</span></span> 
<span data-ttu-id="28551-125">Las canalizaciones (flujos de trabajo orientados a datos) en Azure Data Factory realizan normalmente los tres pasos siguientes:</span><span class="sxs-lookup"><span data-stu-id="28551-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Tres fases de Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="28551-127">Conectar y recopilar</span><span class="sxs-lookup"><span data-stu-id="28551-127">Connect and collect</span></span>
<span data-ttu-id="28551-128">Las empresas tienen datos de varios tipos ubicados en orígenes dispares.</span><span class="sxs-lookup"><span data-stu-id="28551-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="28551-129">El primer paso en la creación de un sistema de producción de información es conectarse a todos los orígenes necesarios de datos y procesamiento, como servicios SaaS, recursos web compartidos de archivos, FTP, servicios web y mover los datos según sea necesario a una ubicación centralizada para su posterior procesamiento.</span><span class="sxs-lookup"><span data-stu-id="28551-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="28551-130">Sin Data Factory, las empresas deben crear componentes de movimiento de datos personalizados o escribir servicios personalizados para integrar estos orígenes de datos y procesamientos.</span><span class="sxs-lookup"><span data-stu-id="28551-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="28551-131">Tales sistemas, además de costosos, resultan difíciles de integrar y administrar, y a menudo carecen de las funcionalidades de supervisión y alerta de clase empresarial y de los controles que un servicio completamente administrado puede ofrecer.</span><span class="sxs-lookup"><span data-stu-id="28551-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="28551-132">Con Data Factory, puede usar la actividad de copia en una canalización de datos para mover los datos desde almacenes de datos de orígenes locales y en la nube a un almacén de datos de centralización en la nube para su posterior análisis.</span><span class="sxs-lookup"><span data-stu-id="28551-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="28551-133">Por ejemplo, puede recopilar datos de una instancia de Azure Data Lake Store y transformarlos posteriormente mediante un servicio de proceso de Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="28551-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="28551-134">O también puede recopilar los datos en Azure Blob Storage y transformarlos más adelante mediante el uso de un clúster de Hadoop de Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="28551-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="28551-135">Transformar y enriquecer</span><span class="sxs-lookup"><span data-stu-id="28551-135">Transform and enrich</span></span>
<span data-ttu-id="28551-136">Una vez que los datos están presentes en un almacén de datos centralizado en la nube, querrá que los datos recopilados se procesen o transformen mediante servicios de proceso, como HDInsight Hadoop, Spark, Data Lake Analytics y Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="28551-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="28551-137">Querrá generar de manera confiable datos transformados según una programación controlada y fácil de mantener a fin de alimentar los entornos de producción con datos de confianza.</span><span class="sxs-lookup"><span data-stu-id="28551-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="28551-138">Publicar</span><span class="sxs-lookup"><span data-stu-id="28551-138">Publish</span></span> 
<span data-ttu-id="28551-139">Los datos transformados en la nube se entregarán a orígenes locales, como SQL Server, o se mantendrán en sus orígenes de almacenamiento en la nube para su consumo por parte de aplicaciones de inteligencia empresarial (BI), herramientas de análisis, etc.</span><span class="sxs-lookup"><span data-stu-id="28551-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="28551-140">Componentes claves</span><span class="sxs-lookup"><span data-stu-id="28551-140">Key components</span></span>
<span data-ttu-id="28551-141">Una suscripción de Azure puede tener una o varias instancias de Azure Data Factory (o factorías de datos).</span><span class="sxs-lookup"><span data-stu-id="28551-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="28551-142">Azure Data Factory está compuesto por cuatro componentes principales que trabajan juntos para proporcionar una plataforma en la que pueda crear flujos de trabajo orientados a datos con pasos para moverlos y transformarlos.</span><span class="sxs-lookup"><span data-stu-id="28551-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="28551-143">Canalización</span><span class="sxs-lookup"><span data-stu-id="28551-143">Pipeline</span></span>
<span data-ttu-id="28551-144">Una factoría de datos puede tener una o más canalizaciones.</span><span class="sxs-lookup"><span data-stu-id="28551-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="28551-145">Una canalización es un grupo de actividades.</span><span class="sxs-lookup"><span data-stu-id="28551-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="28551-146">Juntas, las actividades de una canalización realizan una tarea.</span><span class="sxs-lookup"><span data-stu-id="28551-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="28551-147">Por ejemplo, una canalización podría contener un grupo de actividades que ingiere datos de un blob de Azure y luego ejecutar una consulta de Hive en un clúster de HDInsight para particionar los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="28551-148">La ventaja de esto es que la canalización le permite administrar las actividades como un conjunto en lugar de tener que administrar cada una de ellas individualmente.</span><span class="sxs-lookup"><span data-stu-id="28551-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="28551-149">Por ejemplo, puede implementar y programar la canalización completa, en lugar de las actividades de forma independiente.</span><span class="sxs-lookup"><span data-stu-id="28551-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="28551-150">Actividad</span><span class="sxs-lookup"><span data-stu-id="28551-150">Activity</span></span>
<span data-ttu-id="28551-151">Una canalización puede tener una o más actividades.</span><span class="sxs-lookup"><span data-stu-id="28551-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="28551-152">Las actividades definen las acciones que se van a realizar en los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="28551-153">Por ejemplo, puede utilizar una actividad de copia para copiar datos de un almacén de datos a otro.</span><span class="sxs-lookup"><span data-stu-id="28551-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="28551-154">De igual forma, puede usar una actividad de Hive, que ejecuta una consulta de Hive en un clúster de Azure HDInsight para transformar o analizar los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="28551-155">Data Factory admite dos tipos de actividades: actividades de movimiento de datos y actividades de transformación de datos.</span><span class="sxs-lookup"><span data-stu-id="28551-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="28551-156">Actividades de movimiento de datos</span><span class="sxs-lookup"><span data-stu-id="28551-156">Data movement activities</span></span>
<span data-ttu-id="28551-157">Copiar actividad en Data Factory realiza una copia de los datos de un almacén de datos de origen a uno receptor.</span><span class="sxs-lookup"><span data-stu-id="28551-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="28551-158">Data Factory admite los siguientes almacenes de datos.</span><span class="sxs-lookup"><span data-stu-id="28551-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="28551-159">Se pueden escribir datos desde cualquier origen en todos los tipos de receptores.</span><span class="sxs-lookup"><span data-stu-id="28551-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="28551-160">Haga clic en un almacén de datos para obtener información sobre cómo copiar datos a un almacén como origen o destino.</span><span class="sxs-lookup"><span data-stu-id="28551-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="28551-161">Para más información, consulte el artículo sobre [actividades de movimiento de datos](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="28551-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="28551-162">Actividades de transformación de datos</span><span class="sxs-lookup"><span data-stu-id="28551-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="28551-163">Para más información, consulte el artículo sobre [actividades de transformación de datos](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="28551-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="28551-164">Actividades personalizadas de .NET</span><span class="sxs-lookup"><span data-stu-id="28551-164">Custom .NET activities</span></span>
<span data-ttu-id="28551-165">Si necesita mover datos a un almacén de datos, o desde este, que no sean compatibles con la actividad de copia, o bien transformar datos con su propia lógica, cree una **actividad de .NET personalizada**.</span><span class="sxs-lookup"><span data-stu-id="28551-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="28551-166">Consulte el artículo [Uso de actividades personalizadas en una canalización de Azure Data Factory](data-factory-use-custom-activities.md)para obtener más información sobre la creación y el uso de una actividad personalizada.</span><span class="sxs-lookup"><span data-stu-id="28551-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="28551-167">Conjuntos de datos</span><span class="sxs-lookup"><span data-stu-id="28551-167">Datasets</span></span>
<span data-ttu-id="28551-168">Cada actividad toma cero o más conjuntos de datos como entrada y genera uno o varios conjuntos de datos como salida.</span><span class="sxs-lookup"><span data-stu-id="28551-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="28551-169">Los conjuntos de datos representan las estructuras de datos de los almacenes de datos que simplemente apuntan o hacen referencia a los datos que desea utilizar en sus actividades como entradas o salidas.</span><span class="sxs-lookup"><span data-stu-id="28551-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="28551-170">Por ejemplo, un conjunto de datos del blob de Azure especifica el contenedor de blobs y la carpeta de Azure Blob Storage de los que la canalización debe leer los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="28551-171">O bien, un conjunto de datos de tabla de Azure SQL especifica la tabla en la que la actividad escribe los datos de salida.</span><span class="sxs-lookup"><span data-stu-id="28551-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="28551-172">Servicios vinculados</span><span class="sxs-lookup"><span data-stu-id="28551-172">Linked services</span></span>
<span data-ttu-id="28551-173">Los servicios vinculados son muy similares a las cadenas de conexión que definen la información de conexión necesaria para que Data Factory se conecte a recursos externos.</span><span class="sxs-lookup"><span data-stu-id="28551-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="28551-174">Considérelos de esta forma: un servicio vinculado define la conexión al origen de datos y un conjunto de datos representa la estructura de los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="28551-175">Por ejemplo, un servicio vinculado de Azure Storage especifica la cadena de conexión para conectarse a la cuenta de Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="28551-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="28551-176">Además, un conjunto de datos de Azure Blob especifica el contenedor de blobs y la carpeta que contiene los datos.</span><span class="sxs-lookup"><span data-stu-id="28551-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="28551-177">Los servicios vinculados se utilizan con dos fines en Data Factory:</span><span class="sxs-lookup"><span data-stu-id="28551-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="28551-178">Para representar un **almacén de datos** que incluye, entre otros, una instancia de SQL Server local, una base de datos de Oracle, un recurso compartido de archivos o una cuenta de Azure Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="28551-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="28551-179">Para ver una lista de los almacenes de datos compatibles, consulte la sección [Actividades de movimiento de datos](#data-movement-activities) .</span><span class="sxs-lookup"><span data-stu-id="28551-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="28551-180">Para representar un **recurso de proceso** que puede hospedar la ejecución de una actividad.</span><span class="sxs-lookup"><span data-stu-id="28551-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="28551-181">Por ejemplo, la actividad HDInsightHive se ejecuta en un clúster de Hadoop para HDInsight.</span><span class="sxs-lookup"><span data-stu-id="28551-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="28551-182">Consulte la sección sobre [actividades de transformación de datos](#data-transformation-activities) para ver una lista de los entornos de procesos admitidos.</span><span class="sxs-lookup"><span data-stu-id="28551-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="28551-183">Relación entre las entidades de Data Factory</span><span class="sxs-lookup"><span data-stu-id="28551-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="28551-184">![Diagrama: Data Factory, un servicio de integración de datos en la nube - conceptos clave](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figura 2.**</span><span class="sxs-lookup"><span data-stu-id="28551-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="28551-185">Relaciones entre conjuntos de datos, actividades, canalizaciones y servicios vinculados</span><span class="sxs-lookup"><span data-stu-id="28551-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="28551-186">Regiones admitidas</span><span class="sxs-lookup"><span data-stu-id="28551-186">Supported regions</span></span>
<span data-ttu-id="28551-187">Actualmente, se pueden crear factorías de datos en las regiones de **oeste de EE. UU.**, **este de EE.UU.** y **Europa del Norte**.</span><span class="sxs-lookup"><span data-stu-id="28551-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="28551-188">Sin embargo, una factoría de datos puede acceder a almacenes de datos y a servicios de proceso en otras regiones de Azure para mover datos entre los almacenes de datos o para procesar datos mediante servicios de proceso.</span><span class="sxs-lookup"><span data-stu-id="28551-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="28551-189">Azure Data Factory no almacena ningún dato.</span><span class="sxs-lookup"><span data-stu-id="28551-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="28551-190">Permite crear flujos de trabajo controlados por datos para orquestar el movimiento de los datos entre los [almacenes de datos admitidos](#data-movement-activities) y organizar el procesamiento de los datos mediante [servicios de proceso](#data-transformation-activities) en otras regiones o en entornos locales.</span><span class="sxs-lookup"><span data-stu-id="28551-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="28551-191">También permite [supervisar y administrar flujos de trabajo](data-factory-monitor-manage-pipelines.md) mediante mecanismos de programación y la interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="28551-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="28551-192">Aunque Data Factory solamente está disponible en las regiones de **oeste de EE. UU.**, **este de EE.UU.** y **Europa del Norte**, el servicio que atiende el movimiento de datos en Data Factory está disponible [globalmente](data-factory-data-movement-activities.md#global) en varias regiones.</span><span class="sxs-lookup"><span data-stu-id="28551-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="28551-193">Si un almacén de datos se encuentra detrás de un firewall, será una [puerta de enlace de administración de datos](data-factory-move-data-between-onprem-and-cloud.md) instalada en el entorno local la que mueva los datos en su lugar.</span><span class="sxs-lookup"><span data-stu-id="28551-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="28551-194">Por ejemplo, supongamos que sus entornos de proceso, tales como clúster de Azure HDInsight y Azure Machine Learning, se ejecutan fuera de la región de Europa Occidental.</span><span class="sxs-lookup"><span data-stu-id="28551-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="28551-195">Puede crear y usar una instancia de Azure Data Factory en Europa del Norte y usarla para programar trabajos en los entornos de proceso en Europa Occidental.</span><span class="sxs-lookup"><span data-stu-id="28551-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="28551-196">Data Factory tarda unos milisegundos en desencadenar el trabajo en su entorno de proceso, pero el tiempo para ejecutar el trabajo en el entorno de proceso no cambia.</span><span class="sxs-lookup"><span data-stu-id="28551-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="28551-197">Introducción a la creación de una canalización</span><span class="sxs-lookup"><span data-stu-id="28551-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="28551-198">Puede usar una de esas herramientas o una de estas API para crear canalizaciones de datos en Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="28551-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="28551-199">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="28551-199">Azure portal</span></span>
- <span data-ttu-id="28551-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="28551-200">Visual Studio</span></span>
- <span data-ttu-id="28551-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="28551-201">PowerShell</span></span>
- <span data-ttu-id="28551-202">API de .NET</span><span class="sxs-lookup"><span data-stu-id="28551-202">.NET API</span></span>
- <span data-ttu-id="28551-203">API de REST</span><span class="sxs-lookup"><span data-stu-id="28551-203">REST API</span></span>
- <span data-ttu-id="28551-204">Plantilla de Azure Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="28551-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="28551-205">Para aprender a compilar factorías de datos con canalizaciones de datos, siga las instrucciones paso a paso en los siguientes tutoriales:</span><span class="sxs-lookup"><span data-stu-id="28551-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="28551-206">Tutorial</span><span class="sxs-lookup"><span data-stu-id="28551-206">Tutorial</span></span> | <span data-ttu-id="28551-207">Descripción</span><span class="sxs-lookup"><span data-stu-id="28551-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="28551-208">Movimiento de datos entre dos almacenes de datos en la nube</span><span class="sxs-lookup"><span data-stu-id="28551-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="28551-209">En este tutorial, va a crear una factoría de datos con una canalización que **mueve datos** de Blob Storage a SQL Database.</span><span class="sxs-lookup"><span data-stu-id="28551-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="28551-210">Transformar datos usando el clúster de Hadoop</span><span class="sxs-lookup"><span data-stu-id="28551-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="28551-211">En este tutorial, va a crear su primera instancia de Azure Data Factory con una canalización de datos que **procesa los datos** ejecutando el script de Hive en un clúster de Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="28551-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="28551-212">Movimiento de datos entre un almacén de datos local y un almacén de datos en la nube con Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="28551-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="28551-213">En este tutorial, va a compilar una factoría de datos con una canalización que **mueve los datos** de una base de datos de SQL Server **local** a un blob de Azure.</span><span class="sxs-lookup"><span data-stu-id="28551-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="28551-214">Como parte del tutorial, instalará y configurará la puerta de enlace de administración de datos en su máquina.</span><span class="sxs-lookup"><span data-stu-id="28551-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
