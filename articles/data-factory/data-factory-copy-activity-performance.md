---
title: "Guía de optimización y rendimiento de la actividad de copia | Microsoft Docs"
description: "Conozca los factores más importantes que afectan al rendimiento del movimiento de datos en Data Factory de Azure cuando se usa la actividad de copia."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="f6b41-103">Guía de optimización y rendimiento de la actividad de copia</span><span class="sxs-lookup"><span data-stu-id="f6b41-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="f6b41-104">Copiar actividad de Azure Data Factory ofrece una solución de carga de datos de alto rendimiento fiable y segura de primera clase.</span><span class="sxs-lookup"><span data-stu-id="f6b41-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="f6b41-105">Le permite copiar decenas de terabytes de datos al día en una amplia variedad de almacenes de datos locales y en la nube.</span><span class="sxs-lookup"><span data-stu-id="f6b41-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="f6b41-106">Un rendimiento acelerado de la carga de datos es clave para garantizar que puede centrarse en el problema principal de los "macrodatos": crear soluciones de análisis avanzadas y profundizar en todos esos datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="f6b41-107">Azure proporciona un conjunto de soluciones de almacén de datos y almacenamiento de datos de clase empresarial, y la actividad de copia ofrece una experiencia de carga de datos enormemente optimizada que es fácil de configurar e instalar.</span><span class="sxs-lookup"><span data-stu-id="f6b41-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="f6b41-108">Con solo una actividad de copia, puede conseguir:</span><span class="sxs-lookup"><span data-stu-id="f6b41-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="f6b41-109">Cargar datos en **Azure SQL Data Warehouse** a **1,2 GBps**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="f6b41-110">Para un tutorial con un caso de uso, consulte [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carga de 1 TB en Azure SQL Data Warehouse en 15 minutos con Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="f6b41-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="f6b41-111">Cargar datos en **Azure Blob Storage** a **1,0 GBps**</span><span class="sxs-lookup"><span data-stu-id="f6b41-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="f6b41-112">Cargar datos en **Azure Data Lake Store** a **1,0 GBps**</span><span class="sxs-lookup"><span data-stu-id="f6b41-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="f6b41-113">En este artículo se describe:</span><span class="sxs-lookup"><span data-stu-id="f6b41-113">This article describes:</span></span>

* <span data-ttu-id="f6b41-114">[Números de referencia de rendimiento](#performance-reference) , para almacenes de datos origen y receptor que le ayudan a planear su proyecto.</span><span class="sxs-lookup"><span data-stu-id="f6b41-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="f6b41-115">Características que pueden aumentar el rendimiento de la copia en diferentes escenarios, como [unidades de movimiento de datos de nube](#cloud-data-movement-units), [copia en paralelo](#parallel-copy) y [copia almacenada provisionalmente](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="f6b41-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="f6b41-116">[Directrices de ajuste de rendimiento](#performance-tuning-steps) , acerca de cómo optimizar el rendimiento y los factores clave que pueden afectar al rendimiento de la copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="f6b41-117">Si no está familiarizado con la actividad de copia, consulte [Movimiento de datos con la actividad de copia](data-factory-data-movement-activities.md) antes de leer este artículo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="f6b41-118">Referencia de rendimiento</span><span class="sxs-lookup"><span data-stu-id="f6b41-118">Performance reference</span></span>

<span data-ttu-id="f6b41-119">Como referencia, la tabla siguiente muestra la cantidad de procesamiento de copias en MBps para los pares origen-receptor especificados en función de pruebas internas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="f6b41-120">A efectos de comparación, también muestra cómo distintos valores de [unidades de movimiento de datos de nube](#cloud-data-movement-units) o de [escalabilidad de Data Management Gateway](data-factory-data-management-gateway-high-availability-scalability.md) (varios nodos de puerta de enlace) pueden contribuir al rendimiento de copias.</span><span class="sxs-lookup"><span data-stu-id="f6b41-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Matriz de rendimiento](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="f6b41-122">**Puntos a tener en cuenta:**</span><span class="sxs-lookup"><span data-stu-id="f6b41-122">**Points to note:**</span></span>
* <span data-ttu-id="f6b41-123">La capacidad de proceso se calcula con la siguiente fórmula: [tamaño de los datos leídos del origen]/[duración de la ejecución de Copiar actividad].</span><span class="sxs-lookup"><span data-stu-id="f6b41-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="f6b41-124">Los números de referencia de rendimiento de la tabla se midieron mediante el conjunto de datos [TPC-H](http://www.tpc.org/tpch/) en una ejecución de una única actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="f6b41-125">En los almacenes de datos de Azure, el origen y el receptor se encuentran en la misma región de Azure.</span><span class="sxs-lookup"><span data-stu-id="f6b41-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="f6b41-126">Para la copia híbrida entre almacenes de datos locales y en la nube, cada nodo de puerta de enlace se ejecutaba en un equipo independiente del almacén de datos local con la especificación siguiente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="f6b41-127">Si se ha ejecutado una única actividad en la puerta de enlace, la operación de copia solo ha consumido una pequeña parte del ancho de banda de red, memoria y CPU de la máquina de prueba.</span><span class="sxs-lookup"><span data-stu-id="f6b41-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="f6b41-128">Obtenga más información en [Consideraciones sobre Data Management Gateway](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="f6b41-129">CPU</span><span class="sxs-lookup"><span data-stu-id="f6b41-129">CPU</span></span></td>
        <td><span data-ttu-id="f6b41-130">Intel Xeon E5-2660 v2 de 32 núcleos a 2,20 GHz</span><span class="sxs-lookup"><span data-stu-id="f6b41-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="f6b41-131">Memoria</span><span class="sxs-lookup"><span data-stu-id="f6b41-131">Memory</span></span></td>
        <td><span data-ttu-id="f6b41-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="f6b41-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="f6b41-133">Red</span><span class="sxs-lookup"><span data-stu-id="f6b41-133">Network</span></span></td>
        <td><span data-ttu-id="f6b41-134">Interfaz de Internet: 10 Gbps; interfaz de intranet: 40 Gbps</span><span class="sxs-lookup"><span data-stu-id="f6b41-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="f6b41-135">Para lograr un mayor rendimiento, use más unidades de movimiento de datos (DMU) que el número máximo de DMU predeterminado, que es 32 para una ejecución de actividad de copia de nube a nube.</span><span class="sxs-lookup"><span data-stu-id="f6b41-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="f6b41-136">Por ejemplo, con 100 DMU, puede copiar datos de Azure Blob a Azure Data Lake Store a una velocidad de **1 GBps**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="f6b41-137">Consulte la sección [Unidades de movimiento de datos en la nube](#cloud-data-movement-units) para más detalles sobre esta característica y el escenario admitido.</span><span class="sxs-lookup"><span data-stu-id="f6b41-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="f6b41-138">Póngase en contacto con el [soporte técnico de Azure](https://azure.microsoft.com/support/) para solicitar más DMU.</span><span class="sxs-lookup"><span data-stu-id="f6b41-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="f6b41-139">Copia en paralelo</span><span class="sxs-lookup"><span data-stu-id="f6b41-139">Parallel copy</span></span>
<span data-ttu-id="f6b41-140">Puede leer datos del origen o escribir datos en el destino **en paralelo dentro de una ejecución de actividad de copia**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="f6b41-141">Esta característica mejora el rendimiento de una operación de copia y reduce el tiempo necesario para mover datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="f6b41-142">Esta configuración es diferente de la propiedad **concurrency** de la definición de actividad.</span><span class="sxs-lookup"><span data-stu-id="f6b41-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="f6b41-143">La propiedad **concurrency** determina el número de **ejecuciones simultáneas de la actividad de copia** para procesar datos de diferentes ventanas de actividad (de 1 a.m. a 2 a.m., de 2 a.m. a 3 a.m. y de 3 a.m. a 4 a.m., etc.).</span><span class="sxs-lookup"><span data-stu-id="f6b41-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="f6b41-144">Esta funcionalidad es útil cuando se realiza una carga histórica.</span><span class="sxs-lookup"><span data-stu-id="f6b41-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="f6b41-145">La funcionalidad de copia en paralelo se aplica a la **ejecución de una única actividad**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="f6b41-146">Echemos un vistazo a un escenario de ejemplo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="f6b41-147">En el ejemplo siguiente, se van a procesar varios sectores del pasado.</span><span class="sxs-lookup"><span data-stu-id="f6b41-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="f6b41-148">Data Factory ejecuta una única instancia de actividad de copia (una ejecución de actividad) para cada segmento:</span><span class="sxs-lookup"><span data-stu-id="f6b41-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="f6b41-149">El segmento de datos de la primera ventana de actividad ( de 1 a.m. a 2 a.m.) == > ejecución de actividad 1</span><span class="sxs-lookup"><span data-stu-id="f6b41-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="f6b41-150">El segmento de datos de la segunda ventana de actividad (de 2 a.m. a 3 a.m.) == > ejecución de actividad 2</span><span class="sxs-lookup"><span data-stu-id="f6b41-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="f6b41-151">El segmento de datos de la tercera ventana de actividad (de 3 a.m. a 4 a.m.) == > ejecución de actividad 3</span><span class="sxs-lookup"><span data-stu-id="f6b41-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="f6b41-152">y así sucesivamente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-152">And so on.</span></span>

<span data-ttu-id="f6b41-153">En este ejemplo, cuando el valor de **concurrency** está establecido en 2, la **ejecución de actividad 1** y la **ejecución de actividad 2** copian datos de dos ventanas de actividad **a la vez** para mejorar el rendimiento del movimiento de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="f6b41-154">Sin embargo, si hay varios archivos asociados con la ejecución de actividad 1, el servicio de movimiento de datos copia de uno en uno los archivos del origen al destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="f6b41-155">Unidades de movimiento de datos de nube</span><span class="sxs-lookup"><span data-stu-id="f6b41-155">Cloud data movement units</span></span>
<span data-ttu-id="f6b41-156">Una **unidad de movimiento de datos (DMU) de nube** es una medida que representa la eficacia (una combinación de CPU, memoria y asignación de recursos de red) de una única unidad en Data Factory.</span><span class="sxs-lookup"><span data-stu-id="f6b41-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="f6b41-157">Una DMU podría utilizarse en una operación de copia de una nube a otra, pero no en una copia híbrida.</span><span class="sxs-lookup"><span data-stu-id="f6b41-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="f6b41-158">De forma predeterminada, Data Factory usa una única DMU para realizar una única ejecución de la actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="f6b41-159">Para reemplazar esta configuración predeterminada, especifique un valor para la propiedad **cloudDataMovementUnits** de la manera siguiente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="f6b41-160">Para más información sobre el nivel de ganancia de rendimiento que puede obtener al configurar más unidades para un origen y un receptor de copia específicos, consulte la [referencia de rendimiento](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="f6b41-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="f6b41-161">Los **valores admitidos** para la propiedad **cloudDataMovementUnits** son 1 (predeterminado), 2, 4, 8, 16 y 32.</span><span class="sxs-lookup"><span data-stu-id="f6b41-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="f6b41-162">El **número real de DMS de nube** que usa la operación de copia en tiempo de ejecución es igual o inferior al valor configurado, según el patrón de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="f6b41-163">Si necesita más DMU de nube para aumentar el rendimiento, póngase en contacto con el [servicio técnico de Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="f6b41-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="f6b41-164">La configuración de 8 o más solo funciona actualmente cuando se **copian varios archivos de Blob Storage, Data Lake Store, Amazon S3, FTP en la nube o SFTP en la nube a Blob Storage, Data Lake Store o Azure SQL Database**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="f6b41-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="f6b41-165">parallelCopies</span></span>
<span data-ttu-id="f6b41-166">Puede usar la propiedad **parallelCopies** para indicar el paralelismo que quiere que use la actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="f6b41-167">Esta propiedad se puede considerar como el número máximo de subprocesos dentro de la actividad de copia que se pueden leer del origen o escribir en los almacenes de datos receptores en paralelo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="f6b41-168">Para cada ejecución de actividad de copia, Data Factory determina el número de copias en paralelo que se usarán para copiar datos del almacén de datos de origen al almacén de datos de destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="f6b41-169">El número predeterminado de copias en paralelo que use dependerá del tipo de origen y receptor que vaya a emplear.</span><span class="sxs-lookup"><span data-stu-id="f6b41-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="f6b41-170">Origen y receptor</span><span class="sxs-lookup"><span data-stu-id="f6b41-170">Source and sink</span></span> | <span data-ttu-id="f6b41-171">Recuento predeterminado de copias en paralelo determinado por servicio</span><span class="sxs-lookup"><span data-stu-id="f6b41-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="f6b41-172">Copia de datos entre almacenes basados en archivos (Blob Storage, Data Lake Store, Amazon S3, un sistema de archivos local, un HDFS local)</span><span class="sxs-lookup"><span data-stu-id="f6b41-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="f6b41-173">Entre 1 y 32.</span><span class="sxs-lookup"><span data-stu-id="f6b41-173">Between 1 and 32.</span></span> <span data-ttu-id="f6b41-174">Depende del tamaño de los archivos y del número de unidades de movimiento de datos (DMU) de nube usadas para copiar datos entre dos almacenes de datos de nube; o de la configuración física de la máquina de puerta de enlace usada para una copia híbrida (para copiar datos a o desde un almacén de datos local).</span><span class="sxs-lookup"><span data-stu-id="f6b41-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="f6b41-175">Copia de datos desde **cualquier almacén de datos a Almacenamiento de tablas de Azure**</span><span class="sxs-lookup"><span data-stu-id="f6b41-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="f6b41-176">4</span><span class="sxs-lookup"><span data-stu-id="f6b41-176">4</span></span> |
| <span data-ttu-id="f6b41-177">Todos los demás pares de origen y receptor</span><span class="sxs-lookup"><span data-stu-id="f6b41-177">All other source and sink pairs</span></span> |<span data-ttu-id="f6b41-178">1</span><span class="sxs-lookup"><span data-stu-id="f6b41-178">1</span></span> |

<span data-ttu-id="f6b41-179">Normalmente, el comportamiento predeterminado debe proporcionar el mejor rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="f6b41-180">Sin embargo, para controlar la carga en las máquinas que hospedan los almacenes de datos, o para optimizar el rendimiento de la copia, puede optar por reemplazar el valor predeterminado y especificar un valor para la propiedad **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="f6b41-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="f6b41-181">El valor debe estar entre 1 y 32 (ambos inclusive).</span><span class="sxs-lookup"><span data-stu-id="f6b41-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="f6b41-182">En tiempo de ejecución, y para obtener el mejor rendimiento, la actividad de copia usa un valor inferior o igual al valor que ha establecido.</span><span class="sxs-lookup"><span data-stu-id="f6b41-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="f6b41-183">Puntos a tener en cuenta:</span><span class="sxs-lookup"><span data-stu-id="f6b41-183">Points to note:</span></span>

* <span data-ttu-id="f6b41-184">Cuando copie datos entre almacenes basados en archivos, **parallelCopies** determina el paralelismo en el nivel de archivo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="f6b41-185">La fragmentación dentro de un único archivo sucedería debajo de forma automática y transparente, y está diseñada para utilizar el tamaño de fragmento más adecuado para un tipo de almacén de datos de origen determinado para cargar datos en paralelo y ortogonales a parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="f6b41-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="f6b41-186">El número real de copias en paralelo que usa el servicio de movimiento de datos para la operación de copia en tiempo de ejecución no es superior al número de archivos que tenga.</span><span class="sxs-lookup"><span data-stu-id="f6b41-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="f6b41-187">Si el comportamiento de copia es **mergeFile**, la actividad de copia no puede aprovechar las ventajas del paralelismo de nivel de archivo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="f6b41-188">Cuando especifique un valor para la propiedad **parallelCopies** , tenga en cuenta el aumento de la carga en los almacenes de datos de origen y receptor, y en la puerta de enlace si se trata de una copia híbrida.</span><span class="sxs-lookup"><span data-stu-id="f6b41-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="f6b41-189">Esto sucede especialmente si tiene varias actividades o ejecuciones simultáneas de las mismas actividades que se ejecutan en el mismo almacén de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="f6b41-190">Si observa que el almacén de datos o la puerta de enlace están sobrecargados, disminuya el valor de la propiedad **parallelCopies** para aliviar la carga.</span><span class="sxs-lookup"><span data-stu-id="f6b41-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="f6b41-191">Cuando se copian datos de almacenes no basados en archivos en almacenes basados en archivos, el servicio de movimiento de datos ignora la propiedad **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="f6b41-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="f6b41-192">Aunque se especifica el paralelismo, no se aplica en este caso.</span><span class="sxs-lookup"><span data-stu-id="f6b41-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="f6b41-193">Debe usar Data Management Gateway versión 1.11 o superior para emplear la característica **parallelCopies** cuando realice una copia híbrida.</span><span class="sxs-lookup"><span data-stu-id="f6b41-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="f6b41-194">Para un uso mejor de estas dos propiedades, y para mejorar el rendimiento del movimiento de datos, consulte los [casos de uso de ejemplo](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="f6b41-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="f6b41-195">No es necesario configurar **parallelCopies** para aprovechar el comportamiento predeterminado.</span><span class="sxs-lookup"><span data-stu-id="f6b41-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="f6b41-196">Si configura **parallelCopies** y lo hace en un valor demasiado pequeño, es posible que varias DMU de nube no se utilicen completamente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="f6b41-197">Impacto en la facturación</span><span class="sxs-lookup"><span data-stu-id="f6b41-197">Billing impact</span></span>
<span data-ttu-id="f6b41-198">Es **importante** recordar que se cobra en función del tiempo total de la operación de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="f6b41-199">Si un trabajo de copia solía tardar una hora con una unidad de nube y ahora tarda 15 minutos con cuatro unidades de nube, la factura general será casi igual.</span><span class="sxs-lookup"><span data-stu-id="f6b41-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="f6b41-200">Por ejemplo, va a utilizar cuatro unidades de nube.</span><span class="sxs-lookup"><span data-stu-id="f6b41-200">For example, you use four cloud units.</span></span> <span data-ttu-id="f6b41-201">La primera gasta 10 minutos, la segunda 10 minutos, la tercera 5 minutos y la cuarta 5 minutos, todas ellas en una única ejecución de actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="f6b41-202">Se le cobra por el tiempo total de copia (movimiento de datos), que es 10 + 10 + 5 + 5 = 30 minutos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="f6b41-203">El uso de **parallelCopies** no afecta a la facturación.</span><span class="sxs-lookup"><span data-stu-id="f6b41-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="f6b41-204">copia almacenada provisionalmente</span><span class="sxs-lookup"><span data-stu-id="f6b41-204">Staged copy</span></span>
<span data-ttu-id="f6b41-205">Al copiar datos de un almacén de datos de origen a un almacén de datos receptor, podría elegir usar Almacenamiento de blobs como almacenamiento provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="f6b41-206">El almacenamiento provisional es especialmente útil en los siguientes casos:</span><span class="sxs-lookup"><span data-stu-id="f6b41-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="f6b41-207">**Quiere realizar la ingesta de datos de varios almacenes de datos en SQL Data Warehouse mediante PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="f6b41-208">Almacenamiento de datos SQL emplea PolyBase como mecanismo de alto rendimiento para cargar una gran cantidad de datos en Almacenamiento de datos SQL.</span><span class="sxs-lookup"><span data-stu-id="f6b41-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="f6b41-209">Sin embargo, los datos de origen deben estar en Almacenamiento de blobs y deben satisfacer criterios adicionales.</span><span class="sxs-lookup"><span data-stu-id="f6b41-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="f6b41-210">Al cargar datos desde un almacén de datos distinto de Almacenamiento de blobs, puede activar la copia de datos mediante el Almacenamiento de blobs provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="f6b41-211">En ese caso, Data Factory realiza las transformaciones de datos necesarias para garantizar que se cumplen los requisitos de PolyBase.</span><span class="sxs-lookup"><span data-stu-id="f6b41-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="f6b41-212">A continuación, se usa PolyBase para cargar datos en Almacenamiento de datos SQL.</span><span class="sxs-lookup"><span data-stu-id="f6b41-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="f6b41-213">Para más información, consulte [Uso de PolyBase para cargar datos en Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="f6b41-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="f6b41-214">Para un tutorial con un caso de uso, consulte [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carga de 1 TB en Azure SQL Data Warehouse en 15 minutos con Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="f6b41-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="f6b41-215">**En ocasiones, realizar un movimiento de datos híbridos lleva tiempo (es decir, copiar entre un almacén de datos local y un almacén de datos en la nube) a través de una conexión de red lenta**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="f6b41-216">Para mejorar el rendimiento, puede comprimir los datos locales de modo que se tarde menos tiempo en mover datos al almacén de datos provisional en la nube.</span><span class="sxs-lookup"><span data-stu-id="f6b41-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="f6b41-217">Luego, puede descomprimir los datos en el almacenamiento provisional antes de cargarlos en el almacén de datos de destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="f6b41-218">**No quiere abrir otros puertos que no sean el 80 y el 443 en el firewall, debido a las directivas de TI corporativas**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="f6b41-219">Por ejemplo, al copiar datos de un almacén de datos local a un receptor de Base de datos SQL de Azure o a un receptor de Almacenamiento de datos SQL de Azure, debe activar la comunicación TCP saliente en el puerto 1433 tanto para el firewall de Windows como para el firewall corporativo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="f6b41-220">En ese escenario, aproveche la ventaja de la puerta de enlace para copiar primero los datos en una instancia de ensayo de Blob Storage mediante HTTP o HTTPS en el puerto 443.</span><span class="sxs-lookup"><span data-stu-id="f6b41-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="f6b41-221">Luego, puede cargar los datos en Base de datos SQL o en Almacenamiento de datos SQL desde el Almacenamiento de blobs provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="f6b41-222">En este flujo, no es necesario habilitar el puerto 1433.</span><span class="sxs-lookup"><span data-stu-id="f6b41-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="f6b41-223">Funcionamiento de las copias almacenadas provisionalmente</span><span class="sxs-lookup"><span data-stu-id="f6b41-223">How staged copy works</span></span>
<span data-ttu-id="f6b41-224">Al activar la característica de almacenamiento provisional, primero se copian los datos desde el almacén de datos de origen al almacén de datos provisional (el suyo propio).</span><span class="sxs-lookup"><span data-stu-id="f6b41-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="f6b41-225">A continuación, los datos se copian desde el almacén de datos provisional al almacén de datos receptor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="f6b41-226">Data Factory administra automáticamente el flujo de las dos fases.</span><span class="sxs-lookup"><span data-stu-id="f6b41-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="f6b41-227">Data Factory también limpia los datos temporales del almacenamiento provisional una vez finalizado el movimiento de los datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="f6b41-228">En el escenario de copia en la nube (tanto en almacenes de datos de origen y recepción), no se utiliza la puerta de enlace.</span><span class="sxs-lookup"><span data-stu-id="f6b41-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="f6b41-229">El servicio de Data Factory realiza las operaciones de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-229">The Data Factory service performs the copy operations.</span></span>

![Copias almacenadas provisionalmente: escenario de modelo en la nube](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="f6b41-231">En el escenario de copia híbrida, en el que el origen se encuentra en el entorno local y el receptor está en la nube, la puerta de enlace mueve los datos desde el almacén de datos de origen a un almacén de datos provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="f6b41-232">El servicio de Data Factory también mueve los datos desde el almacén de datos provisional al almacén de datos receptor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="f6b41-233">Con el flujo invertido también se permite copiar datos de un almacén de datos en la nube a uno local a través del almacenamiento provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Copias almacenadas provisionalmente: escenario de modelo híbrido](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="f6b41-235">Cuando activa el movimiento de datos mediante un almacenamiento provisional, puede especificar si quiere que los datos se compriman antes de moverlos del almacén de datos de origen al provisional y luego descomprimirlos antes de moverlos desde un almacenamiento de datos provisional a un almacén de datos receptor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="f6b41-236">Actualmente, no se pueden copiar datos entre dos almacenes de datos locales mediante almacenamiento provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="f6b41-237">Esperamos que esta opción esté pronto disponible.</span><span class="sxs-lookup"><span data-stu-id="f6b41-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="f6b41-238">Configuración</span><span class="sxs-lookup"><span data-stu-id="f6b41-238">Configuration</span></span>
<span data-ttu-id="f6b41-239">Configure la opción **enableStaging** de la actividad de copia para especificar si quiere que los datos se almacenen provisionalmente en Blob Storage antes de cargarlos en un almacén de datos de destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="f6b41-240">Al establecer **enableStaging** en TRUE, especifique las propiedades adicionales enumeradas en la siguiente tabla.</span><span class="sxs-lookup"><span data-stu-id="f6b41-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="f6b41-241">Si no tiene un servicio vinculado a la firma de acceso compartido de Almacenamiento o de Almacenamiento de Azure para el almacenamiento provisional, deberá crear uno.</span><span class="sxs-lookup"><span data-stu-id="f6b41-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="f6b41-242">Propiedad</span><span class="sxs-lookup"><span data-stu-id="f6b41-242">Property</span></span> | <span data-ttu-id="f6b41-243">Description</span><span class="sxs-lookup"><span data-stu-id="f6b41-243">Description</span></span> | <span data-ttu-id="f6b41-244">Valor predeterminado</span><span class="sxs-lookup"><span data-stu-id="f6b41-244">Default value</span></span> | <span data-ttu-id="f6b41-245">Obligatorio</span><span class="sxs-lookup"><span data-stu-id="f6b41-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="f6b41-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="f6b41-246">**enableStaging**</span></span> |<span data-ttu-id="f6b41-247">Especifique si desea copiar los datos a través de un almacén provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="f6b41-248">False</span><span class="sxs-lookup"><span data-stu-id="f6b41-248">False</span></span> |<span data-ttu-id="f6b41-249">No</span><span class="sxs-lookup"><span data-stu-id="f6b41-249">No</span></span> |
| <span data-ttu-id="f6b41-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="f6b41-250">**linkedServiceName**</span></span> |<span data-ttu-id="f6b41-251">Especifique el nombre de un servicio vinculado [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) o [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service), que haga referencia a la instancia de Azure Storage que se usa como almacenamiento provisional.</span><span class="sxs-lookup"><span data-stu-id="f6b41-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="f6b41-252">No puede usar Almacenamiento con una firma de acceso compartido para cargar datos en Almacenamiento de datos SQL mediante PolyBase.</span><span class="sxs-lookup"><span data-stu-id="f6b41-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="f6b41-253">Puede usarlo en todos los demás casos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="f6b41-254">N/D</span><span class="sxs-lookup"><span data-stu-id="f6b41-254">N/A</span></span> |<span data-ttu-id="f6b41-255">Sí, cuando el valor de **enableStaging** está establecido en True.</span><span class="sxs-lookup"><span data-stu-id="f6b41-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="f6b41-256">**path**</span><span class="sxs-lookup"><span data-stu-id="f6b41-256">**path**</span></span> |<span data-ttu-id="f6b41-257">Especifique la ruta de acceso de Almacenamiento de blobs que quiere que contenga los datos almacenados provisionalmente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="f6b41-258">Si no se proporciona una ruta de acceso, el servicio creará un contenedor para almacenar los datos temporales.</span><span class="sxs-lookup"><span data-stu-id="f6b41-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="f6b41-259">Especifique una ruta de acceso solo si usa Almacenamiento con una firma de acceso compartido o si necesita que los datos temporales estén en una ubicación específica.</span><span class="sxs-lookup"><span data-stu-id="f6b41-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="f6b41-260">N/D</span><span class="sxs-lookup"><span data-stu-id="f6b41-260">N/A</span></span> |<span data-ttu-id="f6b41-261">No</span><span class="sxs-lookup"><span data-stu-id="f6b41-261">No</span></span> |
| <span data-ttu-id="f6b41-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="f6b41-262">**enableCompression**</span></span> |<span data-ttu-id="f6b41-263">Especifica si se deben comprimir los datos antes de copiarlos en el destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="f6b41-264">Esta configuración reduce el volumen de datos que se va a transferir.</span><span class="sxs-lookup"><span data-stu-id="f6b41-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="f6b41-265">False</span><span class="sxs-lookup"><span data-stu-id="f6b41-265">False</span></span> |<span data-ttu-id="f6b41-266">No</span><span class="sxs-lookup"><span data-stu-id="f6b41-266">No</span></span> |

<span data-ttu-id="f6b41-267">Este es un ejemplo de definición de actividad de copia con las propiedades que se han descrito en la tabla anterior:</span><span class="sxs-lookup"><span data-stu-id="f6b41-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="f6b41-268">Impacto en la facturación</span><span class="sxs-lookup"><span data-stu-id="f6b41-268">Billing impact</span></span>
<span data-ttu-id="f6b41-269">Los cargos que se le realizan se basan en dos elementos: duración de la copia y tipo de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="f6b41-270">Al utilizar almacenamiento provisional durante una copia de nube (copia de datos de un almacén de datos en la nube a otro de este tipo), se le cobrará de la siguiente forma: [suma de la duración de la copia de los pasos 1 y 2] x [precio unitario de la copia de nube].</span><span class="sxs-lookup"><span data-stu-id="f6b41-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="f6b41-271">Al utilizar almacenamiento provisional durante una copia híbrida (copia de datos de un almacén de datos local a uno en la nube), se le cobrará de la siguiente forma: [duración de la copia híbrida] x [precio unitario de la copia híbrida] + [duración de la copia de nube] x [precio unitario de la copia de nube].</span><span class="sxs-lookup"><span data-stu-id="f6b41-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="f6b41-272">Pasos de optimización del rendimiento</span><span class="sxs-lookup"><span data-stu-id="f6b41-272">Performance tuning steps</span></span>
<span data-ttu-id="f6b41-273">Para optimizar el rendimiento del servicio Data Factory con la actividad de copia, sugerimos que realice estos pasos:</span><span class="sxs-lookup"><span data-stu-id="f6b41-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="f6b41-274">**Establezca una línea base**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-274">**Establish a baseline**.</span></span> <span data-ttu-id="f6b41-275">Durante la fase de desarrollo, pruebe la canalización usando la actividad de copia en un ejemplo de datos representativo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="f6b41-276">Puede usar el [modelo de segmentación](data-factory-scheduling-and-execution.md) de Data Factory para limitar la cantidad de datos con los que trabaja.</span><span class="sxs-lookup"><span data-stu-id="f6b41-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="f6b41-277">Recopile características de tiempo de ejecución y rendimiento mediante la **Aplicación de supervisión y administración**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="f6b41-278">Elija **Supervisión y administración** en la página de inicio de Data Factory.</span><span class="sxs-lookup"><span data-stu-id="f6b41-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="f6b41-279">En la vista de árbol, elija el **conjunto de datos de salida**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="f6b41-280">En la lista **Activity Windows** (Ventanas de actividad), elija la ejecución de la actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="f6b41-281">**Activity Windows** (Ventanas de actividad) se muestra la duración de la actividad de copia y el tamaño de los datos que se copian.</span><span class="sxs-lookup"><span data-stu-id="f6b41-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="f6b41-282">El rendimiento se muestra en **Activity Window Explorer**(Explorador de ventanas de actividad).</span><span class="sxs-lookup"><span data-stu-id="f6b41-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="f6b41-283">Para más información sobre la aplicación, consulte [Supervisión y administración de canalizaciones de Data Factory de Azure mediante la nueva Aplicación de supervisión y administración](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="f6b41-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Detalles de ejecución de actividad](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="f6b41-285">Más adelante en este artículo, puede comparar el rendimiento y la configuración de su escenario con la [referencia de rendimiento](#performance-reference) de la actividad de copia de nuestras pruebas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="f6b41-286">**Diagnostique y optimice el rendimiento**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="f6b41-287">Si el rendimiento que observa no satisface sus expectativas, deberá identificar los cuellos de botella.</span><span class="sxs-lookup"><span data-stu-id="f6b41-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="f6b41-288">A continuación, optimice el rendimiento para eliminar o reducir el efecto de los cuellos de botella.</span><span class="sxs-lookup"><span data-stu-id="f6b41-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="f6b41-289">Aunque la descripción completa del diagnóstico de rendimiento escapa del ámbito de este artículo, aquí hay algunos aspectos comunes a tener en cuenta:</span><span class="sxs-lookup"><span data-stu-id="f6b41-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="f6b41-290">Características de rendimiento:</span><span class="sxs-lookup"><span data-stu-id="f6b41-290">Performance features:</span></span>
     * [<span data-ttu-id="f6b41-291">Copia paralela</span><span class="sxs-lookup"><span data-stu-id="f6b41-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="f6b41-292">Unidades de movimiento de datos de nube</span><span class="sxs-lookup"><span data-stu-id="f6b41-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="f6b41-293">Copias almacenadas provisionalmente</span><span class="sxs-lookup"><span data-stu-id="f6b41-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="f6b41-294">Escalabilidad de Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="f6b41-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="f6b41-295">Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="f6b41-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="f6b41-296">Origen</span><span class="sxs-lookup"><span data-stu-id="f6b41-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="f6b41-297">Sink</span><span class="sxs-lookup"><span data-stu-id="f6b41-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="f6b41-298">Serialización y deserialización</span><span class="sxs-lookup"><span data-stu-id="f6b41-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="f6b41-299">Compresión</span><span class="sxs-lookup"><span data-stu-id="f6b41-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="f6b41-300">Asignación de columnas</span><span class="sxs-lookup"><span data-stu-id="f6b41-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="f6b41-301">Otras consideraciones</span><span class="sxs-lookup"><span data-stu-id="f6b41-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="f6b41-302">**Expanda la configuración a todo el conjunto de datos**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="f6b41-303">Cuando esté satisfecho con los resultados de la ejecución y el rendimiento, puede expandir la definición y el período activo de canalización para cubrir todo el conjunto de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="f6b41-304">Consideraciones sobre Data Management Gateway</span><span class="sxs-lookup"><span data-stu-id="f6b41-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="f6b41-305">**Configuración de puerta de enlace**: se recomienda usar una máquina dedicada para hospedar Data Management Gateway.</span><span class="sxs-lookup"><span data-stu-id="f6b41-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="f6b41-306">Vea [Consideraciones sobre el uso de Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="f6b41-307">**Supervisión y escalado vertical u horizontal de la puerta de enlace**: una sola puerta de enlace con uno o varios nodos de puerta de enlace puede atender varias ejecuciones de actividad de copia simultáneamente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="f6b41-308">Para ver una instantánea casi en tiempo real del uso de recursos (CPU, memoria, red [entrada y salida], etc.) en una máquina de puerta de enlace, además del número de trabajos simultáneos en ejecución frente al límite de Azure Portal, vea [Supervisión de la puerta de enlace en el portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="f6b41-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="f6b41-309">Si depende mucho del movimiento de datos híbridos con un gran número de ejecuciones de actividad de copia simultáneas o con grandes volúmenes de datos que copiar, considere la posibilidad de [escalar vertical u horizontalmente la puerta de enlace](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) con el fin de mejorar el uso de recursos o aprovisionar más recursos para ampliar la capacidad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="f6b41-310">Consideraciones sobre el origen</span><span class="sxs-lookup"><span data-stu-id="f6b41-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="f6b41-311">General</span><span class="sxs-lookup"><span data-stu-id="f6b41-311">General</span></span>
<span data-ttu-id="f6b41-312">Asegúrese de que el almacén de datos subyacente no esté saturado con otras cargas de trabajo que se ejecutan en él o contra él.</span><span class="sxs-lookup"><span data-stu-id="f6b41-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="f6b41-313">Para almacenes de datos de Microsoft, consulte los [temas sobre supervisión y optimización](#performance-reference) específicos de los almacenes de datos que le ayuden a comprender las características de rendimiento del almacén de datos, a reducir los tiempos de respuesta y a maximizar la capacidad de proceso.</span><span class="sxs-lookup"><span data-stu-id="f6b41-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="f6b41-314">Si copia los datos de Almacenamiento de blobs a Almacenamiento de datos SQL, considere el uso de **PolyBase** para mejorar el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="f6b41-315">Consulte [Uso de PolyBase para cargar datos en el Almacenamiento de datos SQL](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) para obtener más información.</span><span class="sxs-lookup"><span data-stu-id="f6b41-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="f6b41-316">Para un tutorial con un caso de uso, consulte [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carga de 1 TB en Azure SQL Data Warehouse en 15 minutos con Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="f6b41-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="f6b41-317">Almacenes de datos basados en archivos</span><span class="sxs-lookup"><span data-stu-id="f6b41-317">File-based data stores</span></span>
<span data-ttu-id="f6b41-318">*(Incluye Blob Storage, Data Lake Store, Amazon S3, sistemas de archivos locales y HDFS local)*</span><span class="sxs-lookup"><span data-stu-id="f6b41-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="f6b41-319">**Tamaño de archivo medio y número de archivos**: la actividad de copia transfiere datos de archivo en archivo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="f6b41-320">Siendo la misma cantidad de datos la que se va a mover, el rendimiento general es menor si los datos constan de muchos archivos pequeños en lugar de algunos grandes, debido a la fase de arranque de cada archivo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="f6b41-321">Por lo tanto, si es posible, combine archivos pequeños en archivos de mayor tamaño para obtener una capacidad de proceso mayor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="f6b41-322">**Formato de archivo y compresión**: para ver más formas de mejorar el rendimiento, consulte las secciones [Consideraciones sobre serialización y deserialización](#considerations-for-serialization-and-deserialization) y [Consideraciones sobre la compresión](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="f6b41-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="f6b41-323">Para el escenario de **sistema de archivos local**, en el que se necesita **Data Management Gateway**, consulte la sección [Consideraciones sobre Data Management Gateway](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="f6b41-324">Almacenes de datos relacionales</span><span class="sxs-lookup"><span data-stu-id="f6b41-324">Relational data stores</span></span>
<span data-ttu-id="f6b41-325">*(Incluye SQL Database, SQL Data Warehouse, Amazon Redshift, bases de datos SQL Server y Oracle, MySQL, DB2, Teradata, Sybase y bases de datos PostgreSQL, etc.)*</span><span class="sxs-lookup"><span data-stu-id="f6b41-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="f6b41-326">**Patrón de datos**: el esquema de tabla afecta al rendimiento de la copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="f6b41-327">Un tamaño de fila grande le ofrece un mejor rendimiento que el tamaño de fila pequeño para copiar la misma cantidad de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="f6b41-328">El motivo es que la base de datos puede recuperar más eficazmente menos lotes de datos que contienen menos filas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="f6b41-329">**Consulta o procedimiento almacenado**: optimice la lógica de la consulta o del procedimiento almacenado que se especifica en el origen de la actividad de copia para que capture los datos de forma más eficiente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="f6b41-330">Además, para el escenario de **bases de datos relacionales locales**, como SQL Server y Oracle, que requieren el uso de **Data Management Gateway**, consulte la sección [Consideraciones sobre Data Management Gateway](#considerations-on-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="f6b41-331">Consideraciones sobre el receptor</span><span class="sxs-lookup"><span data-stu-id="f6b41-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="f6b41-332">General</span><span class="sxs-lookup"><span data-stu-id="f6b41-332">General</span></span>
<span data-ttu-id="f6b41-333">Asegúrese de que el almacén de datos subyacente no esté saturado con otras cargas de trabajo que se ejecutan en él o contra él.</span><span class="sxs-lookup"><span data-stu-id="f6b41-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="f6b41-334">Para información sobre los almacenes de datos de Microsoft, consulte los [temas sobre supervisión y optimización](#performance-reference) que son específicos de los almacenes de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="f6b41-335">Estos temas pueden ayudarle a comprender las características de rendimiento de los almacenes de datos y a saber cómo reducir los tiempos de respuesta y aumentar la capacidad de proceso.</span><span class="sxs-lookup"><span data-stu-id="f6b41-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="f6b41-336">Si va a copiar datos de **Blob Storage** a **SQL Data Warehouse**, considere la posibilidad de usar **PolyBase** para aumentar el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="f6b41-337">Consulte [Uso de PolyBase para cargar datos en el Almacenamiento de datos SQL](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) para obtener más información.</span><span class="sxs-lookup"><span data-stu-id="f6b41-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="f6b41-338">Para un tutorial con un caso de uso, consulte [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carga de 1 TB en Azure SQL Data Warehouse en 15 minutos con Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="f6b41-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="f6b41-339">Almacenes de datos basados en archivos</span><span class="sxs-lookup"><span data-stu-id="f6b41-339">File-based data stores</span></span>
<span data-ttu-id="f6b41-340">*(Incluye Blob Storage, Data Lake Store, Amazon S3, sistemas de archivos locales y HDFS local)*</span><span class="sxs-lookup"><span data-stu-id="f6b41-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="f6b41-341">**Comportamiento de copia**: si copia datos de un almacén de datos basado en archivos diferente, la actividad de copia presenta tres opciones mediante la propiedad **copyBehavior**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="f6b41-342">Conserva la jerarquía, aplana la jerarquía o combina archivos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="f6b41-343">Conservar o aplanar la jerarquía supone poca o ninguna sobrecarga sobre el rendimiento, mientras que combinar archivos hace que aumente dicha sobrecarga.</span><span class="sxs-lookup"><span data-stu-id="f6b41-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="f6b41-344">**Formato de archivo y compresión**: consulte las secciones [Consideraciones sobre serialización y deserialización](#considerations-for-serialization-and-deserialization) y [Consideraciones sobre la compresión](#considerations-for-compression) para conocer más formas de mejorar el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="f6b41-345">**Almacenamiento de blobs**: actualmente, Almacenamiento de blobs solo admite blobs en bloques para optimizar la transferencia de datos y el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="f6b41-346">En escenarios de **sistemas de archivos locales** que requieran el uso de **Data Management Gateway**, consulte la sección [Consideraciones sobre Data Management Gateway](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="f6b41-347">Almacenes de datos relacionales</span><span class="sxs-lookup"><span data-stu-id="f6b41-347">Relational data stores</span></span>
<span data-ttu-id="f6b41-348">*(Incluye SQL Database, SQL Data Warehouse, bases de datos SQL Server y bases de datos Oracle)*</span><span class="sxs-lookup"><span data-stu-id="f6b41-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="f6b41-349">**Comportamiento de copia**: según las propiedades que haya establecido para **sqlSink**, la actividad de copia escribe datos en la base de datos de destino de diferentes formas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="f6b41-350">De forma predeterminada, el servicio de movimiento de datos usa la API de copia masiva para insertar datos en modo de anexión, lo que proporciona el mejor rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="f6b41-351">Si configura un procedimiento almacenado en el receptor, la base de datos aplica los datos de fila en fila en lugar de como una carga masiva.</span><span class="sxs-lookup"><span data-stu-id="f6b41-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="f6b41-352">El rendimiento disminuye considerablemente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-352">Performance drops significantly.</span></span> <span data-ttu-id="f6b41-353">Si el conjunto de datos es grande, considere la posibilidad de cambiar al uso de la propiedad **sqlWriterCleanupScript** , cuando sea conveniente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="f6b41-354">Si configura la propiedad **sqlWriterCleanupScript** para cada ejecución de la actividad de copia, el servicio desencadena el script y luego el usuario usa la API de copia masiva para insertar los datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="f6b41-355">Por ejemplo, para sobrescribir toda la tabla con los datos más recientes, puede especificar un script para eliminar primero todos los registros antes de realizar la carga masiva de los nuevos datos desde el origen.</span><span class="sxs-lookup"><span data-stu-id="f6b41-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="f6b41-356">**Patrón de datos y tamaño de lote**:</span><span class="sxs-lookup"><span data-stu-id="f6b41-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="f6b41-357">El esquema de tabla afecta al rendimiento de la copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="f6b41-358">Para copiar la misma cantidad de datos, un tamaño de fila grande proporcionará un mejor rendimiento que un tamaño de fila pequeño porque la base de datos puede confirmar de forma más eficiente menos lotes de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="f6b41-359">La actividad de copia inserta datos en una serie de lotes.</span><span class="sxs-lookup"><span data-stu-id="f6b41-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="f6b41-360">Puede establecer el número de filas en un lote mediante la propiedad **writeBatchSize** .</span><span class="sxs-lookup"><span data-stu-id="f6b41-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="f6b41-361">Si los datos tienen filas pequeñas, puede establecer la propiedad **writeBatchSize** con un valor más alto para beneficiarse de una menor sobrecarga de los lotes y un mayor rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="f6b41-362">Si el tamaño de fila de los datos es grande, tenga cuidado al aumentar **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="f6b41-363">Un valor alto podría provocar un error de copia provocado por la sobrecarga de la base de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="f6b41-364">Para **bases de datos relacionales locales** como SQL Server y Oracle, que requieren el uso de **Data Management Gateway**, consulte la sección [Consideraciones sobre Data Management Gateway](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="f6b41-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="f6b41-365">Almacenes NoSQL</span><span class="sxs-lookup"><span data-stu-id="f6b41-365">NoSQL stores</span></span>
<span data-ttu-id="f6b41-366">*(Incluye Table Storage y Azure Cosmos DB)*</span><span class="sxs-lookup"><span data-stu-id="f6b41-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="f6b41-367">Para **Almacenamiento de tablas**:</span><span class="sxs-lookup"><span data-stu-id="f6b41-367">For **Table storage**:</span></span>
  * <span data-ttu-id="f6b41-368">**Partición**: escribir datos en particiones intercaladas degrada considerablemente el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="f6b41-369">Ordene los datos de origen por la clave de partición para que los datos se inserten de forma eficiente en una partición después de otra o ajuste la lógica para escribir los datos en una sola partición.</span><span class="sxs-lookup"><span data-stu-id="f6b41-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="f6b41-370">Para **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="f6b41-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="f6b41-371">**Tamaño del lote**: la propiedad **writeBatchSize** establece el número de solicitudes en paralelo al servicio Azure Cosmos DB para crear documentos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="f6b41-372">Puede esperar un rendimiento mejor si aumenta el valor de **writeBatchSize** porque se envían más solicitudes en paralelo a Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="f6b41-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="f6b41-373">Sin embargo, tenga cuidado con las limitaciones cuando escriba en Azure Cosmos DB (el mensaje de error es "La tasa de solicitudes es grande").</span><span class="sxs-lookup"><span data-stu-id="f6b41-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="f6b41-374">Son varios los factores que pueden provocar limitaciones, como el tamaño del documento, el número de términos que contiene y la directiva de indexación de la colección de destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="f6b41-375">Para lograr un mayor rendimiento de la actividad de copia, considere la posibilidad de usar una colección mejor (por ejemplo, S3).</span><span class="sxs-lookup"><span data-stu-id="f6b41-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="f6b41-376">Consideraciones sobre serialización y deserialización</span><span class="sxs-lookup"><span data-stu-id="f6b41-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="f6b41-377">La serialización y deserialización pueden tener lugar cuando el conjunto de datos de entrada o el conjunto de datos de salida es un archivo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="f6b41-378">Consulte [Formatos de archivo y de compresión admitidos](data-factory-supported-file-and-compression-formats.md) con detalles sobre los formatos de archivo que admite la actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="f6b41-379">**Comportamiento de copia**:</span><span class="sxs-lookup"><span data-stu-id="f6b41-379">**Copy behavior**:</span></span>

* <span data-ttu-id="f6b41-380">Al copiar archivos entre almacenes de datos basados en archivos:</span><span class="sxs-lookup"><span data-stu-id="f6b41-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="f6b41-381">Cuando los conjuntos de datos de entrada y salida tienen la misma configuración de formato de archivo o carecen de dicha configuración, el servicio de movimiento de datos ejecuta una copia binaria sin ninguna serialización o deserialización.</span><span class="sxs-lookup"><span data-stu-id="f6b41-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="f6b41-382">En este caso, el rendimiento es mayor en comparación con el escenario en el que la configuración del formato de archivo de origen y receptor es diferente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="f6b41-383">Cuando los conjuntos de datos de entrada y salida están en formato de texto y solo es diferente el tipo de codificación, el servicio de movimiento de datos solo realiza la conversión de la codificación.</span><span class="sxs-lookup"><span data-stu-id="f6b41-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="f6b41-384">No se realiza ninguna serialización y deserialización, lo que provoca cierta sobrecarga en el rendimiento en comparación con una copia binaria.</span><span class="sxs-lookup"><span data-stu-id="f6b41-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="f6b41-385">Cuando los conjuntos de datos de entrada y salida tienen formatos de archivo diferentes o configuraciones diferentes, por ejemplo, los delimitadores, el servicio de movimiento de datos deserializa los datos de origen para transmitirlos, transformarlos y luego serializarlos en el formato de salida indicado.</span><span class="sxs-lookup"><span data-stu-id="f6b41-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="f6b41-386">Esta operación da como resultado una sobrecarga mucho mayor sobre el rendimiento en comparación con otros escenarios.</span><span class="sxs-lookup"><span data-stu-id="f6b41-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="f6b41-387">Al copiar archivos desde un almacén de datos y hacia un almacén de datos que no se basa en archivos (por ejemplo, desde un almacén basado en archivos hasta un almacén relacional), se requiere el paso de serialización o deserialización.</span><span class="sxs-lookup"><span data-stu-id="f6b41-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="f6b41-388">Este paso produce una sobrecarga considerable sobre el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="f6b41-389">**Formato de archivo**: el formato de archivo que elija puede afectar al rendimiento de la copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="f6b41-390">Por ejemplo, Avro es un formato binario compacto que almacena metadatos con datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="f6b41-391">Es ampliamente admitido para el procesamiento y la realización de consultas en el ecosistema de Hadoop.</span><span class="sxs-lookup"><span data-stu-id="f6b41-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="f6b41-392">Sin embargo, Avro resulta más caro para serialización y deserialización, lo que da lugar a un menor rendimiento de la copia en comparación con el formato de texto.</span><span class="sxs-lookup"><span data-stu-id="f6b41-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="f6b41-393">Elija el formato de archivo para el flujo de procesamiento de forma holística.</span><span class="sxs-lookup"><span data-stu-id="f6b41-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="f6b41-394">Para comenzar, piense en qué formato se almacenan los datos, los almacenes de datos de origen o si se extraerán de sistemas externos; el mejor formato para el almacenamiento, el procesamiento analítico y la realización de consultas; y en qué formato se deben exportar los datos a data marts para poder usar herramientas de visualización y generación de informes.</span><span class="sxs-lookup"><span data-stu-id="f6b41-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="f6b41-395">A veces, un formato de archivo que no es óptimo desde el punto de vista del rendimiento de lectura y escritura podría ser una buena opción al considerar el proceso analítico en general.</span><span class="sxs-lookup"><span data-stu-id="f6b41-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="f6b41-396">Consideraciones sobre la compresión</span><span class="sxs-lookup"><span data-stu-id="f6b41-396">Considerations for compression</span></span>
<span data-ttu-id="f6b41-397">Cuando el conjunto de datos de entrada o salida es un archivo, puede configurar la actividad de copia para realizar la compresión y descompresión de los datos a medida que se escriben en el destino.</span><span class="sxs-lookup"><span data-stu-id="f6b41-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="f6b41-398">Si elige compresión, está buscando el equilibrio entre entrada/salida (E/S) y CPU.</span><span class="sxs-lookup"><span data-stu-id="f6b41-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="f6b41-399">La compresión de los datos supone un costo adicional en recursos de proceso.</span><span class="sxs-lookup"><span data-stu-id="f6b41-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="f6b41-400">Pero, a cambio, se reduce la E/S de red y el almacenamiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="f6b41-401">Según los datos, puede que observe un aumento en el rendimiento general de la actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="f6b41-402">**Códec**: la actividad de copia admite los tipos de compresión gzip, bzip2 y Deflate.</span><span class="sxs-lookup"><span data-stu-id="f6b41-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="f6b41-403">HDInsight de Azure puede consumir los tres tipos de procesamiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="f6b41-404">Cada códec de compresión tiene sus ventajas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-404">Each compression codec has advantages.</span></span> <span data-ttu-id="f6b41-405">Por ejemplo, bzip2 tiene el rendimiento de copia más bajo, pero obtiene el mejor rendimiento de consulta de Hive porque puede dividirlo para el procesamiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="f6b41-406">Gzip es la opción más equilibrada y es la que se usa con mayor frecuencia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="f6b41-407">Elija el códec que mejor se adapte a su escenario de principio a fin.</span><span class="sxs-lookup"><span data-stu-id="f6b41-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="f6b41-408">**Nivel:**para cada códec de compresión, puede elegir entre dos opciones: compresión más rápida y compresión más óptima.</span><span class="sxs-lookup"><span data-stu-id="f6b41-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="f6b41-409">La operación de compresión más rápida comprime los datos tan pronto como sea posible, incluso si el archivo resultante no se comprime de forma óptima.</span><span class="sxs-lookup"><span data-stu-id="f6b41-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="f6b41-410">La opción de compresión óptima dedica más tiempo a la compresión y produce una cantidad mínima de datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="f6b41-411">Puede probar ambas opciones para ver cuál proporciona un mejor rendimiento general en su caso.</span><span class="sxs-lookup"><span data-stu-id="f6b41-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="f6b41-412">**Una consideración**: para copiar una gran cantidad de datos entre un almacén local y la nube, considere el uso de Almacenamiento de blobs provisional con compresión.</span><span class="sxs-lookup"><span data-stu-id="f6b41-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="f6b41-413">El uso de almacenamiento provisional resulta de utilidad cuando el ancho de banda de la red corporativa y los servicios de Azure son el factor limitador, y si quiere que el conjunto de datos de entrada y el conjunto de datos de salida estén ambos en formato sin comprimir.</span><span class="sxs-lookup"><span data-stu-id="f6b41-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="f6b41-414">En concreto, puede dividir una única actividad de copia en dos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="f6b41-415">La primera copia del origen en un blob de almacenamiento provisional en formato comprimido.</span><span class="sxs-lookup"><span data-stu-id="f6b41-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="f6b41-416">La segunda copia los datos comprimidos del almacenamiento provisional y los descomprime mientras se escriben en el receptor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="f6b41-417">Consideraciones sobre la asignación de columnas</span><span class="sxs-lookup"><span data-stu-id="f6b41-417">Considerations for column mapping</span></span>
<span data-ttu-id="f6b41-418">La propiedad **columnMappings** se puede establecer en la actividad de copia para asignar todas las columnas de entrada, o un subconjunto de ellas, a las columnas de salida.</span><span class="sxs-lookup"><span data-stu-id="f6b41-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="f6b41-419">Después de que el servicio de movimiento de datos lee los datos del origen, debe realizar la asignación de columnas en los datos antes de escribirlos en el receptor.</span><span class="sxs-lookup"><span data-stu-id="f6b41-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="f6b41-420">Este procesamiento adicional reduce la capacidad de proceso de la copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="f6b41-421">Si el almacén de datos de origen es consultable, por ejemplo, si es un almacén relacional, como SQL Database o SQL Server, o es un almacén NoSQL como Table Storage o Azure Cosmos DB, considere la posibilidad de insertar la lógica de filtrado y reordenación de columnas en la propiedad **query**, en lugar de usar la asignación de columnas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="f6b41-422">De esta forma, la proyección se produce mientras el servicio de movimiento de datos lee los datos del almacén de datos de origen, donde es mucho más eficaz.</span><span class="sxs-lookup"><span data-stu-id="f6b41-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="f6b41-423">Otras consideraciones</span><span class="sxs-lookup"><span data-stu-id="f6b41-423">Other considerations</span></span>
<span data-ttu-id="f6b41-424">Si el tamaño de los datos que quiere copiar es grande, puede ajustar la lógica empresarial para particionar los datos aún más mediante el mecanismo de fragmentación de Data Factory.</span><span class="sxs-lookup"><span data-stu-id="f6b41-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="f6b41-425">A continuación, programe la actividad de copia para ejecutarse con mayor frecuencia y así reducir el tamaño de los datos con cada ejecución de actividad de copia.</span><span class="sxs-lookup"><span data-stu-id="f6b41-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="f6b41-426">Tenga cuidado con el número de conjuntos de datos y actividades de copia que necesitan Data Factory para conectarse al mismo almacén de datos al mismo tiempo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="f6b41-427">Muchos trabajos de copia simultáneos podrían limitar un almacén de datos y llevar a una degradación en el rendimiento, reintentos internos de trabajos de copia y, en ocasiones, errores de ejecución.</span><span class="sxs-lookup"><span data-stu-id="f6b41-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="f6b41-428">Escenario de ejemplo: Copia de una instancia local de SQL Server a Blob Storage</span><span class="sxs-lookup"><span data-stu-id="f6b41-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="f6b41-429">**Escenario**: se crea una canalización para copiar datos de una instancia de SQL Server local a Almacenamiento de blobs en formato CSV.</span><span class="sxs-lookup"><span data-stu-id="f6b41-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="f6b41-430">Para acelerar el trabajo de copia, los archivos CSV se deben comprimir en formato bzip2.</span><span class="sxs-lookup"><span data-stu-id="f6b41-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="f6b41-431">**Análisis y pruebas**: el rendimiento de la actividad de copia es inferior a 2 MBps, que es mucho más lento que la referencia de rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="f6b41-432">**Análisis y ajuste del rendimiento**: para solucionar el problema de rendimiento, primero veremos cómo se procesan y se mueven los datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="f6b41-433">**Lectura de datos**: la puerta de enlace abre una conexión a SQL Server y envía la consulta.</span><span class="sxs-lookup"><span data-stu-id="f6b41-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="f6b41-434">SQL Server responde enviando el flujo de datos a la puerta de enlace a través de la intranet.</span><span class="sxs-lookup"><span data-stu-id="f6b41-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="f6b41-435">**Serialización y compresión de datos**: la puerta de enlace serializa el flujo de datos en formato CSV y comprime los datos en una secuencia bzip2.</span><span class="sxs-lookup"><span data-stu-id="f6b41-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="f6b41-436">**Escritura de datos**: la puerta de enlace carga la secuencia bzip2 en Almacenamiento de blobs a través de Internet.</span><span class="sxs-lookup"><span data-stu-id="f6b41-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="f6b41-437">Como puede ver, los datos se procesan y se mueven en streaming de forma secuencial: SQL Server > LAN > Puerta de enlace > WAN > Almacenamiento de blobs.</span><span class="sxs-lookup"><span data-stu-id="f6b41-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="f6b41-438">**El rendimiento general viene determinado por el rendimiento mínimo a través de la canalización**.</span><span class="sxs-lookup"><span data-stu-id="f6b41-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![flujo de datos](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="f6b41-440">Puede que uno o varios de los siguientes factores provoquen el cuello de botella en el rendimiento:</span><span class="sxs-lookup"><span data-stu-id="f6b41-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="f6b41-441">**Origen:**el propio SQL Server tiene un rendimiento bajo debido a cargas intensas.</span><span class="sxs-lookup"><span data-stu-id="f6b41-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="f6b41-442">**Data Management Gateway**</span><span class="sxs-lookup"><span data-stu-id="f6b41-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="f6b41-443">**LAN**: la puerta de enlace se encuentra lejos de la máquina de SQL Server y tiene una conexión de ancho de banda bajo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="f6b41-444">**Puerta de enlace**: la puerta de enlace ha alcanzado sus limitaciones de carga para llevar a cabo las siguientes operaciones:</span><span class="sxs-lookup"><span data-stu-id="f6b41-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="f6b41-445">**Serialización:**la serialización del flujo de datos a formato CSV tiene un rendimiento bajo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="f6b41-446">**Compresión**: ha elegido un códec de compresión lenta (por ejemplo, bzip2, a 2,8 MBps con Core i7).</span><span class="sxs-lookup"><span data-stu-id="f6b41-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="f6b41-447">**WAN**: el ancho de banda entre la red corporativa y los servicios de Azure es bajo (por ejemplo, T1 = 1544 kbps. T2 = 6312 kbps).</span><span class="sxs-lookup"><span data-stu-id="f6b41-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="f6b41-448">**Receptor**: el Almacenamiento de blobs tiene un rendimiento bajo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="f6b41-449">(Esta situación es improbable porque su SLA garantiza un mínimo de 60 MBps).</span><span class="sxs-lookup"><span data-stu-id="f6b41-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="f6b41-450">En este caso, la compresión de datos bzip2 podría estar ralentizando la canalización entera.</span><span class="sxs-lookup"><span data-stu-id="f6b41-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="f6b41-451">El cambio a un códec de compresión gzip podría aliviar este cuello de botella.</span><span class="sxs-lookup"><span data-stu-id="f6b41-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="f6b41-452">Escenarios de ejemplo: uso de la copia en paralelo</span><span class="sxs-lookup"><span data-stu-id="f6b41-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="f6b41-453">**Escenario I:** se copian 1000 archivos de 1 MB del sistema de archivos local a Almacenamiento de blobs.</span><span class="sxs-lookup"><span data-stu-id="f6b41-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="f6b41-454">**Análisis y optimización del rendimiento**: por ejemplo, si ha instalado la puerta de enlace en una máquina de cuatro núcleos, Data Factory usa 16 copias en paralelo para mover los archivos del sistema de archivos a Blob Storage de manera simultánea.</span><span class="sxs-lookup"><span data-stu-id="f6b41-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="f6b41-455">Esta ejecución en paralelo debe tener como resultado un alto rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="f6b41-456">También puede especificar explícitamente el número de copias en paralelo.</span><span class="sxs-lookup"><span data-stu-id="f6b41-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="f6b41-457">Al copiar muchos archivos pequeños, las copias en paralelo ayudan considerablemente al rendimiento al usar los recursos de forma más eficaz.</span><span class="sxs-lookup"><span data-stu-id="f6b41-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Escenario 1.](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="f6b41-459">**Escenario II**: se copian 20 blobs de 500 MB cada uno de Almacenamiento de blobs a Data Lake Store Analytics y luego se optimiza el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="f6b41-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="f6b41-460">**Análisis y optimización del rendimiento**: en este escenario, Data Factory copia los datos de Blob Storage a Data Lake Store mediante una única copia (**parallelCopies** se establece en 1) y unidades de movimiento de datos de nube única.</span><span class="sxs-lookup"><span data-stu-id="f6b41-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="f6b41-461">El rendimiento que observe estará próximo al que se describe en la [sección de referencia de rendimiento](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="f6b41-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Escenario 2.](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="f6b41-463">**Escenario III**: el tamaño de cada archivo es mayor que decenas de MB y el volumen total es grande.</span><span class="sxs-lookup"><span data-stu-id="f6b41-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="f6b41-464">**Análisis y optimización del rendimiento**: el aumento del valor de **parallelCopies** no da lugar a un rendimiento mejor de la copia debido a las limitaciones de recursos de una DMU de nube única.</span><span class="sxs-lookup"><span data-stu-id="f6b41-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="f6b41-465">En su lugar, debe especificar más DMU de nube para obtener más recursos de cara a realizar el movimiento de los datos.</span><span class="sxs-lookup"><span data-stu-id="f6b41-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="f6b41-466">No especifique un valor para la propiedad **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="f6b41-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="f6b41-467">Data Factory controla el paralelismo automáticamente.</span><span class="sxs-lookup"><span data-stu-id="f6b41-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="f6b41-468">En este caso, si establece **cloudDataMovementUnits** en 4, se produce una capacidad de proceso cuádruple.</span><span class="sxs-lookup"><span data-stu-id="f6b41-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Escenario 3.](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="f6b41-470">Referencia</span><span class="sxs-lookup"><span data-stu-id="f6b41-470">Reference</span></span>
<span data-ttu-id="f6b41-471">Estas son algunas referencias para la supervisión y la optimización del rendimiento para algunos de los almacenes de datos admitidos:</span><span class="sxs-lookup"><span data-stu-id="f6b41-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="f6b41-472">Azure Storage (que incluyeBlob Storage y Table Storage): [Objetivos de escalabilidad de Azure Storage](../storage/common/storage-scalability-targets.md) y [Lista de comprobación de rendimiento y escalabilidad de Azure Storage](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="f6b41-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="f6b41-473">Base de datos SQL de Azure: puede [supervisar el rendimiento](../sql-database/sql-database-single-database-monitor.md) y comprobar el porcentaje de unidades de transacción de base de datos (DTU).</span><span class="sxs-lookup"><span data-stu-id="f6b41-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="f6b41-474">Almacenamiento de datos SQL de Azure: su capacidad se mide en unidades de almacenamiento de datos (DWU); consulte [Administración de la potencia de proceso en Almacenamiento de datos SQL de Azure (información general)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="f6b41-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="f6b41-475">Azure Cosmos DB: [Niveles de rendimiento de Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="f6b41-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="f6b41-476">Instancia de SQL Server local: [Supervisión y optimización del rendimiento](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="f6b41-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="f6b41-477">Servidor de archivos local: [Performance Tuning for File Servers](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="f6b41-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
